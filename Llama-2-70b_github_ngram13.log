You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
results_new/neo125_github_experiment/meta-llama_Llama-2-70b-hf/github_ngram_13_<0.8_truncated
Saving results to absolute path: /home/chawins/mimir/tmp_results/neo125_github_experiment/meta-llama_Llama-2-70b-hf/github_ngram_13_<0.8_truncated
LOG: cache_dir is /home/chawins/.cache
Using cache dir /home/chawins/.cache
Loading BASE model meta-llama/Llama-2-70b-hf...
Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.embed_tokens.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.0.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.0.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.0.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.0.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.0.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.0.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.0.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.0.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.0.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.1.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.1.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.1.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.1.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.1.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.1.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.1.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.1.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.1.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.2.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.2.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.2.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.2.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.2.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.2.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.2.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.2.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.2.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.3.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.3.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.3.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.3.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.3.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.3.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.3.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.3.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.3.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.4.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.4.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.4.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.4.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.4.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.4.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.4.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.4.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.4.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.5.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.5.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.5.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.5.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.5.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
Loading checkpoint shards:   7%|▋         | 1/15 [00:00<00:04,  3.29it/s]/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.5.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.5.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.5.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.5.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.6.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.6.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.6.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.6.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.6.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.6.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.6.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.6.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.6.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.7.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.7.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.7.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.7.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.7.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.7.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.7.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.7.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.7.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.8.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.8.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.8.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.8.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.8.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.8.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.8.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.8.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.8.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.9.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.9.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.9.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.9.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.9.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.9.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.9.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.9.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.9.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.10.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.10.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.10.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.10.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.10.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.10.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.10.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.10.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.10.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.11.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.11.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.11.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.11.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
Loading checkpoint shards:  13%|█▎        | 2/15 [00:00<00:04,  3.16it/s]/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.11.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.11.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.11.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.11.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.11.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.12.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.12.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.12.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.12.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.12.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.12.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.12.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.12.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.12.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.13.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.13.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.13.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.13.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.13.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.13.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.13.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.13.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.13.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.14.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.14.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.14.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.14.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.14.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.14.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.14.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.14.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.14.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.15.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.15.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.15.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.15.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.15.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.15.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.15.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.15.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.15.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.16.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.16.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.16.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.16.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.16.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.16.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.16.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.16.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.16.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
Loading checkpoint shards:  20%|██        | 3/15 [00:00<00:03,  3.23it/s]/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.17.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.17.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.17.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.17.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.17.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.17.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.17.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.17.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.17.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.18.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.18.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.18.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.18.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.18.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.18.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.18.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.18.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.18.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.19.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.19.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.19.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.19.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.19.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.19.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.19.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.19.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.19.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.20.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.20.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.20.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.20.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.20.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.20.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.20.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.20.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.20.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.21.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.21.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.21.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.21.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.21.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.21.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.21.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.21.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.21.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.22.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.22.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.22.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.22.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.22.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.22.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
Loading checkpoint shards:  27%|██▋       | 4/15 [00:01<00:03,  3.29it/s]/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.22.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.22.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.22.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.23.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.23.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.23.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.23.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.23.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.23.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.23.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.23.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.23.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.24.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.24.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.24.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.24.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.24.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.24.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.24.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.24.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.24.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.25.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.25.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.25.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.25.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.25.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.25.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.25.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.25.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.25.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.26.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.26.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.26.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.26.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.26.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.26.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.26.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.26.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.26.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.27.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.27.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.27.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.27.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.27.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.27.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.27.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.27.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.27.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.28.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.28.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.28.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.28.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.28.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
Loading checkpoint shards:  33%|███▎      | 5/15 [00:01<00:02,  3.37it/s]/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.28.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.28.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.28.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.28.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.29.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.29.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.29.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.29.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.29.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.29.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.29.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.29.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.29.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.30.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.30.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.30.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.30.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.30.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.30.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.30.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.30.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.30.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.31.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.31.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.31.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.31.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.31.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.31.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.31.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.31.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.31.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.32.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.32.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.32.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.32.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.32.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.32.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.32.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.32.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.32.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.33.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.33.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.33.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.33.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.33.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.33.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.33.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.33.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.33.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.34.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.34.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.34.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.34.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
Loading checkpoint shards:  40%|████      | 6/15 [00:01<00:02,  3.41it/s]/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.34.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.34.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.34.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.34.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.34.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.35.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.35.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.35.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.35.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.35.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.35.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.35.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.35.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.35.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.36.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.36.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.36.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.36.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.36.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.36.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.36.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.36.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.36.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.37.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.37.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.37.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.37.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.37.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.37.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.37.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.37.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.37.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.38.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.38.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.38.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.38.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.38.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.38.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.38.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.38.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.38.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.39.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.39.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.39.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.39.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.39.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.39.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.39.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.39.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.39.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
Loading checkpoint shards:  47%|████▋     | 7/15 [00:02<00:02,  3.43it/s]/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.40.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.40.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.40.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.40.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.40.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.40.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.40.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.40.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.40.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.41.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.41.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.41.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.41.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.41.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.41.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.41.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.41.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.41.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.42.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.42.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.42.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.42.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.42.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.42.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.42.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.42.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.42.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.43.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.43.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.43.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.43.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.43.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.43.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.43.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.43.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.43.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.44.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.44.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.44.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.44.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.44.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.44.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.44.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.44.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.44.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.45.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.45.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.45.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.45.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.45.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.45.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
results_new/neo125_github_experiment/meta-llama_Llama-2-70b-hf/github_ngram_13_<0.8_truncated
Saving results to absolute path: /home/chawins/mimir/tmp_results/neo125_github_experiment/meta-llama_Llama-2-70b-hf/github_ngram_13_<0.8_truncated
LOG: cache_dir is /home/chawins/.cache
Using cache dir /home/chawins/.cache
Loading BASE model meta-llama/Llama-2-70b-hf...
Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.embed_tokens.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.0.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.0.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.0.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.0.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.0.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.0.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.0.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.0.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.0.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.1.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.1.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.1.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.1.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.1.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.1.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.1.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.1.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.1.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.2.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.2.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.2.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.2.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.2.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.2.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.2.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.2.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.2.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.3.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.3.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.3.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.3.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.3.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.3.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.3.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.3.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.3.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.4.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.4.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.4.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.4.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.4.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.4.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.4.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.4.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.4.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.5.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.5.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.5.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.5.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.5.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
Loading checkpoint shards:   7%|▋         | 1/15 [00:00<00:02,  5.68it/s]/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.5.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.5.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.5.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.5.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.6.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.6.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.6.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.6.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.6.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.6.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.6.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.6.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.6.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.7.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.7.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.7.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.7.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.7.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.7.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.7.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.7.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.7.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.8.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.8.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.8.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.8.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.8.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.8.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.8.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.8.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.8.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.9.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.9.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.9.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.9.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.9.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.9.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.9.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.9.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.9.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.10.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.10.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.10.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.10.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.10.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.10.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.10.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.10.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.10.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.11.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.11.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.11.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.11.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
Loading checkpoint shards:  13%|█▎        | 2/15 [00:00<00:02,  5.70it/s]/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.11.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.11.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.11.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.11.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.11.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.12.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.12.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.12.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.12.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.12.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.12.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.12.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.12.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.12.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.13.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.13.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.13.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.13.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.13.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.13.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.13.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.13.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.13.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.14.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.14.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.14.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.14.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.14.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.14.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.14.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.14.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.14.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.15.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.15.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.15.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.15.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.15.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.15.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.15.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.15.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.15.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.16.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.16.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.16.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.16.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.16.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.16.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.16.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.16.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.16.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
Loading checkpoint shards:  20%|██        | 3/15 [00:00<00:02,  5.61it/s]/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.17.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.17.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.17.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.17.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.17.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.17.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.17.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.17.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.17.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.18.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.18.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.18.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.18.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.18.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.18.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.18.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.18.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.18.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.19.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.19.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.19.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.19.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.19.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.19.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.19.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.19.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.19.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.20.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.20.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.20.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.20.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.20.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.20.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.20.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.20.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.20.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.21.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.21.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.21.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.21.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.21.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.21.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.21.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.21.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.21.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.22.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.22.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.22.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.22.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.22.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.22.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
Loading checkpoint shards:  27%|██▋       | 4/15 [00:00<00:01,  5.54it/s]/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.22.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.22.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.22.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.23.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.23.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.23.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.23.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.23.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.23.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.23.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.23.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.23.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.24.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.24.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.24.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.24.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.24.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.24.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.24.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.24.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.24.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.25.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.25.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.25.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.25.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.25.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.25.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.25.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.25.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.25.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.26.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.26.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.26.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.26.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.26.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.26.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.26.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.26.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.26.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.27.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.27.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.27.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.27.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.27.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.27.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.27.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.27.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.27.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.28.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.28.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.28.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.28.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.28.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
Loading checkpoint shards:  33%|███▎      | 5/15 [00:00<00:01,  5.58it/s]/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.28.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.28.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.28.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.28.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.29.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.29.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.29.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.29.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.29.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.29.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.29.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.29.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.29.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.30.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.30.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.30.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.30.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.30.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.30.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.30.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.30.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.30.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.31.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.31.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.31.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.31.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.31.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.31.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.31.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.31.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.31.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.32.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.32.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.32.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.32.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.32.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.32.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.32.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.32.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.32.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.33.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.33.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.33.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.33.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.33.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.33.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.33.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.33.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.33.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.34.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.34.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.34.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.34.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
Loading checkpoint shards:  40%|████      | 6/15 [00:01<00:01,  5.67it/s]/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.34.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.34.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.34.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.34.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.34.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.35.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.35.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.35.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.35.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.35.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.35.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.35.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.35.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.35.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.36.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.36.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.36.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.36.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.36.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.36.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.36.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.36.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.36.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.37.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.37.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.37.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.37.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.37.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.37.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.37.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.37.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.37.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.38.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.38.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.38.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.38.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.38.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.38.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.38.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.38.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.38.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.39.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.39.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.39.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.39.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.39.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.39.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.39.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.39.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.39.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
Loading checkpoint shards:  47%|████▋     | 7/15 [00:01<00:01,  5.69it/s]/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.40.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.40.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.40.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.40.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.40.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.40.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.40.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.40.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.40.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.41.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.41.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.41.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.41.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.41.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.41.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.41.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.41.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.41.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.42.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.42.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.42.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.42.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.42.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.42.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.42.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.42.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.42.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.43.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.43.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.43.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.43.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.43.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.43.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.43.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.43.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.43.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.44.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.44.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.44.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.44.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.44.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.44.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.44.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.44.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.44.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.45.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.45.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.45.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.45.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.45.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.45.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
Loading checkpoint shards:  53%|█████▎    | 8/15 [00:01<00:01,  5.64it/s]/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.45.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.45.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.45.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.46.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.46.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.46.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.46.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.46.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.46.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.46.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.46.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.46.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.47.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.47.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.47.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.47.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.47.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.47.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.47.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.47.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.47.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.48.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.48.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.48.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.48.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.48.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.48.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.48.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.48.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.48.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.49.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.49.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.49.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.49.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.49.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.49.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.49.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.49.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.49.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.50.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.50.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.50.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.50.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.50.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.50.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.50.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.50.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.50.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.51.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.51.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.51.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.51.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.51.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
Loading checkpoint shards:  60%|██████    | 9/15 [00:01<00:01,  5.65it/s]/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.51.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.51.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.51.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.51.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.52.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.52.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.52.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.52.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.52.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.52.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.52.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.52.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.52.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.53.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.53.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.53.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.53.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.53.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.53.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.53.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.53.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.53.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.54.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.54.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.54.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.54.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.54.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.54.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.54.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.54.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.54.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.55.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.55.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.55.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.55.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.55.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.55.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.55.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.55.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.55.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.56.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.56.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.56.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.56.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.56.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.56.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.56.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.56.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.56.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.57.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.57.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.57.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.57.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
Loading checkpoint shards:  67%|██████▋   | 10/15 [00:01<00:00,  5.71it/s]/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.57.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.57.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.57.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.57.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.57.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.58.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.58.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.58.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.58.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.58.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.58.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.58.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.58.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.58.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.59.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.59.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.59.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.59.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.59.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.59.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.59.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.59.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.59.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.60.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.60.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.60.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.60.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.60.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.60.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.60.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.60.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.60.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.61.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.61.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.61.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.61.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.61.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.61.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.61.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.61.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.61.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.62.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.62.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.62.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.62.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.62.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.62.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.62.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.62.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.62.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
Loading checkpoint shards:  73%|███████▎  | 11/15 [00:01<00:00,  5.69it/s]/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.63.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.63.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.63.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.63.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.63.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.63.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.63.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.63.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.63.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.64.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.64.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.64.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.64.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.64.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.64.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.64.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.64.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.64.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.65.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.65.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.65.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.65.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.65.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.65.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.65.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.65.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.65.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.66.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.66.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.66.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.66.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.66.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.66.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.66.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.66.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.66.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.67.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.67.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.67.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.67.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.67.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.67.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.67.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.67.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.67.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.68.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.68.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.68.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.68.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.68.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.68.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
Loading checkpoint shards:  80%|████████  | 12/15 [00:02<00:00,  5.69it/s]/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.68.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.68.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.68.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.69.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.69.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.69.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.69.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.69.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.69.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.69.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.69.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.69.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.70.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.70.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.70.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.70.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.70.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.70.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.70.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.70.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.70.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.71.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.71.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.71.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.71.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.71.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.71.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.71.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.71.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.71.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.72.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.72.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.72.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.72.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.72.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.72.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.72.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.72.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.72.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.73.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.73.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.73.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.73.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.73.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.73.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.73.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.73.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.73.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.74.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.74.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.74.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.74.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.74.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
Loading checkpoint shards:  87%|████████▋ | 13/15 [00:02<00:00,  5.64it/s]/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.74.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.74.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.74.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.74.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.75.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.75.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.75.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.75.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.75.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.75.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.75.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.75.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.75.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.76.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.76.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.76.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.76.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.76.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.76.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.76.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.76.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.76.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.77.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.77.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.77.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.77.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.77.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.77.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.77.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.77.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.77.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.78.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.78.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.78.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.78.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.78.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.78.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.78.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.78.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.78.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.79.self_attn.q_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.79.self_attn.k_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.79.self_attn.v_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.79.self_attn.o_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.79.mlp.gate_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.79.mlp.up_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.79.mlp.down_proj.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.79.input_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.layers.79.post_attention_layernorm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for model.norm.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
Loading checkpoint shards:  93%|█████████▎| 14/15 [00:02<00:00,  5.67it/s]/home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/torch/nn/modules/module.py:2025: UserWarning: for lm_head.weight: copying from a non-meta parameter in the checkpoint to a meta parameter in the current model, which is a no-op. (Did you mean to pass `assign=True` to assign items in the state dictionary to their corresponding key in the module instead of copying them in place?)
  warnings.warn(f'for {key}: copying from a non-meta parameter in the checkpoint to a meta '
Loading checkpoint shards: 100%|██████████| 15/15 [00:02<00:00,  5.75it/s]Loading checkpoint shards: 100%|██████████| 15/15 [00:02<00:00,  5.67it/s]
  0%|          | 0/57 [00:00<?, ?w/s]model.embed_tokens.weight:   0%|          | 0/57 [00:00<?, ?w/s, dev=0]model.embed_tokens.weight:   2%|▏         | 1/57 [00:00<00:10,  5.26w/s, dev=0]model.layers.0.input_layernorm.weight:   2%|▏         | 1/57 [00:00<00:10,  5.25w/s, dev=0]model.layers.0.mlp.down_proj.weight:   4%|▎         | 2/57 [00:00<00:05, 10.48w/s, dev=0]  model.layers.0.mlp.down_proj.weight:   5%|▌         | 3/57 [00:00<00:06,  8.40w/s, dev=0]model.layers.0.mlp.gate_proj.weight:   5%|▌         | 3/57 [00:00<00:06,  8.39w/s, dev=0]model.layers.0.mlp.up_proj.weight:   7%|▋         | 4/57 [00:00<00:06,  7.60w/s, dev=0]  model.layers.0.mlp.up_proj.weight:   9%|▉         | 5/57 [00:00<00:07,  7.25w/s, dev=0]model.layers.0.post_attention_layernorm.weight:   9%|▉         | 5/57 [00:00<00:07,  7.24w/s, dev=0]model.layers.0.self_attn.k_proj.weight:  11%|█         | 6/57 [00:00<00:05,  8.69w/s, dev=0]        model.layers.0.self_attn.o_proj.weight:  12%|█▏        | 7/57 [00:00<00:04, 10.04w/s, dev=0]model.layers.0.self_attn.q_proj.weight:  14%|█▍        | 8/57 [00:00<00:04, 10.70w/s, dev=0]model.layers.0.self_attn.q_proj.weight:  16%|█▌        | 9/57 [00:00<00:04, 11.24w/s, dev=0]model.layers.0.self_attn.rotary_emb.inv_freq:  16%|█▌        | 9/57 [00:00<00:04, 11.23w/s, dev=0]model.layers.0.self_attn.v_proj.weight:  18%|█▊        | 10/57 [00:00<00:03, 12.48w/s, dev=0]     model.layers.1.input_layernorm.weight:  19%|█▉        | 11/57 [00:00<00:03, 13.59w/s, dev=0] model.layers.1.mlp.down_proj.weight:  21%|██        | 12/57 [00:00<00:03, 14.82w/s, dev=0]  model.layers.1.mlp.down_proj.weight:  23%|██▎       | 13/57 [00:00<00:03, 13.16w/s, dev=0]model.layers.1.mlp.gate_proj.weight:  23%|██▎       | 13/57 [00:00<00:03, 13.16w/s, dev=0]model.layers.1.mlp.up_proj.weight:  25%|██▍       | 14/57 [00:01<00:03, 12.03w/s, dev=0]  model.layers.1.post_attention_layernorm.weight:  26%|██▋       | 15/57 [00:01<00:03, 11.23w/s, dev=0]model.layers.1.self_attn.k_proj.weight:  28%|██▊       | 16/57 [00:01<00:03, 11.97w/s, dev=0]        model.layers.1.self_attn.k_proj.weight:  30%|██▉       | 17/57 [00:01<00:03, 12.65w/s, dev=0]model.layers.1.self_attn.o_proj.weight:  30%|██▉       | 17/57 [00:01<00:03, 12.65w/s, dev=0]model.layers.1.self_attn.q_proj.weight:  32%|███▏      | 18/57 [00:01<00:03, 12.95w/s, dev=0]model.layers.1.self_attn.rotary_emb.inv_freq:  33%|███▎      | 19/57 [00:01<00:02, 13.21w/s, dev=0]model.layers.1.self_attn.v_proj.weight:  35%|███▌      | 20/57 [00:01<00:02, 13.90w/s, dev=0]      model.layers.1.self_attn.v_proj.weight:  37%|███▋      | 21/57 [00:01<00:02, 14.53w/s, dev=0]model.layers.2.input_layernorm.weight:  37%|███▋      | 21/57 [00:01<00:02, 14.53w/s, dev=0] model.layers.2.mlp.down_proj.weight:  39%|███▊      | 22/57 [00:01<00:02, 15.22w/s, dev=0]  model.layers.2.mlp.gate_proj.weight:  40%|████      | 23/57 [00:01<00:02, 14.26w/s, dev=0]model.layers.2.mlp.up_proj.weight:  42%|████▏     | 24/57 [00:01<00:02, 13.46w/s, dev=0]  model.layers.2.mlp.up_proj.weight:  44%|████▍     | 25/57 [00:01<00:02, 12.79w/s, dev=0]model.layers.2.post_attention_layernorm.weight:  44%|████▍     | 25/57 [00:01<00:02, 12.79w/s, dev=0]model.layers.2.self_attn.k_proj.weight:  46%|████▌     | 26/57 [00:01<00:02, 13.30w/s, dev=0]        model.layers.2.self_attn.o_proj.weight:  47%|████▋     | 27/57 [00:01<00:02, 13.75w/s, dev=0]model.layers.2.self_attn.q_proj.weight:  49%|████▉     | 28/57 [00:02<00:02, 13.91w/s, dev=0]model.layers.2.self_attn.q_proj.weight:  51%|█████     | 29/57 [00:02<00:01, 14.05w/s, dev=0]model.layers.2.self_attn.rotary_emb.inv_freq:  51%|█████     | 29/57 [00:02<00:01, 14.05w/s, dev=0]model.layers.2.self_attn.v_proj.weight:  53%|█████▎    | 30/57 [00:02<00:01, 14.53w/s, dev=0]      model.layers.3.input_layernorm.weight:  54%|█████▍    | 31/57 [00:02<00:01, 14.96w/s, dev=0] model.layers.3.mlp.down_proj.weight:  56%|█████▌    | 32/57 [00:02<00:01, 15.44w/s, dev=0]  model.layers.3.mlp.down_proj.weight:  58%|█████▊    | 33/57 [00:02<00:01, 14.71w/s, dev=0]model.layers.3.mlp.gate_proj.weight:  58%|█████▊    | 33/57 [00:02<00:01, 14.71w/s, dev=0]model.layers.3.mlp.up_proj.weight:  60%|█████▉    | 34/57 [00:02<00:01, 14.09w/s, dev=0]  model.layers.3.post_attention_layernorm.weight:  61%|██████▏   | 35/57 [00:02<00:01, 13.56w/s, dev=0]model.layers.3.self_attn.k_proj.weight:  63%|██████▎   | 36/57 [00:02<00:01, 13.94w/s, dev=0]        model.layers.3.self_attn.k_proj.weight:  65%|██████▍   | 37/57 [00:02<00:01, 14.29w/s, dev=0]model.layers.3.self_attn.o_proj.weight:  65%|██████▍   | 37/57 [00:02<00:01, 14.28w/s, dev=0]model.layers.3.self_attn.q_proj.weight:  67%|██████▋   | 38/57 [00:02<00:01, 14.39w/s, dev=0]model.layers.3.self_attn.rotary_emb.inv_freq:  68%|██████▊   | 39/57 [00:02<00:01, 14.50w/s, dev=0]model.layers.3.self_attn.v_proj.weight:  70%|███████   | 40/57 [00:02<00:01, 14.87w/s, dev=0]      model.layers.3.self_attn.v_proj.weight:  72%|███████▏  | 41/57 [00:02<00:01, 15.20w/s, dev=0]model.layers.4.input_layernorm.weight:  72%|███████▏  | 41/57 [00:02<00:01, 15.20w/s, dev=0] model.layers.4.mlp.down_proj.weight:  74%|███████▎  | 42/57 [00:02<00:00, 15.57w/s, dev=0]  model.layers.4.mlp.gate_proj.weight:  75%|███████▌  | 43/57 [00:02<00:00, 14.95w/s, dev=0]model.layers.4.mlp.up_proj.weight:  77%|███████▋  | 44/57 [00:03<00:00, 14.38w/s, dev=0]  model.layers.4.mlp.up_proj.weight:  79%|███████▉  | 45/57 [00:03<00:00, 13.91w/s, dev=0]model.layers.4.post_attention_layernorm.weight:  79%|███████▉  | 45/57 [00:03<00:00, 13.91w/s, dev=0]model.layers.4.self_attn.k_proj.weight:  81%|████████  | 46/57 [00:03<00:00, 14.22w/s, dev=0]        model.layers.4.self_attn.o_proj.weight:  82%|████████▏ | 47/57 [00:03<00:00, 14.50w/s, dev=0]model.layers.4.self_attn.q_proj.weight:  84%|████████▍ | 48/57 [00:03<00:00, 14.58w/s, dev=0]model.layers.4.self_attn.q_proj.weight:  86%|████████▌ | 49/57 [00:03<00:00, 14.67w/s, dev=0]model.layers.4.self_attn.rotary_emb.inv_freq:  86%|████████▌ | 49/57 [00:03<00:00, 14.67w/s, dev=0]model.layers.4.self_attn.v_proj.weight:  88%|████████▊ | 50/57 [00:03<00:00, 14.97w/s, dev=0]      model.layers.5.mlp.gate_proj.weight:  89%|████████▉ | 51/57 [00:03<00:00, 15.23w/s, dev=0]   model.layers.5.self_attn.k_proj.weight:  91%|█████████ | 52/57 [00:03<00:00, 14.76w/s, dev=0]model.layers.5.self_attn.k_proj.weight:  93%|█████████▎| 53/57 [00:03<00:00, 15.01w/s, dev=0]model.layers.5.self_attn.o_proj.weight:  93%|█████████▎| 53/57 [00:03<00:00, 15.01w/s, dev=0]model.layers.5.self_attn.q_proj.weight:  95%|█████████▍| 54/57 [00:03<00:00, 15.07w/s, dev=0]model.layers.5.self_attn.rotary_emb.inv_freq:  96%|█████████▋| 55/57 [00:03<00:00, 15.12w/s, dev=0]model.layers.5.self_attn.v_proj.weight:  98%|█████████▊| 56/57 [00:03<00:00, 15.40w/s, dev=0]      model.layers.5.self_attn.v_proj.weight: 100%|██████████| 57/57 [00:03<00:00, 15.64w/s, dev=0]                                                                                               0%|          | 0/59 [00:00<?, ?w/s]model.layers.5.input_layernorm.weight:   0%|          | 0/59 [00:00<?, ?w/s, dev=0]model.layers.5.mlp.down_proj.weight:   2%|▏         | 1/59 [00:00<00:00, 1592.98w/s, dev=0]model.layers.5.mlp.down_proj.weight:   3%|▎         | 2/59 [00:00<00:04, 11.63w/s, dev=0]  model.layers.5.mlp.up_proj.weight:   3%|▎         | 2/59 [00:00<00:04, 11.61w/s, dev=0]  model.layers.5.post_attention_layernorm.weight:   5%|▌         | 3/59 [00:00<00:06,  8.70w/s, dev=0]model.layers.5.post_attention_layernorm.weight:   7%|▋         | 4/59 [00:00<00:04, 11.58w/s, dev=0]model.layers.6.input_layernorm.weight:   7%|▋         | 4/59 [00:00<00:04, 11.57w/s, dev=0]         model.layers.6.mlp.down_proj.weight:   8%|▊         | 5/59 [00:00<00:03, 14.46w/s, dev=0]  model.layers.6.mlp.down_proj.weight:  10%|█         | 6/59 [00:00<00:04, 11.34w/s, dev=0]model.layers.6.mlp.gate_proj.weight:  10%|█         | 6/59 [00:00<00:04, 11.33w/s, dev=0]model.layers.6.mlp.up_proj.weight:  12%|█▏        | 7/59 [00:00<00:05,  9.46w/s, dev=0]  model.layers.6.mlp.up_proj.weight:  14%|█▎        | 8/59 [00:00<00:05,  8.71w/s, dev=0]model.layers.6.post_attention_layernorm.weight:  14%|█▎        | 8/59 [00:00<00:05,  8.71w/s, dev=0]model.layers.6.self_attn.k_proj.weight:  15%|█▌        | 9/59 [00:00<00:05,  9.79w/s, dev=0]        model.layers.6.self_attn.o_proj.weight:  17%|█▋        | 10/59 [00:00<00:04, 10.79w/s, dev=0]model.layers.6.self_attn.q_proj.weight:  19%|█▊        | 11/59 [00:00<00:04, 11.21w/s, dev=0]model.layers.6.self_attn.q_proj.weight:  20%|██        | 12/59 [00:01<00:04, 11.63w/s, dev=0]model.layers.6.self_attn.rotary_emb.inv_freq:  20%|██        | 12/59 [00:01<00:04, 11.62w/s, dev=0]model.layers.6.self_attn.v_proj.weight:  22%|██▏       | 13/59 [00:01<00:03, 12.59w/s, dev=0]      model.layers.7.input_layernorm.weight:  24%|██▎       | 14/59 [00:01<00:03, 13.46w/s, dev=0] model.layers.7.mlp.down_proj.weight:  25%|██▌       | 15/59 [00:01<00:03, 14.42w/s, dev=0]  model.layers.7.mlp.down_proj.weight:  27%|██▋       | 16/59 [00:01<00:03, 13.31w/s, dev=0]model.layers.7.mlp.gate_proj.weight:  27%|██▋       | 16/59 [00:01<00:03, 13.31w/s, dev=0]model.layers.7.mlp.up_proj.weight:  29%|██▉       | 17/59 [00:01<00:03, 11.74w/s, dev=0]  model.layers.7.post_attention_layernorm.weight:  31%|███       | 18/59 [00:01<00:03, 10.36w/s, dev=0]model.layers.7.self_attn.k_proj.weight:  32%|███▏      | 19/59 [00:01<00:03, 10.93w/s, dev=0]        model.layers.7.self_attn.k_proj.weight:  34%|███▍      | 20/59 [00:01<00:03, 11.43w/s, dev=0]model.layers.7.self_attn.o_proj.weight:  34%|███▍      | 20/59 [00:01<00:03, 11.42w/s, dev=0]model.layers.7.self_attn.q_proj.weight:  36%|███▌      | 21/59 [00:01<00:03, 11.59w/s, dev=0]model.layers.7.self_attn.rotary_emb.inv_freq:  37%|███▋      | 22/59 [00:01<00:03, 11.83w/s, dev=0]model.layers.7.self_attn.v_proj.weight:  39%|███▉      | 23/59 [00:01<00:02, 12.37w/s, dev=0]      model.layers.7.self_attn.v_proj.weight:  41%|████      | 24/59 [00:01<00:02, 12.86w/s, dev=0]model.layers.8.input_layernorm.weight:  41%|████      | 24/59 [00:01<00:02, 12.86w/s, dev=0] model.layers.8.mlp.down_proj.weight:  42%|████▏     | 25/59 [00:01<00:02, 13.39w/s, dev=0]  model.layers.8.mlp.gate_proj.weight:  44%|████▍     | 26/59 [00:02<00:02, 12.80w/s, dev=0]model.layers.8.mlp.up_proj.weight:  46%|████▌     | 27/59 [00:02<00:02, 11.64w/s, dev=0]  model.layers.8.mlp.up_proj.weight:  47%|████▋     | 28/59 [00:02<00:02, 10.66w/s, dev=0]model.layers.8.post_attention_layernorm.weight:  47%|████▋     | 28/59 [00:02<00:02, 10.66w/s, dev=0]model.layers.8.self_attn.k_proj.weight:  49%|████▉     | 29/59 [00:02<00:02, 11.03w/s, dev=0]        model.layers.8.self_attn.o_proj.weight:  51%|█████     | 30/59 [00:02<00:02, 11.37w/s, dev=0]model.layers.8.self_attn.q_proj.weight:  53%|█████▎    | 31/59 [00:02<00:02, 11.38w/s, dev=0]model.layers.8.self_attn.q_proj.weight:  54%|█████▍    | 32/59 [00:02<00:02, 11.38w/s, dev=0]model.layers.8.self_attn.rotary_emb.inv_freq:  54%|█████▍    | 32/59 [00:02<00:02, 11.38w/s, dev=0]model.layers.8.self_attn.v_proj.weight:  56%|█████▌    | 33/59 [00:02<00:02, 11.74w/s, dev=0]      model.layers.9.input_layernorm.weight:  58%|█████▊    | 34/59 [00:02<00:02, 12.05w/s, dev=0] model.layers.9.mlp.down_proj.weight:  59%|█████▉    | 35/59 [00:02<00:01, 12.40w/s, dev=0]  model.layers.9.mlp.down_proj.weight:  61%|██████    | 36/59 [00:03<00:01, 11.71w/s, dev=0]model.layers.9.mlp.gate_proj.weight:  61%|██████    | 36/59 [00:03<00:01, 11.71w/s, dev=0]model.layers.9.mlp.up_proj.weight:  63%|██████▎   | 37/59 [00:03<00:01, 11.32w/s, dev=0]  model.layers.9.post_attention_layernorm.weight:  64%|██████▍   | 38/59 [00:03<00:01, 10.70w/s, dev=0]model.layers.9.self_attn.k_proj.weight:  66%|██████▌   | 39/59 [00:03<00:01, 10.98w/s, dev=0]        model.layers.9.self_attn.k_proj.weight:  68%|██████▊   | 40/59 [00:03<00:01, 11.23w/s, dev=0]model.layers.9.self_attn.o_proj.weight:  68%|██████▊   | 40/59 [00:03<00:01, 11.23w/s, dev=0]model.layers.9.self_attn.q_proj.weight:  69%|██████▉   | 41/59 [00:03<00:01, 11.31w/s, dev=0]model.layers.9.self_attn.rotary_emb.inv_freq:  71%|███████   | 42/59 [00:03<00:01, 11.41w/s, dev=0]model.layers.9.self_attn.v_proj.weight:  73%|███████▎  | 43/59 [00:03<00:01, 11.68w/s, dev=0]      model.layers.9.self_attn.v_proj.weight:  75%|███████▍  | 44/59 [00:03<00:01, 11.92w/s, dev=0]model.layers.10.input_layernorm.weight:  75%|███████▍  | 44/59 [00:03<00:01, 11.92w/s, dev=0]model.layers.10.mlp.down_proj.weight:  76%|███████▋  | 45/59 [00:03<00:01, 12.19w/s, dev=0]  model.layers.10.mlp.gate_proj.weight:  78%|███████▊  | 46/59 [00:03<00:01, 11.94w/s, dev=0]model.layers.10.mlp.up_proj.weight:  80%|███████▉  | 47/59 [00:04<00:01, 11.70w/s, dev=0]  model.layers.10.mlp.up_proj.weight:  81%|████████▏ | 48/59 [00:04<00:00, 11.45w/s, dev=0]model.layers.10.post_attention_layernorm.weight:  81%|████████▏ | 48/59 [00:04<00:00, 11.45w/s, dev=0]model.layers.10.self_attn.k_proj.weight:  83%|████████▎ | 49/59 [00:04<00:00, 11.69w/s, dev=0]        model.layers.10.self_attn.o_proj.weight:  85%|████████▍ | 50/59 [00:04<00:00, 11.91w/s, dev=0]model.layers.10.self_attn.q_proj.weight:  86%|████████▋ | 51/59 [00:04<00:00, 12.01w/s, dev=0]model.layers.10.self_attn.q_proj.weight:  88%|████████▊ | 52/59 [00:04<00:00, 12.10w/s, dev=0]model.layers.10.self_attn.rotary_emb.inv_freq:  88%|████████▊ | 52/59 [00:04<00:00, 12.10w/s, dev=0]model.layers.10.self_attn.v_proj.weight:  90%|████████▉ | 53/59 [00:04<00:00, 12.33w/s, dev=0]      model.layers.11.self_attn.k_proj.weight:  92%|█████████▏| 54/59 [00:04<00:00, 12.54w/s, dev=0]model.layers.11.self_attn.o_proj.weight:  93%|█████████▎| 55/59 [00:04<00:00, 12.76w/s, dev=0]model.layers.11.self_attn.q_proj.weight:  95%|█████████▍| 56/59 [00:04<00:00, 12.81w/s, dev=0]model.layers.11.self_attn.q_proj.weight:  97%|█████████▋| 57/59 [00:04<00:00, 12.90w/s, dev=0]model.layers.11.self_attn.rotary_emb.inv_freq:  97%|█████████▋| 57/59 [00:04<00:00, 12.90w/s, dev=0]model.layers.11.self_attn.v_proj.weight:  98%|█████████▊| 58/59 [00:04<00:00, 13.12w/s, dev=0]                                                                                                      0%|          | 0/55 [00:00<?, ?w/s]model.layers.11.input_layernorm.weight:   0%|          | 0/55 [00:00<?, ?w/s, dev=0]model.layers.11.mlp.down_proj.weight:   2%|▏         | 1/55 [00:00<00:00, 1604.55w/s, dev=0]model.layers.11.mlp.down_proj.weight:   4%|▎         | 2/55 [00:00<00:05,  8.89w/s, dev=0]  model.layers.11.mlp.gate_proj.weight:   4%|▎         | 2/55 [00:00<00:05,  8.89w/s, dev=0]model.layers.11.mlp.up_proj.weight:   5%|▌         | 3/55 [00:00<00:07,  7.20w/s, dev=0]  model.layers.11.mlp.up_proj.weight:   7%|▋         | 4/55 [00:00<00:08,  6.05w/s, dev=0]model.layers.11.post_attention_layernorm.weight:   7%|▋         | 4/55 [00:00<00:08,  6.05w/s, dev=0]model.layers.12.input_layernorm.weight:   9%|▉         | 5/55 [00:00<00:06,  7.56w/s, dev=0]         model.layers.12.mlp.down_proj.weight:  11%|█         | 6/55 [00:00<00:05,  9.07w/s, dev=0]  model.layers.12.mlp.down_proj.weight:  13%|█▎        | 7/55 [00:00<00:06,  7.73w/s, dev=0]model.layers.12.mlp.gate_proj.weight:  13%|█▎        | 7/55 [00:00<00:06,  7.72w/s, dev=0]model.layers.12.mlp.up_proj.weight:  15%|█▍        | 8/55 [00:01<00:06,  7.18w/s, dev=0]  model.layers.12.post_attention_layernorm.weight:  16%|█▋        | 9/55 [00:01<00:06,  6.97w/s, dev=0]model.layers.12.post_attention_layernorm.weight:  18%|█▊        | 10/55 [00:01<00:05,  7.74w/s, dev=0]model.layers.12.self_attn.k_proj.weight:  18%|█▊        | 10/55 [00:01<00:05,  7.74w/s, dev=0]        model.layers.12.self_attn.o_proj.weight:  20%|██        | 11/55 [00:01<00:05,  7.95w/s, dev=0]model.layers.12.self_attn.q_proj.weight:  22%|██▏       | 12/55 [00:01<00:05,  8.38w/s, dev=0]model.layers.12.self_attn.q_proj.weight:  24%|██▎       | 13/55 [00:01<00:04,  8.77w/s, dev=0]model.layers.12.self_attn.rotary_emb.inv_freq:  24%|██▎       | 13/55 [00:01<00:04,  8.77w/s, dev=0]model.layers.12.self_attn.v_proj.weight:  25%|██▌       | 14/55 [00:01<00:04,  9.44w/s, dev=0]      model.layers.13.input_layernorm.weight:  27%|██▋       | 15/55 [00:01<00:04,  9.99w/s, dev=0] model.layers.13.mlp.down_proj.weight:  29%|██▉       | 16/55 [00:01<00:03, 10.65w/s, dev=0]  model.layers.13.mlp.down_proj.weight:  31%|███       | 17/55 [00:01<00:03, 10.20w/s, dev=0]model.layers.13.mlp.gate_proj.weight:  31%|███       | 17/55 [00:01<00:03, 10.20w/s, dev=0]model.layers.13.mlp.up_proj.weight:  33%|███▎      | 18/55 [00:01<00:03,  9.75w/s, dev=0]  model.layers.13.post_attention_layernorm.weight:  35%|███▍      | 19/55 [00:02<00:04,  8.84w/s, dev=0]model.layers.13.self_attn.k_proj.weight:  36%|███▋      | 20/55 [00:02<00:03,  9.30w/s, dev=0]        model.layers.13.self_attn.k_proj.weight:  38%|███▊      | 21/55 [00:02<00:03,  9.73w/s, dev=0]model.layers.13.self_attn.o_proj.weight:  38%|███▊      | 21/55 [00:02<00:03,  9.73w/s, dev=0]model.layers.13.self_attn.q_proj.weight:  40%|████      | 22/55 [00:02<00:03,  9.93w/s, dev=0]model.layers.13.self_attn.rotary_emb.inv_freq:  42%|████▏     | 23/55 [00:02<00:03, 10.16w/s, dev=0]model.layers.13.self_attn.v_proj.weight:  44%|████▎     | 24/55 [00:02<00:02, 10.60w/s, dev=0]      model.layers.13.self_attn.v_proj.weight:  45%|████▌     | 25/55 [00:02<00:02, 10.26w/s, dev=0]model.layers.14.input_layernorm.weight:  45%|████▌     | 25/55 [00:02<00:02, 10.26w/s, dev=0] model.layers.14.mlp.down_proj.weight:  47%|████▋     | 26/55 [00:02<00:02, 10.66w/s, dev=0]  model.layers.14.mlp.gate_proj.weight:  49%|████▉     | 27/55 [00:02<00:02, 10.23w/s, dev=0]model.layers.14.mlp.up_proj.weight:  51%|█████     | 28/55 [00:02<00:02,  9.93w/s, dev=0]  model.layers.14.mlp.up_proj.weight:  53%|█████▎    | 29/55 [00:03<00:02,  9.16w/s, dev=0]model.layers.14.post_attention_layernorm.weight:  53%|█████▎    | 29/55 [00:03<00:02,  9.16w/s, dev=0]model.layers.14.self_attn.k_proj.weight:  55%|█████▍    | 30/55 [00:03<00:02,  9.48w/s, dev=0]        model.layers.14.self_attn.o_proj.weight:  56%|█████▋    | 31/55 [00:03<00:02,  9.76w/s, dev=0]model.layers.14.self_attn.q_proj.weight:  58%|█████▊    | 32/55 [00:03<00:02,  9.84w/s, dev=0]model.layers.14.self_attn.q_proj.weight:  60%|██████    | 33/55 [00:03<00:02,  9.96w/s, dev=0]model.layers.14.self_attn.rotary_emb.inv_freq:  60%|██████    | 33/55 [00:03<00:02,  9.96w/s, dev=0]model.layers.14.self_attn.v_proj.weight:  62%|██████▏   | 34/55 [00:03<00:02, 10.26w/s, dev=0]      model.layers.15.input_layernorm.weight:  64%|██████▎   | 35/55 [00:03<00:02,  9.90w/s, dev=0] model.layers.15.mlp.down_proj.weight:  65%|██████▌   | 36/55 [00:03<00:01, 10.18w/s, dev=0]  model.layers.15.mlp.down_proj.weight:  67%|██████▋   | 37/55 [00:03<00:01,  9.78w/s, dev=0]model.layers.15.mlp.gate_proj.weight:  67%|██████▋   | 37/55 [00:03<00:01,  9.78w/s, dev=0]model.layers.15.mlp.up_proj.weight:  69%|██████▉   | 38/55 [00:04<00:01,  9.29w/s, dev=0]  model.layers.15.post_attention_layernorm.weight:  71%|███████   | 39/55 [00:04<00:01,  8.93w/s, dev=0]model.layers.15.self_attn.k_proj.weight:  73%|███████▎  | 40/55 [00:04<00:01,  9.16w/s, dev=0]        model.layers.15.self_attn.k_proj.weight:  75%|███████▍  | 41/55 [00:04<00:01,  9.37w/s, dev=0]model.layers.15.self_attn.o_proj.weight:  75%|███████▍  | 41/55 [00:04<00:01,  9.37w/s, dev=0]model.layers.15.self_attn.q_proj.weight:  76%|███████▋  | 42/55 [00:04<00:01,  9.49w/s, dev=0]model.layers.15.self_attn.rotary_emb.inv_freq:  78%|███████▊  | 43/55 [00:04<00:01,  9.61w/s, dev=0]model.layers.15.self_attn.v_proj.weight:  80%|████████  | 44/55 [00:04<00:01,  9.83w/s, dev=0]      model.layers.15.self_attn.v_proj.weight:  82%|████████▏ | 45/55 [00:04<00:00, 10.02w/s, dev=0]model.layers.16.input_layernorm.weight:  82%|████████▏ | 45/55 [00:04<00:00, 10.02w/s, dev=0] model.layers.16.mlp.down_proj.weight:  84%|████████▎ | 46/55 [00:04<00:00, 10.24w/s, dev=0]  model.layers.16.mlp.gate_proj.weight:  85%|████████▌ | 47/55 [00:04<00:00, 10.10w/s, dev=0]model.layers.16.mlp.up_proj.weight:  87%|████████▋ | 48/55 [00:04<00:00,  9.61w/s, dev=0]  model.layers.16.mlp.up_proj.weight:  89%|████████▉ | 49/55 [00:05<00:00,  9.51w/s, dev=0]model.layers.16.post_attention_layernorm.weight:  89%|████████▉ | 49/55 [00:05<00:00,  9.51w/s, dev=0]model.layers.16.self_attn.k_proj.weight:  91%|█████████ | 50/55 [00:05<00:00,  9.70w/s, dev=0]        model.layers.16.self_attn.o_proj.weight:  93%|█████████▎| 51/55 [00:05<00:00,  9.40w/s, dev=0]model.layers.16.self_attn.q_proj.weight:  95%|█████████▍| 52/55 [00:05<00:00,  9.48w/s, dev=0]model.layers.16.self_attn.q_proj.weight:  96%|█████████▋| 53/55 [00:05<00:00,  9.58w/s, dev=0]model.layers.16.self_attn.rotary_emb.inv_freq:  96%|█████████▋| 53/55 [00:05<00:00,  9.58w/s, dev=0]model.layers.16.self_attn.v_proj.weight:  98%|█████████▊| 54/55 [00:05<00:00,  9.76w/s, dev=0]                                                                                                      0%|          | 0/57 [00:00<?, ?w/s]model.layers.17.input_layernorm.weight:   0%|          | 0/57 [00:00<?, ?w/s, dev=0]model.layers.17.mlp.down_proj.weight:   2%|▏         | 1/57 [00:00<00:00, 1629.49w/s, dev=0]model.layers.17.mlp.down_proj.weight:   4%|▎         | 2/57 [00:00<00:04, 11.66w/s, dev=0]  model.layers.17.mlp.gate_proj.weight:   4%|▎         | 2/57 [00:00<00:04, 11.65w/s, dev=0]model.layers.17.mlp.up_proj.weight:   5%|▌         | 3/57 [00:00<00:05,  9.06w/s, dev=0]  model.layers.17.mlp.up_proj.weight:   7%|▋         | 4/57 [00:00<00:06,  7.80w/s, dev=0]model.layers.17.post_attention_layernorm.weight:   7%|▋         | 4/57 [00:00<00:06,  7.79w/s, dev=0]model.layers.17.self_attn.k_proj.weight:   9%|▉         | 5/57 [00:00<00:05,  9.73w/s, dev=0]        model.layers.17.self_attn.o_proj.weight:  11%|█         | 6/57 [00:00<00:04, 11.46w/s, dev=0]model.layers.17.self_attn.q_proj.weight:  12%|█▏        | 7/57 [00:00<00:04, 12.07w/s, dev=0]model.layers.17.self_attn.q_proj.weight:  14%|█▍        | 8/57 [00:00<00:03, 12.63w/s, dev=0]model.layers.17.self_attn.rotary_emb.inv_freq:  14%|█▍        | 8/57 [00:00<00:03, 12.62w/s, dev=0]model.layers.17.self_attn.v_proj.weight:  16%|█▌        | 9/57 [00:00<00:03, 14.19w/s, dev=0]      model.layers.18.input_layernorm.weight:  18%|█▊        | 10/57 [00:00<00:03, 15.59w/s, dev=0]model.layers.18.mlp.down_proj.weight:  19%|█▉        | 11/57 [00:00<00:02, 17.14w/s, dev=0]  model.layers.18.mlp.down_proj.weight:  21%|██        | 12/57 [00:00<00:03, 13.42w/s, dev=0]model.layers.18.mlp.gate_proj.weight:  21%|██        | 12/57 [00:00<00:03, 13.42w/s, dev=0]model.layers.18.mlp.up_proj.weight:  23%|██▎       | 13/57 [00:01<00:03, 11.69w/s, dev=0]  model.layers.18.post_attention_layernorm.weight:  25%|██▍       | 14/57 [00:01<00:04, 10.62w/s, dev=0]model.layers.18.self_attn.k_proj.weight:  26%|██▋       | 15/57 [00:01<00:03, 11.37w/s, dev=0]        model.layers.18.self_attn.k_proj.weight:  28%|██▊       | 16/57 [00:01<00:03, 12.02w/s, dev=0]model.layers.18.self_attn.o_proj.weight:  28%|██▊       | 16/57 [00:01<00:03, 12.02w/s, dev=0]model.layers.18.self_attn.q_proj.weight:  30%|██▉       | 17/57 [00:01<00:03, 12.01w/s, dev=0]model.layers.18.self_attn.rotary_emb.inv_freq:  32%|███▏      | 18/57 [00:01<00:03, 12.26w/s, dev=0]model.layers.18.self_attn.v_proj.weight:  33%|███▎      | 19/57 [00:01<00:02, 12.93w/s, dev=0]      model.layers.18.self_attn.v_proj.weight:  35%|███▌      | 20/57 [00:01<00:02, 13.52w/s, dev=0]model.layers.19.input_layernorm.weight:  35%|███▌      | 20/57 [00:01<00:02, 13.52w/s, dev=0] model.layers.19.mlp.down_proj.weight:  37%|███▋      | 21/57 [00:01<00:02, 14.19w/s, dev=0]  model.layers.19.mlp.gate_proj.weight:  39%|███▊      | 22/57 [00:01<00:02, 13.22w/s, dev=0]model.layers.19.mlp.up_proj.weight:  40%|████      | 23/57 [00:01<00:02, 12.55w/s, dev=0]  model.layers.19.mlp.up_proj.weight:  42%|████▏     | 24/57 [00:01<00:02, 12.05w/s, dev=0]model.layers.19.post_attention_layernorm.weight:  42%|████▏     | 24/57 [00:01<00:02, 12.05w/s, dev=0]model.layers.19.self_attn.k_proj.weight:  44%|████▍     | 25/57 [00:01<00:02, 12.55w/s, dev=0]        model.layers.19.self_attn.o_proj.weight:  46%|████▌     | 26/57 [00:01<00:02, 13.01w/s, dev=0]model.layers.19.self_attn.q_proj.weight:  47%|████▋     | 27/57 [00:02<00:02, 13.21w/s, dev=0]model.layers.19.self_attn.rotary_emb.inv_freq:  49%|████▉     | 28/57 [00:02<00:02, 13.40w/s, dev=0]model.layers.19.self_attn.v_proj.weight:  51%|█████     | 29/57 [00:02<00:02, 13.87w/s, dev=0]      model.layers.19.self_attn.v_proj.weight:  53%|█████▎    | 30/57 [00:02<00:01, 14.30w/s, dev=0]model.layers.20.input_layernorm.weight:  53%|█████▎    | 30/57 [00:02<00:02, 12.43w/s, dev=1] model.layers.20.mlp.down_proj.weight:  54%|█████▍    | 31/57 [00:02<00:02, 12.84w/s, dev=1]  model.layers.20.mlp.gate_proj.weight:  56%|█████▌    | 32/57 [00:02<00:02, 12.37w/s, dev=1]model.layers.20.mlp.up_proj.weight:  58%|█████▊    | 33/57 [00:02<00:02, 11.99w/s, dev=1]  model.layers.20.post_attention_layernorm.weight:  60%|█████▉    | 34/57 [00:02<00:01, 11.60w/s, dev=1]model.layers.20.self_attn.k_proj.weight:  61%|██████▏   | 35/57 [00:02<00:01, 11.94w/s, dev=1]        model.layers.20.self_attn.k_proj.weight:  63%|██████▎   | 36/57 [00:02<00:01, 12.25w/s, dev=1]model.layers.20.self_attn.o_proj.weight:  63%|██████▎   | 36/57 [00:02<00:01, 12.25w/s, dev=1]model.layers.20.self_attn.q_proj.weight:  65%|██████▍   | 37/57 [00:02<00:01, 12.39w/s, dev=1]model.layers.20.self_attn.rotary_emb.inv_freq:  67%|██████▋   | 38/57 [00:03<00:01, 12.52w/s, dev=1]model.layers.20.self_attn.v_proj.weight:  68%|██████▊   | 39/57 [00:03<00:01, 12.85w/s, dev=1]      model.layers.21.input_layernorm.weight:  70%|███████   | 40/57 [00:03<00:01, 13.15w/s, dev=1] model.layers.21.mlp.down_proj.weight:  72%|███████▏  | 41/57 [00:03<00:01, 13.48w/s, dev=1]  model.layers.21.mlp.down_proj.weight:  74%|███████▎  | 42/57 [00:03<00:01, 13.05w/s, dev=1]model.layers.21.mlp.gate_proj.weight:  74%|███████▎  | 42/57 [00:03<00:01, 13.05w/s, dev=1]model.layers.21.mlp.up_proj.weight:  75%|███████▌  | 43/57 [00:03<00:01, 12.63w/s, dev=1]  model.layers.21.post_attention_layernorm.weight:  77%|███████▋  | 44/57 [00:03<00:01, 12.33w/s, dev=1]model.layers.21.self_attn.k_proj.weight:  79%|███████▉  | 45/57 [00:03<00:00, 12.61w/s, dev=1]        model.layers.21.self_attn.o_proj.weight:  81%|████████  | 46/57 [00:03<00:00, 12.86w/s, dev=1]model.layers.21.self_attn.q_proj.weight:  82%|████████▏ | 47/57 [00:03<00:00, 12.95w/s, dev=1]model.layers.21.self_attn.q_proj.weight:  84%|████████▍ | 48/57 [00:03<00:00, 13.02w/s, dev=1]model.layers.21.self_attn.rotary_emb.inv_freq:  84%|████████▍ | 48/57 [00:03<00:00, 13.02w/s, dev=1]model.layers.21.self_attn.v_proj.weight:  86%|████████▌ | 49/57 [00:03<00:00, 13.29w/s, dev=1]      model.layers.22.mlp.down_proj.weight:  88%|████████▊ | 50/57 [00:03<00:00, 13.52w/s, dev=1]   model.layers.22.mlp.gate_proj.weight:  89%|████████▉ | 51/57 [00:03<00:00, 13.14w/s, dev=1]model.layers.22.self_attn.k_proj.weight:  91%|█████████ | 52/57 [00:04<00:00, 12.80w/s, dev=1]model.layers.22.self_attn.o_proj.weight:  93%|█████████▎| 53/57 [00:04<00:00, 13.03w/s, dev=1]model.layers.22.self_attn.o_proj.weight:  95%|█████████▍| 54/57 [00:04<00:00, 13.10w/s, dev=1]model.layers.22.self_attn.q_proj.weight:  95%|█████████▍| 54/57 [00:04<00:00, 13.10w/s, dev=1]model.layers.22.self_attn.rotary_emb.inv_freq:  96%|█████████▋| 55/57 [00:04<00:00, 13.18w/s, dev=1]model.layers.22.self_attn.v_proj.weight:  98%|█████████▊| 56/57 [00:04<00:00, 13.42w/s, dev=1]                                                                                                      0%|          | 0/59 [00:00<?, ?w/s]model.layers.22.input_layernorm.weight:   0%|          | 0/59 [00:00<?, ?w/s, dev=1]model.layers.22.mlp.up_proj.weight:   2%|▏         | 1/59 [00:00<00:00, 1260.69w/s, dev=1]model.layers.22.mlp.up_proj.weight:   3%|▎         | 2/59 [00:00<00:04, 12.22w/s, dev=1]  model.layers.22.post_attention_layernorm.weight:   3%|▎         | 2/59 [00:00<00:04, 12.20w/s, dev=1]model.layers.23.input_layernorm.weight:   5%|▌         | 3/59 [00:00<00:03, 18.26w/s, dev=1]         model.layers.23.mlp.down_proj.weight:   7%|▋         | 4/59 [00:00<00:02, 24.31w/s, dev=1]  model.layers.23.mlp.down_proj.weight:   8%|▊         | 5/59 [00:00<00:03, 14.94w/s, dev=1]model.layers.23.mlp.gate_proj.weight:   8%|▊         | 5/59 [00:00<00:03, 14.93w/s, dev=1]model.layers.23.mlp.up_proj.weight:  10%|█         | 6/59 [00:00<00:05, 10.51w/s, dev=1]  model.layers.23.post_attention_layernorm.weight:  12%|█▏        | 7/59 [00:00<00:06,  8.61w/s, dev=1]model.layers.23.post_attention_layernorm.weight:  14%|█▎        | 8/59 [00:00<00:05,  9.84w/s, dev=1]model.layers.23.self_attn.k_proj.weight:  14%|█▎        | 8/59 [00:00<00:05,  9.84w/s, dev=1]        model.layers.23.self_attn.o_proj.weight:  15%|█▌        | 9/59 [00:00<00:04, 10.07w/s, dev=1]model.layers.23.self_attn.q_proj.weight:  17%|█▋        | 10/59 [00:00<00:04, 10.59w/s, dev=1]model.layers.23.self_attn.q_proj.weight:  19%|█▊        | 11/59 [00:00<00:04, 11.07w/s, dev=1]model.layers.23.self_attn.rotary_emb.inv_freq:  19%|█▊        | 11/59 [00:00<00:04, 11.07w/s, dev=1]model.layers.23.self_attn.v_proj.weight:  20%|██        | 12/59 [00:00<00:03, 12.07w/s, dev=1]      model.layers.24.input_layernorm.weight:  22%|██▏       | 13/59 [00:01<00:04, 11.32w/s, dev=1] model.layers.24.input_layernorm.weight:  24%|██▎       | 14/59 [00:01<00:03, 12.19w/s, dev=1]model.layers.24.mlp.down_proj.weight:  24%|██▎       | 14/59 [00:01<00:03, 12.19w/s, dev=1]  model.layers.24.mlp.gate_proj.weight:  25%|██▌       | 15/59 [00:01<00:03, 11.32w/s, dev=1]model.layers.24.mlp.up_proj.weight:  27%|██▋       | 16/59 [00:01<00:04,  9.56w/s, dev=1]  model.layers.24.mlp.up_proj.weight:  29%|██▉       | 17/59 [00:01<00:04,  8.69w/s, dev=1]model.layers.24.post_attention_layernorm.weight:  29%|██▉       | 17/59 [00:01<00:04,  8.69w/s, dev=1]model.layers.24.self_attn.k_proj.weight:  31%|███       | 18/59 [00:01<00:04,  9.20w/s, dev=1]        model.layers.24.self_attn.o_proj.weight:  32%|███▏      | 19/59 [00:02<00:04,  8.96w/s, dev=1]model.layers.24.self_attn.o_proj.weight:  34%|███▍      | 20/59 [00:02<00:04,  9.13w/s, dev=1]model.layers.24.self_attn.q_proj.weight:  34%|███▍      | 20/59 [00:02<00:04,  9.13w/s, dev=1]model.layers.24.self_attn.rotary_emb.inv_freq:  36%|███▌      | 21/59 [00:02<00:04,  8.46w/s, dev=1]model.layers.24.self_attn.v_proj.weight:  37%|███▋      | 22/59 [00:02<00:04,  8.86w/s, dev=1]      model.layers.24.self_attn.v_proj.weight:  39%|███▉      | 23/59 [00:02<00:03,  9.23w/s, dev=1]model.layers.25.input_layernorm.weight:  39%|███▉      | 23/59 [00:02<00:03,  9.23w/s, dev=1] model.layers.25.mlp.down_proj.weight:  41%|████      | 24/59 [00:02<00:03,  9.63w/s, dev=1]  model.layers.25.mlp.gate_proj.weight:  42%|████▏     | 25/59 [00:02<00:03,  9.39w/s, dev=1]model.layers.25.mlp.gate_proj.weight:  44%|████▍     | 26/59 [00:02<00:03,  9.19w/s, dev=1]model.layers.25.mlp.up_proj.weight:  44%|████▍     | 26/59 [00:02<00:03,  9.19w/s, dev=1]  model.layers.25.post_attention_layernorm.weight:  46%|████▌     | 27/59 [00:02<00:03,  9.02w/s, dev=1]model.layers.25.self_attn.k_proj.weight:  47%|████▋     | 28/59 [00:02<00:03,  9.35w/s, dev=1]        model.layers.25.self_attn.k_proj.weight:  49%|████▉     | 29/59 [00:03<00:03,  9.30w/s, dev=1]model.layers.25.self_attn.o_proj.weight:  49%|████▉     | 29/59 [00:03<00:03,  9.30w/s, dev=1]model.layers.25.self_attn.q_proj.weight:  51%|█████     | 30/59 [00:03<00:03,  9.47w/s, dev=1]model.layers.25.self_attn.rotary_emb.inv_freq:  53%|█████▎    | 31/59 [00:03<00:02,  9.63w/s, dev=1]model.layers.25.self_attn.v_proj.weight:  54%|█████▍    | 32/59 [00:03<00:02,  9.94w/s, dev=1]      model.layers.25.self_attn.v_proj.weight:  56%|█████▌    | 33/59 [00:03<00:02, 10.19w/s, dev=1]model.layers.26.input_layernorm.weight:  56%|█████▌    | 33/59 [00:03<00:02, 10.19w/s, dev=1] model.layers.26.mlp.down_proj.weight:  58%|█████▊    | 34/59 [00:03<00:02, 10.50w/s, dev=1]  model.layers.26.mlp.gate_proj.weight:  59%|█████▉    | 35/59 [00:03<00:02, 10.25w/s, dev=1]model.layers.26.mlp.up_proj.weight:  61%|██████    | 36/59 [00:03<00:02,  9.70w/s, dev=1]  model.layers.26.mlp.up_proj.weight:  63%|██████▎   | 37/59 [00:03<00:02,  9.56w/s, dev=1]model.layers.26.post_attention_layernorm.weight:  63%|██████▎   | 37/59 [00:03<00:02,  9.56w/s, dev=1]model.layers.26.self_attn.k_proj.weight:  64%|██████▍   | 38/59 [00:03<00:02,  9.81w/s, dev=1]        model.layers.26.self_attn.o_proj.weight:  66%|██████▌   | 39/59 [00:03<00:02,  9.88w/s, dev=1]model.layers.26.self_attn.q_proj.weight:  68%|██████▊   | 40/59 [00:04<00:01, 10.00w/s, dev=1]model.layers.26.self_attn.q_proj.weight:  69%|██████▉   | 41/59 [00:04<00:01, 10.11w/s, dev=1]model.layers.26.self_attn.rotary_emb.inv_freq:  69%|██████▉   | 41/59 [00:04<00:01, 10.11w/s, dev=1]model.layers.26.self_attn.v_proj.weight:  71%|███████   | 42/59 [00:04<00:01, 10.36w/s, dev=1]      model.layers.27.input_layernorm.weight:  73%|███████▎  | 43/59 [00:04<00:01, 10.57w/s, dev=1] model.layers.27.mlp.down_proj.weight:  75%|███████▍  | 44/59 [00:04<00:01, 10.81w/s, dev=1]  model.layers.27.mlp.down_proj.weight:  76%|███████▋  | 45/59 [00:04<00:01, 10.61w/s, dev=1]model.layers.27.mlp.gate_proj.weight:  76%|███████▋  | 45/59 [00:04<00:01, 10.61w/s, dev=1]model.layers.27.mlp.up_proj.weight:  78%|███████▊  | 46/59 [00:04<00:01, 10.14w/s, dev=1]  model.layers.27.post_attention_layernorm.weight:  80%|███████▉  | 47/59 [00:04<00:01, 10.00w/s, dev=1]model.layers.27.self_attn.k_proj.weight:  81%|████████▏ | 48/59 [00:04<00:01, 10.21w/s, dev=1]        model.layers.27.self_attn.k_proj.weight:  83%|████████▎ | 49/59 [00:04<00:00, 10.13w/s, dev=1]model.layers.27.self_attn.o_proj.weight:  83%|████████▎ | 49/59 [00:04<00:00, 10.13w/s, dev=1]model.layers.27.self_attn.q_proj.weight:  85%|████████▍ | 50/59 [00:04<00:00, 10.23w/s, dev=1]model.layers.27.self_attn.rotary_emb.inv_freq:  86%|████████▋ | 51/59 [00:04<00:00, 10.32w/s, dev=1]model.layers.27.self_attn.v_proj.weight:  88%|████████▊ | 52/59 [00:04<00:00, 10.52w/s, dev=1]      model.layers.27.self_attn.v_proj.weight:  90%|████████▉ | 53/59 [00:04<00:00, 10.70w/s, dev=1]model.layers.28.mlp.gate_proj.weight:  90%|████████▉ | 53/59 [00:04<00:00, 10.70w/s, dev=1]   model.layers.28.self_attn.k_proj.weight:  92%|█████████▏| 54/59 [00:05<00:00, 10.51w/s, dev=1]model.layers.28.self_attn.o_proj.weight:  93%|█████████▎| 55/59 [00:05<00:00, 10.18w/s, dev=1]model.layers.28.self_attn.q_proj.weight:  95%|█████████▍| 56/59 [00:05<00:00, 10.26w/s, dev=1]model.layers.28.self_attn.q_proj.weight:  97%|█████████▋| 57/59 [00:05<00:00, 10.34w/s, dev=1]model.layers.28.self_attn.rotary_emb.inv_freq:  97%|█████████▋| 57/59 [00:05<00:00, 10.34w/s, dev=1]model.layers.28.self_attn.v_proj.weight:  98%|█████████▊| 58/59 [00:05<00:00, 10.52w/s, dev=1]                                                                                                      0%|          | 0/59 [00:00<?, ?w/s]model.layers.28.input_layernorm.weight:   0%|          | 0/59 [00:00<?, ?w/s, dev=1]model.layers.28.mlp.down_proj.weight:   2%|▏         | 1/59 [00:00<00:00, 1290.56w/s, dev=1]model.layers.28.mlp.down_proj.weight:   3%|▎         | 2/59 [00:00<00:10,  5.39w/s, dev=1]  model.layers.28.mlp.up_proj.weight:   3%|▎         | 2/59 [00:00<00:10,  5.38w/s, dev=1]  model.layers.28.post_attention_layernorm.weight:   5%|▌         | 3/59 [00:00<00:10,  5.60w/s, dev=1]model.layers.28.post_attention_layernorm.weight:   7%|▋         | 4/59 [00:00<00:07,  7.46w/s, dev=1]model.layers.29.input_layernorm.weight:   7%|▋         | 4/59 [00:00<00:07,  7.46w/s, dev=1]         model.layers.29.mlp.down_proj.weight:   8%|▊         | 5/59 [00:00<00:05,  9.32w/s, dev=1]  model.layers.29.mlp.down_proj.weight:  10%|█         | 6/59 [00:00<00:06,  8.63w/s, dev=1]model.layers.29.mlp.gate_proj.weight:  10%|█         | 6/59 [00:00<00:06,  8.63w/s, dev=1]model.layers.29.mlp.up_proj.weight:  12%|█▏        | 7/59 [00:00<00:06,  7.55w/s, dev=1]  model.layers.29.mlp.up_proj.weight:  14%|█▎        | 8/59 [00:01<00:06,  7.38w/s, dev=1]model.layers.29.post_attention_layernorm.weight:  14%|█▎        | 8/59 [00:01<00:06,  7.38w/s, dev=1]model.layers.29.self_attn.k_proj.weight:  15%|█▌        | 9/59 [00:01<00:06,  8.30w/s, dev=1]        model.layers.29.self_attn.k_proj.weight:  17%|█▋        | 10/59 [00:01<00:06,  7.99w/s, dev=1]model.layers.29.self_attn.o_proj.weight:  17%|█▋        | 10/59 [00:01<00:06,  7.98w/s, dev=1]model.layers.29.self_attn.q_proj.weight:  19%|█▊        | 11/59 [00:01<00:05,  8.44w/s, dev=1]model.layers.29.self_attn.rotary_emb.inv_freq:  20%|██        | 12/59 [00:01<00:05,  8.89w/s, dev=1]model.layers.29.self_attn.v_proj.weight:  22%|██▏       | 13/59 [00:01<00:04,  9.63w/s, dev=1]      model.layers.29.self_attn.v_proj.weight:  24%|██▎       | 14/59 [00:01<00:04, 10.31w/s, dev=1]model.layers.30.input_layernorm.weight:  24%|██▎       | 14/59 [00:01<00:04, 10.31w/s, dev=1] model.layers.30.mlp.down_proj.weight:  25%|██▌       | 15/59 [00:01<00:03, 11.05w/s, dev=1]  model.layers.30.mlp.gate_proj.weight:  27%|██▋       | 16/59 [00:01<00:04, 10.54w/s, dev=1]model.layers.30.mlp.up_proj.weight:  29%|██▉       | 17/59 [00:01<00:04, 10.17w/s, dev=1]  model.layers.30.mlp.up_proj.weight:  31%|███       | 18/59 [00:01<00:04,  9.59w/s, dev=1]model.layers.30.post_attention_layernorm.weight:  31%|███       | 18/59 [00:01<00:04,  9.59w/s, dev=1]model.layers.30.self_attn.k_proj.weight:  32%|███▏      | 19/59 [00:01<00:03, 10.12w/s, dev=1]        model.layers.30.self_attn.o_proj.weight:  34%|███▍      | 20/59 [00:01<00:03, 10.60w/s, dev=1]model.layers.30.self_attn.q_proj.weight:  36%|███▌      | 21/59 [00:01<00:03, 10.86w/s, dev=1]model.layers.30.self_attn.q_proj.weight:  37%|███▋      | 22/59 [00:01<00:03, 11.11w/s, dev=1]model.layers.30.self_attn.rotary_emb.inv_freq:  37%|███▋      | 22/59 [00:01<00:03, 11.11w/s, dev=1]model.layers.30.self_attn.v_proj.weight:  39%|███▉      | 23/59 [00:01<00:03, 11.61w/s, dev=1]      model.layers.31.input_layernorm.weight:  41%|████      | 24/59 [00:01<00:02, 12.06w/s, dev=1] model.layers.31.mlp.down_proj.weight:  42%|████▏     | 25/59 [00:01<00:02, 12.56w/s, dev=1]  model.layers.31.mlp.down_proj.weight:  44%|████▍     | 26/59 [00:02<00:02, 11.99w/s, dev=1]model.layers.31.mlp.gate_proj.weight:  44%|████▍     | 26/59 [00:02<00:02, 11.99w/s, dev=1]model.layers.31.mlp.up_proj.weight:  46%|████▌     | 27/59 [00:02<00:02, 10.78w/s, dev=1]  model.layers.31.post_attention_layernorm.weight:  47%|████▋     | 28/59 [00:02<00:02, 10.46w/s, dev=1]model.layers.31.self_attn.k_proj.weight:  49%|████▉     | 29/59 [00:02<00:02, 10.83w/s, dev=1]        model.layers.31.self_attn.k_proj.weight:  51%|█████     | 30/59 [00:02<00:02, 11.16w/s, dev=1]model.layers.31.self_attn.o_proj.weight:  51%|█████     | 30/59 [00:02<00:02, 11.16w/s, dev=1]model.layers.31.self_attn.q_proj.weight:  53%|█████▎    | 31/59 [00:02<00:02, 11.33w/s, dev=1]model.layers.31.self_attn.rotary_emb.inv_freq:  54%|█████▍    | 32/59 [00:03<00:02, 10.59w/s, dev=1]model.layers.31.self_attn.v_proj.weight:  56%|█████▌    | 33/59 [00:03<00:02, 10.92w/s, dev=1]      model.layers.31.self_attn.v_proj.weight:  58%|█████▊    | 34/59 [00:03<00:02, 11.22w/s, dev=1]model.layers.32.input_layernorm.weight:  58%|█████▊    | 34/59 [00:03<00:02, 11.22w/s, dev=1] model.layers.32.mlp.down_proj.weight:  59%|█████▉    | 35/59 [00:03<00:02, 11.55w/s, dev=1]  model.layers.32.mlp.gate_proj.weight:  61%|██████    | 36/59 [00:03<00:02, 11.22w/s, dev=1]model.layers.32.mlp.up_proj.weight:  63%|██████▎   | 37/59 [00:03<00:01, 11.01w/s, dev=1]  model.layers.32.mlp.up_proj.weight:  64%|██████▍   | 38/59 [00:03<00:02, 10.36w/s, dev=1]model.layers.32.post_attention_layernorm.weight:  64%|██████▍   | 38/59 [00:03<00:02, 10.36w/s, dev=1]model.layers.32.self_attn.k_proj.weight:  66%|██████▌   | 39/59 [00:03<00:01, 10.63w/s, dev=1]        model.layers.32.self_attn.o_proj.weight:  68%|██████▊   | 40/59 [00:03<00:01, 10.87w/s, dev=1]model.layers.32.self_attn.q_proj.weight:  69%|██████▉   | 41/59 [00:03<00:01, 10.99w/s, dev=1]model.layers.32.self_attn.q_proj.weight:  71%|███████   | 42/59 [00:03<00:01, 11.12w/s, dev=1]model.layers.32.self_attn.rotary_emb.inv_freq:  71%|███████   | 42/59 [00:03<00:01, 11.11w/s, dev=1]model.layers.32.self_attn.v_proj.weight:  73%|███████▎  | 43/59 [00:03<00:01, 11.38w/s, dev=1]      model.layers.33.input_layernorm.weight:  75%|███████▍  | 44/59 [00:03<00:01, 11.62w/s, dev=1] model.layers.33.mlp.down_proj.weight:  76%|███████▋  | 45/59 [00:03<00:01, 11.88w/s, dev=1]  model.layers.33.mlp.down_proj.weight:  78%|███████▊  | 46/59 [00:03<00:01, 11.65w/s, dev=1]model.layers.33.mlp.gate_proj.weight:  78%|███████▊  | 46/59 [00:03<00:01, 11.65w/s, dev=1]model.layers.33.mlp.up_proj.weight:  80%|███████▉  | 47/59 [00:04<00:01, 10.91w/s, dev=1]  model.layers.33.post_attention_layernorm.weight:  81%|████████▏ | 48/59 [00:04<00:01, 10.75w/s, dev=1]model.layers.33.self_attn.k_proj.weight:  83%|████████▎ | 49/59 [00:04<00:00, 10.97w/s, dev=1]        model.layers.33.self_attn.k_proj.weight:  85%|████████▍ | 50/59 [00:04<00:00, 11.18w/s, dev=1]model.layers.33.self_attn.o_proj.weight:  85%|████████▍ | 50/59 [00:04<00:00, 11.18w/s, dev=1]model.layers.33.self_attn.q_proj.weight:  86%|████████▋ | 51/59 [00:04<00:00, 11.29w/s, dev=1]model.layers.33.self_attn.rotary_emb.inv_freq:  88%|████████▊ | 52/59 [00:04<00:00, 11.40w/s, dev=1]model.layers.33.self_attn.v_proj.weight:  90%|████████▉ | 53/59 [00:04<00:00, 11.62w/s, dev=1]      model.layers.34.self_attn.k_proj.weight:  92%|█████████▏| 54/59 [00:04<00:00, 11.82w/s, dev=1]model.layers.34.self_attn.k_proj.weight:  93%|█████████▎| 55/59 [00:04<00:00, 12.02w/s, dev=1]model.layers.34.self_attn.o_proj.weight:  93%|█████████▎| 55/59 [00:04<00:00, 12.02w/s, dev=1]model.layers.34.self_attn.q_proj.weight:  95%|█████████▍| 56/59 [00:04<00:00, 12.12w/s, dev=1]model.layers.34.self_attn.rotary_emb.inv_freq:  97%|█████████▋| 57/59 [00:04<00:00, 12.20w/s, dev=1]model.layers.34.self_attn.v_proj.weight:  98%|█████████▊| 58/59 [00:04<00:00, 12.41w/s, dev=1]                                                                                                      0%|          | 0/55 [00:00<?, ?w/s]model.layers.34.input_layernorm.weight:   0%|          | 0/55 [00:00<?, ?w/s, dev=1]model.layers.34.mlp.down_proj.weight:   2%|▏         | 1/55 [00:00<00:00, 1323.12w/s, dev=1]model.layers.34.mlp.down_proj.weight:   4%|▎         | 2/55 [00:00<00:04, 12.84w/s, dev=1]  model.layers.34.mlp.gate_proj.weight:   4%|▎         | 2/55 [00:00<00:04, 12.82w/s, dev=1]model.layers.34.mlp.up_proj.weight:   5%|▌         | 3/55 [00:00<00:05,  9.28w/s, dev=1]  model.layers.34.mlp.up_proj.weight:   7%|▋         | 4/55 [00:00<00:06,  8.18w/s, dev=1]model.layers.34.post_attention_layernorm.weight:   7%|▋         | 4/55 [00:00<00:06,  8.18w/s, dev=1]model.layers.35.input_layernorm.weight:   9%|▉         | 5/55 [00:00<00:04, 10.21w/s, dev=1]         model.layers.35.mlp.down_proj.weight:  11%|█         | 6/55 [00:00<00:04, 12.25w/s, dev=1]  model.layers.35.mlp.down_proj.weight:  13%|█▎        | 7/55 [00:00<00:04, 10.53w/s, dev=1]model.layers.35.mlp.gate_proj.weight:  13%|█▎        | 7/55 [00:00<00:04, 10.53w/s, dev=1]model.layers.35.mlp.up_proj.weight:  15%|█▍        | 8/55 [00:00<00:04,  9.73w/s, dev=1]  model.layers.35.post_attention_layernorm.weight:  16%|█▋        | 9/55 [00:00<00:05,  9.17w/s, dev=1]model.layers.35.post_attention_layernorm.weight:  18%|█▊        | 10/55 [00:00<00:04, 10.18w/s, dev=1]model.layers.35.self_attn.k_proj.weight:  18%|█▊        | 10/55 [00:00<00:04, 10.18w/s, dev=1]        model.layers.35.self_attn.o_proj.weight:  20%|██        | 11/55 [00:00<00:03, 11.13w/s, dev=1]model.layers.35.self_attn.q_proj.weight:  22%|██▏       | 12/55 [00:01<00:03, 11.56w/s, dev=1]model.layers.35.self_attn.q_proj.weight:  24%|██▎       | 13/55 [00:01<00:03, 11.96w/s, dev=1]model.layers.35.self_attn.rotary_emb.inv_freq:  24%|██▎       | 13/55 [00:01<00:03, 11.95w/s, dev=1]model.layers.35.self_attn.v_proj.weight:  25%|██▌       | 14/55 [00:01<00:03, 12.87w/s, dev=1]      model.layers.36.input_layernorm.weight:  27%|██▋       | 15/55 [00:01<00:02, 13.69w/s, dev=1] model.layers.36.mlp.down_proj.weight:  29%|██▉       | 16/55 [00:01<00:02, 14.60w/s, dev=1]  model.layers.36.mlp.down_proj.weight:  31%|███       | 17/55 [00:01<00:02, 13.52w/s, dev=1]model.layers.36.mlp.gate_proj.weight:  31%|███       | 17/55 [00:01<00:02, 13.52w/s, dev=1]model.layers.36.mlp.up_proj.weight:  33%|███▎      | 18/55 [00:01<00:02, 12.74w/s, dev=1]  model.layers.36.post_attention_layernorm.weight:  35%|███▍      | 19/55 [00:01<00:02, 12.11w/s, dev=1]model.layers.36.self_attn.k_proj.weight:  36%|███▋      | 20/55 [00:01<00:02, 12.74w/s, dev=1]        model.layers.36.self_attn.k_proj.weight:  38%|███▊      | 21/55 [00:01<00:02, 13.32w/s, dev=1]model.layers.36.self_attn.o_proj.weight:  38%|███▊      | 21/55 [00:01<00:02, 13.31w/s, dev=1]model.layers.36.self_attn.q_proj.weight:  40%|████      | 22/55 [00:01<00:02, 13.55w/s, dev=1]model.layers.36.self_attn.rotary_emb.inv_freq:  42%|████▏     | 23/55 [00:01<00:02, 13.74w/s, dev=1]model.layers.36.self_attn.v_proj.weight:  44%|████▎     | 24/55 [00:01<00:02, 14.33w/s, dev=1]      model.layers.36.self_attn.v_proj.weight:  45%|████▌     | 25/55 [00:01<00:02, 14.86w/s, dev=1]model.layers.37.input_layernorm.weight:  45%|████▌     | 25/55 [00:01<00:02, 14.86w/s, dev=1] model.layers.37.mlp.down_proj.weight:  47%|████▋     | 26/55 [00:01<00:01, 15.45w/s, dev=1]  model.layers.37.mlp.gate_proj.weight:  49%|████▉     | 27/55 [00:01<00:01, 14.64w/s, dev=1]model.layers.37.mlp.up_proj.weight:  51%|█████     | 28/55 [00:02<00:01, 14.00w/s, dev=1]  model.layers.37.mlp.up_proj.weight:  53%|█████▎    | 29/55 [00:02<00:01, 13.37w/s, dev=1]model.layers.37.post_attention_layernorm.weight:  53%|█████▎    | 29/55 [00:02<00:01, 13.37w/s, dev=1]model.layers.37.self_attn.k_proj.weight:  55%|█████▍    | 30/55 [00:02<00:01, 13.82w/s, dev=1]        model.layers.37.self_attn.o_proj.weight:  56%|█████▋    | 31/55 [00:02<00:01, 14.24w/s, dev=1]model.layers.37.self_attn.q_proj.weight:  58%|█████▊    | 32/55 [00:02<00:01, 14.40w/s, dev=1]model.layers.37.self_attn.rotary_emb.inv_freq:  60%|██████    | 33/55 [00:02<00:01, 14.55w/s, dev=1]model.layers.37.self_attn.v_proj.weight:  62%|██████▏   | 34/55 [00:02<00:01, 14.99w/s, dev=1]      model.layers.37.self_attn.v_proj.weight:  64%|██████▎   | 35/55 [00:02<00:01, 15.39w/s, dev=1]model.layers.38.input_layernorm.weight:  64%|██████▎   | 35/55 [00:02<00:01, 15.39w/s, dev=1] model.layers.38.mlp.down_proj.weight:  65%|██████▌   | 36/55 [00:02<00:01, 15.82w/s, dev=1]  model.layers.38.mlp.gate_proj.weight:  67%|██████▋   | 37/55 [00:02<00:01, 15.21w/s, dev=1]model.layers.38.mlp.up_proj.weight:  69%|██████▉   | 38/55 [00:02<00:01, 14.59w/s, dev=1]  model.layers.38.post_attention_layernorm.weight:  71%|███████   | 39/55 [00:02<00:01, 14.11w/s, dev=1]model.layers.38.self_attn.k_proj.weight:  73%|███████▎  | 40/55 [00:02<00:01, 14.47w/s, dev=1]        model.layers.38.self_attn.k_proj.weight:  75%|███████▍  | 41/55 [00:02<00:00, 14.79w/s, dev=1]model.layers.38.self_attn.o_proj.weight:  75%|███████▍  | 41/55 [00:02<00:00, 14.79w/s, dev=1]model.layers.38.self_attn.q_proj.weight:  76%|███████▋  | 42/55 [00:02<00:00, 14.89w/s, dev=1]model.layers.38.self_attn.rotary_emb.inv_freq:  78%|███████▊  | 43/55 [00:02<00:00, 15.00w/s, dev=1]model.layers.38.self_attn.v_proj.weight:  80%|████████  | 44/55 [00:02<00:00, 15.34w/s, dev=1]      model.layers.39.input_layernorm.weight:  82%|████████▏ | 45/55 [00:02<00:00, 15.64w/s, dev=1] model.layers.39.mlp.down_proj.weight:  84%|████████▎ | 46/55 [00:02<00:00, 15.99w/s, dev=1]  model.layers.39.mlp.down_proj.weight:  85%|████████▌ | 47/55 [00:03<00:00, 15.41w/s, dev=1]model.layers.39.mlp.gate_proj.weight:  85%|████████▌ | 47/55 [00:03<00:00, 15.41w/s, dev=1]model.layers.39.mlp.up_proj.weight:  87%|████████▋ | 48/55 [00:03<00:00, 14.86w/s, dev=1]  model.layers.39.post_attention_layernorm.weight:  89%|████████▉ | 49/55 [00:03<00:00, 14.48w/s, dev=1]model.layers.39.self_attn.k_proj.weight:  91%|█████████ | 50/55 [00:03<00:00, 14.77w/s, dev=1]        model.layers.39.self_attn.o_proj.weight:  93%|█████████▎| 51/55 [00:03<00:00, 15.03w/s, dev=1]model.layers.39.self_attn.q_proj.weight:  95%|█████████▍| 52/55 [00:03<00:00, 15.11w/s, dev=1]model.layers.39.self_attn.q_proj.weight:  96%|█████████▋| 53/55 [00:03<00:00, 15.19w/s, dev=1]model.layers.39.self_attn.rotary_emb.inv_freq:  96%|█████████▋| 53/55 [00:03<00:00, 15.19w/s, dev=1]model.layers.39.self_attn.v_proj.weight:  98%|█████████▊| 54/55 [00:03<00:00, 15.47w/s, dev=1]                                                                                                      0%|          | 0/57 [00:00<?, ?w/s]model.layers.40.input_layernorm.weight:   0%|          | 0/57 [00:00<?, ?w/s, dev=1]model.layers.40.mlp.down_proj.weight:   2%|▏         | 1/57 [00:00<00:00, 1330.26w/s, dev=1]model.layers.40.mlp.down_proj.weight:   4%|▎         | 2/57 [00:00<00:04, 12.21w/s, dev=1]  model.layers.40.mlp.gate_proj.weight:   4%|▎         | 2/57 [00:00<00:04, 12.19w/s, dev=1]model.layers.40.mlp.up_proj.weight:   5%|▌         | 3/57 [00:00<00:05,  9.21w/s, dev=1]  model.layers.40.mlp.up_proj.weight:   7%|▋         | 4/57 [00:00<00:06,  8.27w/s, dev=1]model.layers.40.post_attention_layernorm.weight:   7%|▋         | 4/57 [00:00<00:06,  8.27w/s, dev=1]model.layers.40.self_attn.k_proj.weight:   9%|▉         | 5/57 [00:00<00:05, 10.33w/s, dev=1]        model.layers.40.self_attn.o_proj.weight:  11%|█         | 6/57 [00:00<00:04, 12.22w/s, dev=1]model.layers.40.self_attn.q_proj.weight:  12%|█▏        | 7/57 [00:00<00:03, 13.02w/s, dev=1]model.layers.40.self_attn.q_proj.weight:  14%|█▍        | 8/57 [00:00<00:03, 13.69w/s, dev=1]model.layers.40.self_attn.rotary_emb.inv_freq:  14%|█▍        | 8/57 [00:00<00:03, 13.68w/s, dev=1]model.layers.40.self_attn.v_proj.weight:  16%|█▌        | 9/57 [00:00<00:03, 15.38w/s, dev=1]      model.layers.41.input_layernorm.weight:  18%|█▊        | 10/57 [00:00<00:03, 15.20w/s, dev=2]model.layers.41.mlp.down_proj.weight:  19%|█▉        | 11/57 [00:00<00:02, 16.63w/s, dev=2]  model.layers.41.mlp.down_proj.weight:  21%|██        | 12/57 [00:00<00:03, 14.28w/s, dev=2]model.layers.41.mlp.gate_proj.weight:  21%|██        | 12/57 [00:00<00:03, 14.28w/s, dev=2]model.layers.41.mlp.up_proj.weight:  23%|██▎       | 13/57 [00:01<00:03, 12.89w/s, dev=2]  model.layers.41.post_attention_layernorm.weight:  25%|██▍       | 14/57 [00:01<00:03, 11.94w/s, dev=2]model.layers.41.self_attn.k_proj.weight:  26%|██▋       | 15/57 [00:01<00:03, 12.79w/s, dev=2]        model.layers.41.self_attn.k_proj.weight:  28%|██▊       | 16/57 [00:01<00:03, 13.57w/s, dev=2]model.layers.41.self_attn.o_proj.weight:  28%|██▊       | 16/57 [00:01<00:03, 13.56w/s, dev=2]model.layers.41.self_attn.q_proj.weight:  30%|██▉       | 17/57 [00:01<00:02, 13.87w/s, dev=2]model.layers.41.self_attn.rotary_emb.inv_freq:  32%|███▏      | 18/57 [00:01<00:02, 14.13w/s, dev=2]model.layers.41.self_attn.v_proj.weight:  33%|███▎      | 19/57 [00:01<00:02, 14.91w/s, dev=2]      model.layers.41.self_attn.v_proj.weight:  35%|███▌      | 20/57 [00:01<00:02, 15.61w/s, dev=2]model.layers.42.input_layernorm.weight:  35%|███▌      | 20/57 [00:01<00:02, 15.61w/s, dev=2] model.layers.42.mlp.down_proj.weight:  37%|███▋      | 21/57 [00:01<00:02, 16.39w/s, dev=2]  model.layers.42.mlp.gate_proj.weight:  39%|███▊      | 22/57 [00:01<00:02, 15.17w/s, dev=2]model.layers.42.mlp.up_proj.weight:  40%|████      | 23/57 [00:01<00:02, 14.15w/s, dev=2]  model.layers.42.mlp.up_proj.weight:  42%|████▏     | 24/57 [00:01<00:02, 13.42w/s, dev=2]model.layers.42.post_attention_layernorm.weight:  42%|████▏     | 24/57 [00:01<00:02, 13.42w/s, dev=2]model.layers.42.self_attn.k_proj.weight:  44%|████▍     | 25/57 [00:01<00:02, 13.97w/s, dev=2]        model.layers.42.self_attn.o_proj.weight:  46%|████▌     | 26/57 [00:01<00:02, 14.48w/s, dev=2]model.layers.42.self_attn.q_proj.weight:  47%|████▋     | 27/57 [00:01<00:02, 14.68w/s, dev=2]model.layers.42.self_attn.rotary_emb.inv_freq:  49%|████▉     | 28/57 [00:01<00:01, 14.85w/s, dev=2]model.layers.42.self_attn.v_proj.weight:  51%|█████     | 29/57 [00:01<00:01, 15.38w/s, dev=2]      model.layers.42.self_attn.v_proj.weight:  53%|█████▎    | 30/57 [00:01<00:01, 15.84w/s, dev=2]model.layers.43.input_layernorm.weight:  53%|█████▎    | 30/57 [00:01<00:01, 15.84w/s, dev=2] model.layers.43.mlp.down_proj.weight:  54%|█████▍    | 31/57 [00:01<00:01, 16.37w/s, dev=2]  model.layers.43.mlp.gate_proj.weight:  56%|█████▌    | 32/57 [00:02<00:01, 15.58w/s, dev=2]model.layers.43.mlp.up_proj.weight:  58%|█████▊    | 33/57 [00:02<00:01, 14.82w/s, dev=2]  model.layers.43.post_attention_layernorm.weight:  60%|█████▉    | 34/57 [00:02<00:01, 14.10w/s, dev=2]model.layers.43.self_attn.k_proj.weight:  61%|██████▏   | 35/57 [00:02<00:01, 14.51w/s, dev=2]        model.layers.43.self_attn.k_proj.weight:  63%|██████▎   | 36/57 [00:02<00:01, 14.87w/s, dev=2]model.layers.43.self_attn.o_proj.weight:  63%|██████▎   | 36/57 [00:02<00:01, 14.87w/s, dev=2]model.layers.43.self_attn.q_proj.weight:  65%|██████▍   | 37/57 [00:02<00:01, 14.95w/s, dev=2]model.layers.43.self_attn.rotary_emb.inv_freq:  67%|██████▋   | 38/57 [00:02<00:01, 15.01w/s, dev=2]model.layers.43.self_attn.v_proj.weight:  68%|██████▊   | 39/57 [00:02<00:01, 15.40w/s, dev=2]      model.layers.44.input_layernorm.weight:  70%|███████   | 40/57 [00:02<00:01, 15.75w/s, dev=2] model.layers.44.mlp.down_proj.weight:  72%|███████▏  | 41/57 [00:02<00:00, 16.14w/s, dev=2]  model.layers.44.mlp.down_proj.weight:  74%|███████▎  | 42/57 [00:02<00:00, 15.44w/s, dev=2]model.layers.44.mlp.gate_proj.weight:  74%|███████▎  | 42/57 [00:02<00:00, 15.44w/s, dev=2]model.layers.44.mlp.up_proj.weight:  75%|███████▌  | 43/57 [00:02<00:00, 14.93w/s, dev=2]  model.layers.44.post_attention_layernorm.weight:  77%|███████▋  | 44/57 [00:03<00:00, 14.47w/s, dev=2]model.layers.44.self_attn.k_proj.weight:  79%|███████▉  | 45/57 [00:03<00:00, 14.79w/s, dev=2]        model.layers.44.self_attn.o_proj.weight:  81%|████████  | 46/57 [00:03<00:00, 15.09w/s, dev=2]model.layers.44.self_attn.q_proj.weight:  82%|████████▏ | 47/57 [00:03<00:00, 15.19w/s, dev=2]model.layers.44.self_attn.q_proj.weight:  84%|████████▍ | 48/57 [00:03<00:00, 15.29w/s, dev=2]model.layers.44.self_attn.rotary_emb.inv_freq:  84%|████████▍ | 48/57 [00:03<00:00, 15.29w/s, dev=2]model.layers.44.self_attn.v_proj.weight:  86%|████████▌ | 49/57 [00:03<00:00, 15.60w/s, dev=2]      model.layers.45.mlp.down_proj.weight:  88%|████████▊ | 50/57 [00:03<00:00, 15.88w/s, dev=2]   model.layers.45.mlp.gate_proj.weight:  89%|████████▉ | 51/57 [00:03<00:00, 15.42w/s, dev=2]model.layers.45.self_attn.k_proj.weight:  91%|█████████ | 52/57 [00:03<00:00, 14.97w/s, dev=2]model.layers.45.self_attn.o_proj.weight:  93%|█████████▎| 53/57 [00:03<00:00, 15.22w/s, dev=2]model.layers.45.self_attn.o_proj.weight:  95%|█████████▍| 54/57 [00:03<00:00, 15.26w/s, dev=2]model.layers.45.self_attn.q_proj.weight:  95%|█████████▍| 54/57 [00:03<00:00, 15.26w/s, dev=2]model.layers.45.self_attn.rotary_emb.inv_freq:  96%|█████████▋| 55/57 [00:03<00:00, 15.33w/s, dev=2]model.layers.45.self_attn.v_proj.weight:  98%|█████████▊| 56/57 [00:03<00:00, 15.60w/s, dev=2]                                                                                                      0%|          | 0/59 [00:00<?, ?w/s]model.layers.45.input_layernorm.weight:   0%|          | 0/59 [00:00<?, ?w/s, dev=2]model.layers.45.mlp.up_proj.weight:   2%|▏         | 1/59 [00:00<00:00, 1116.40w/s, dev=2]model.layers.45.mlp.up_proj.weight:   3%|▎         | 2/59 [00:00<00:04, 12.87w/s, dev=2]  model.layers.45.post_attention_layernorm.weight:   3%|▎         | 2/59 [00:00<00:04, 12.85w/s, dev=2]model.layers.46.input_layernorm.weight:   5%|▌         | 3/59 [00:00<00:02, 19.22w/s, dev=2]         model.layers.46.mlp.down_proj.weight:   7%|▋         | 4/59 [00:00<00:02, 25.59w/s, dev=2]  model.layers.46.mlp.down_proj.weight:   8%|▊         | 5/59 [00:00<00:03, 15.71w/s, dev=2]model.layers.46.mlp.gate_proj.weight:   8%|▊         | 5/59 [00:00<00:03, 15.69w/s, dev=2]model.layers.46.mlp.up_proj.weight:  10%|█         | 6/59 [00:00<00:04, 12.48w/s, dev=2]  model.layers.46.post_attention_layernorm.weight:  12%|█▏        | 7/59 [00:00<00:04, 10.97w/s, dev=2]model.layers.46.post_attention_layernorm.weight:  14%|█▎        | 8/59 [00:00<00:04, 12.53w/s, dev=2]model.layers.46.self_attn.k_proj.weight:  14%|█▎        | 8/59 [00:00<00:04, 12.53w/s, dev=2]        model.layers.46.self_attn.o_proj.weight:  15%|█▌        | 9/59 [00:00<00:03, 13.95w/s, dev=2]model.layers.46.self_attn.q_proj.weight:  17%|█▋        | 10/59 [00:00<00:03, 14.46w/s, dev=2]model.layers.46.self_attn.q_proj.weight:  19%|█▊        | 11/59 [00:00<00:03, 14.88w/s, dev=2]model.layers.46.self_attn.rotary_emb.inv_freq:  19%|█▊        | 11/59 [00:00<00:03, 14.87w/s, dev=2]model.layers.46.self_attn.v_proj.weight:  20%|██        | 12/59 [00:00<00:02, 16.21w/s, dev=2]      model.layers.47.input_layernorm.weight:  22%|██▏       | 13/59 [00:00<00:02, 17.38w/s, dev=2] model.layers.47.mlp.down_proj.weight:  24%|██▎       | 14/59 [00:00<00:02, 18.71w/s, dev=2]  model.layers.47.mlp.down_proj.weight:  25%|██▌       | 15/59 [00:00<00:02, 16.46w/s, dev=2]model.layers.47.mlp.gate_proj.weight:  25%|██▌       | 15/59 [00:00<00:02, 16.46w/s, dev=2]model.layers.47.mlp.up_proj.weight:  27%|██▋       | 16/59 [00:01<00:02, 14.92w/s, dev=2]  model.layers.47.post_attention_layernorm.weight:  29%|██▉       | 17/59 [00:01<00:03, 13.77w/s, dev=2]model.layers.47.self_attn.k_proj.weight:  31%|███       | 18/59 [00:01<00:02, 14.58w/s, dev=2]        model.layers.47.self_attn.k_proj.weight:  32%|███▏      | 19/59 [00:01<00:02, 15.28w/s, dev=2]model.layers.47.self_attn.o_proj.weight:  32%|███▏      | 19/59 [00:01<00:02, 15.28w/s, dev=2]model.layers.47.self_attn.q_proj.weight:  34%|███▍      | 20/59 [00:01<00:02, 15.47w/s, dev=2]model.layers.47.self_attn.rotary_emb.inv_freq:  36%|███▌      | 21/59 [00:01<00:02, 15.65w/s, dev=2]model.layers.47.self_attn.v_proj.weight:  37%|███▋      | 22/59 [00:01<00:02, 16.38w/s, dev=2]      model.layers.47.self_attn.v_proj.weight:  39%|███▉      | 23/59 [00:01<00:02, 16.91w/s, dev=2]model.layers.48.input_layernorm.weight:  39%|███▉      | 23/59 [00:01<00:02, 16.91w/s, dev=2] model.layers.48.mlp.down_proj.weight:  41%|████      | 24/59 [00:01<00:01, 17.64w/s, dev=2]  model.layers.48.mlp.gate_proj.weight:  42%|████▏     | 25/59 [00:01<00:02, 16.43w/s, dev=2]model.layers.48.mlp.up_proj.weight:  44%|████▍     | 26/59 [00:01<00:02, 15.51w/s, dev=2]  model.layers.48.mlp.up_proj.weight:  46%|████▌     | 27/59 [00:01<00:02, 14.69w/s, dev=2]model.layers.48.post_attention_layernorm.weight:  46%|████▌     | 27/59 [00:01<00:02, 14.69w/s, dev=2]model.layers.48.self_attn.k_proj.weight:  47%|████▋     | 28/59 [00:01<00:02, 15.23w/s, dev=2]        model.layers.48.self_attn.o_proj.weight:  49%|████▉     | 29/59 [00:01<00:01, 15.70w/s, dev=2]model.layers.48.self_attn.q_proj.weight:  51%|█████     | 30/59 [00:01<00:01, 15.83w/s, dev=2]model.layers.48.self_attn.q_proj.weight:  53%|█████▎    | 31/59 [00:01<00:01, 15.96w/s, dev=2]model.layers.48.self_attn.rotary_emb.inv_freq:  53%|█████▎    | 31/59 [00:01<00:01, 15.95w/s, dev=2]model.layers.48.self_attn.v_proj.weight:  54%|█████▍    | 32/59 [00:01<00:01, 16.47w/s, dev=2]      model.layers.49.input_layernorm.weight:  56%|█████▌    | 33/59 [00:01<00:01, 16.92w/s, dev=2] model.layers.49.mlp.down_proj.weight:  58%|█████▊    | 34/59 [00:01<00:01, 17.43w/s, dev=2]  model.layers.49.mlp.down_proj.weight:  59%|█████▉    | 35/59 [00:02<00:01, 16.58w/s, dev=2]model.layers.49.mlp.gate_proj.weight:  59%|█████▉    | 35/59 [00:02<00:01, 16.57w/s, dev=2]model.layers.49.mlp.up_proj.weight:  61%|██████    | 36/59 [00:02<00:01, 15.87w/s, dev=2]  model.layers.49.post_attention_layernorm.weight:  63%|██████▎   | 37/59 [00:02<00:01, 15.24w/s, dev=2]model.layers.49.self_attn.k_proj.weight:  64%|██████▍   | 38/59 [00:02<00:01, 15.65w/s, dev=2]        model.layers.49.self_attn.k_proj.weight:  66%|██████▌   | 39/59 [00:02<00:01, 16.02w/s, dev=2]model.layers.49.self_attn.o_proj.weight:  66%|██████▌   | 39/59 [00:02<00:01, 16.02w/s, dev=2]model.layers.49.self_attn.q_proj.weight:  68%|██████▊   | 40/59 [00:02<00:01, 16.12w/s, dev=2]model.layers.49.self_attn.rotary_emb.inv_freq:  69%|██████▉   | 41/59 [00:02<00:01, 16.21w/s, dev=2]model.layers.49.self_attn.v_proj.weight:  71%|███████   | 42/59 [00:02<00:01, 16.60w/s, dev=2]      model.layers.49.self_attn.v_proj.weight:  73%|███████▎  | 43/59 [00:02<00:00, 16.94w/s, dev=2]model.layers.50.input_layernorm.weight:  73%|███████▎  | 43/59 [00:02<00:00, 16.94w/s, dev=2] model.layers.50.mlp.down_proj.weight:  75%|███████▍  | 44/59 [00:02<00:00, 17.33w/s, dev=2]  model.layers.50.mlp.gate_proj.weight:  76%|███████▋  | 45/59 [00:02<00:00, 16.66w/s, dev=2]model.layers.50.mlp.up_proj.weight:  78%|███████▊  | 46/59 [00:02<00:00, 16.09w/s, dev=2]  model.layers.50.mlp.up_proj.weight:  80%|███████▉  | 47/59 [00:03<00:00, 15.59w/s, dev=2]model.layers.50.post_attention_layernorm.weight:  80%|███████▉  | 47/59 [00:03<00:00, 15.59w/s, dev=2]model.layers.50.self_attn.k_proj.weight:  81%|████████▏ | 48/59 [00:03<00:00, 15.92w/s, dev=2]        model.layers.50.self_attn.o_proj.weight:  83%|████████▎ | 49/59 [00:03<00:00, 16.20w/s, dev=2]model.layers.50.self_attn.q_proj.weight:  85%|████████▍ | 50/59 [00:03<00:00, 16.27w/s, dev=2]model.layers.50.self_attn.q_proj.weight:  86%|████████▋ | 51/59 [00:03<00:00, 16.34w/s, dev=2]model.layers.50.self_attn.rotary_emb.inv_freq:  86%|████████▋ | 51/59 [00:03<00:00, 16.34w/s, dev=2]model.layers.50.self_attn.v_proj.weight:  88%|████████▊ | 52/59 [00:03<00:00, 16.66w/s, dev=2]      model.layers.51.mlp.gate_proj.weight:  90%|████████▉ | 53/59 [00:03<00:00, 16.95w/s, dev=2]   model.layers.51.self_attn.k_proj.weight:  92%|█████████▏| 54/59 [00:03<00:00, 16.44w/s, dev=2]model.layers.51.self_attn.k_proj.weight:  93%|█████████▎| 55/59 [00:03<00:00, 16.71w/s, dev=2]model.layers.51.self_attn.o_proj.weight:  93%|█████████▎| 55/59 [00:03<00:00, 16.71w/s, dev=2]model.layers.51.self_attn.q_proj.weight:  95%|█████████▍| 56/59 [00:03<00:00, 16.78w/s, dev=2]model.layers.51.self_attn.rotary_emb.inv_freq:  97%|█████████▋| 57/59 [00:03<00:00, 16.83w/s, dev=2]model.layers.51.self_attn.v_proj.weight:  98%|█████████▊| 58/59 [00:03<00:00, 17.13w/s, dev=2]      model.layers.51.self_attn.v_proj.weight: 100%|██████████| 59/59 [00:03<00:00, 17.39w/s, dev=2]                                                                                                0%|          | 0/59 [00:00<?, ?w/s]model.layers.51.input_layernorm.weight:   0%|          | 0/59 [00:00<?, ?w/s, dev=2]model.layers.51.mlp.down_proj.weight:   2%|▏         | 1/59 [00:00<00:00, 1132.68w/s, dev=2]model.layers.51.mlp.down_proj.weight:   3%|▎         | 2/59 [00:00<00:04, 12.05w/s, dev=2]  model.layers.51.mlp.up_proj.weight:   3%|▎         | 2/59 [00:00<00:04, 12.03w/s, dev=2]  model.layers.51.post_attention_layernorm.weight:   5%|▌         | 3/59 [00:00<00:05,  9.43w/s, dev=2]model.layers.51.post_attention_layernorm.weight:   7%|▋         | 4/59 [00:00<00:04, 12.55w/s, dev=2]model.layers.52.input_layernorm.weight:   7%|▋         | 4/59 [00:00<00:04, 12.55w/s, dev=2]         model.layers.52.mlp.down_proj.weight:   8%|▊         | 5/59 [00:00<00:03, 15.68w/s, dev=2]  model.layers.52.mlp.down_proj.weight:  10%|█         | 6/59 [00:00<00:04, 12.63w/s, dev=2]model.layers.52.mlp.gate_proj.weight:  10%|█         | 6/59 [00:00<00:04, 12.62w/s, dev=2]model.layers.52.mlp.up_proj.weight:  12%|█▏        | 7/59 [00:00<00:04, 11.08w/s, dev=2]  model.layers.52.mlp.up_proj.weight:  14%|█▎        | 8/59 [00:00<00:05, 10.13w/s, dev=2]model.layers.52.post_attention_layernorm.weight:  14%|█▎        | 8/59 [00:00<00:05, 10.12w/s, dev=2]model.layers.52.self_attn.k_proj.weight:  15%|█▌        | 9/59 [00:00<00:04, 11.38w/s, dev=2]        model.layers.52.self_attn.o_proj.weight:  17%|█▋        | 10/59 [00:00<00:03, 12.55w/s, dev=2]model.layers.52.self_attn.q_proj.weight:  19%|█▊        | 11/59 [00:00<00:03, 13.05w/s, dev=2]model.layers.52.self_attn.rotary_emb.inv_freq:  20%|██        | 12/59 [00:00<00:03, 13.52w/s, dev=2]model.layers.52.self_attn.v_proj.weight:  22%|██▏       | 13/59 [00:00<00:03, 14.64w/s, dev=2]      model.layers.52.self_attn.v_proj.weight:  24%|██▎       | 14/59 [00:00<00:02, 15.65w/s, dev=2]model.layers.53.input_layernorm.weight:  24%|██▎       | 14/59 [00:00<00:02, 15.65w/s, dev=2] model.layers.53.mlp.down_proj.weight:  25%|██▌       | 15/59 [00:00<00:02, 16.76w/s, dev=2]  model.layers.53.mlp.gate_proj.weight:  27%|██▋       | 16/59 [00:01<00:02, 15.24w/s, dev=2]model.layers.53.mlp.up_proj.weight:  29%|██▉       | 17/59 [00:01<00:02, 14.05w/s, dev=2]  model.layers.53.post_attention_layernorm.weight:  31%|███       | 18/59 [00:01<00:03, 13.07w/s, dev=2]model.layers.53.self_attn.k_proj.weight:  32%|███▏      | 19/59 [00:01<00:02, 13.79w/s, dev=2]        model.layers.53.self_attn.k_proj.weight:  34%|███▍      | 20/59 [00:01<00:02, 14.45w/s, dev=2]model.layers.53.self_attn.o_proj.weight:  34%|███▍      | 20/59 [00:01<00:02, 14.45w/s, dev=2]model.layers.53.self_attn.q_proj.weight:  36%|███▌      | 21/59 [00:01<00:02, 14.65w/s, dev=2]model.layers.53.self_attn.rotary_emb.inv_freq:  37%|███▋      | 22/59 [00:01<00:02, 14.85w/s, dev=2]model.layers.53.self_attn.v_proj.weight:  39%|███▉      | 23/59 [00:01<00:02, 15.52w/s, dev=2]      model.layers.54.input_layernorm.weight:  41%|████      | 24/59 [00:01<00:02, 16.11w/s, dev=2] model.layers.54.mlp.down_proj.weight:  42%|████▏     | 25/59 [00:01<00:02, 16.78w/s, dev=2]  model.layers.54.mlp.down_proj.weight:  44%|████▍     | 26/59 [00:01<00:02, 15.71w/s, dev=2]model.layers.54.mlp.gate_proj.weight:  44%|████▍     | 26/59 [00:01<00:02, 15.71w/s, dev=2]model.layers.54.mlp.up_proj.weight:  46%|████▌     | 27/59 [00:01<00:02, 14.90w/s, dev=2]  model.layers.54.post_attention_layernorm.weight:  47%|████▋     | 28/59 [00:01<00:02, 14.20w/s, dev=2]model.layers.54.self_attn.k_proj.weight:  49%|████▉     | 29/59 [00:01<00:02, 14.70w/s, dev=2]        model.layers.54.self_attn.o_proj.weight:  51%|█████     | 30/59 [00:01<00:01, 15.15w/s, dev=2]model.layers.54.self_attn.q_proj.weight:  53%|█████▎    | 31/59 [00:02<00:01, 15.29w/s, dev=2]model.layers.54.self_attn.q_proj.weight:  54%|█████▍    | 32/59 [00:02<00:01, 15.42w/s, dev=2]model.layers.54.self_attn.rotary_emb.inv_freq:  54%|█████▍    | 32/59 [00:02<00:01, 15.42w/s, dev=2]model.layers.54.self_attn.v_proj.weight:  56%|█████▌    | 33/59 [00:02<00:01, 15.89w/s, dev=2]      model.layers.55.input_layernorm.weight:  58%|█████▊    | 34/59 [00:02<00:01, 16.31w/s, dev=2] model.layers.55.mlp.down_proj.weight:  59%|█████▉    | 35/59 [00:02<00:01, 16.79w/s, dev=2]  model.layers.55.mlp.gate_proj.weight:  61%|██████    | 36/59 [00:02<00:01, 16.05w/s, dev=2]model.layers.55.mlp.up_proj.weight:  63%|██████▎   | 37/59 [00:02<00:01, 15.37w/s, dev=2]  model.layers.55.mlp.up_proj.weight:  64%|██████▍   | 38/59 [00:02<00:01, 14.79w/s, dev=2]model.layers.55.post_attention_layernorm.weight:  64%|██████▍   | 38/59 [00:02<00:01, 14.79w/s, dev=2]model.layers.55.self_attn.k_proj.weight:  66%|██████▌   | 39/59 [00:02<00:01, 15.17w/s, dev=2]        model.layers.55.self_attn.o_proj.weight:  68%|██████▊   | 40/59 [00:02<00:01, 15.51w/s, dev=2]model.layers.55.self_attn.q_proj.weight:  69%|██████▉   | 41/59 [00:02<00:01, 15.61w/s, dev=2]model.layers.55.self_attn.rotary_emb.inv_freq:  71%|███████   | 42/59 [00:02<00:01, 15.72w/s, dev=2]model.layers.55.self_attn.v_proj.weight:  73%|███████▎  | 43/59 [00:02<00:00, 16.09w/s, dev=2]      model.layers.55.self_attn.v_proj.weight:  75%|███████▍  | 44/59 [00:02<00:00, 16.43w/s, dev=2]model.layers.56.input_layernorm.weight:  75%|███████▍  | 44/59 [00:02<00:00, 16.43w/s, dev=2] model.layers.56.mlp.down_proj.weight:  76%|███████▋  | 45/59 [00:02<00:00, 16.80w/s, dev=2]  model.layers.56.mlp.gate_proj.weight:  78%|███████▊  | 46/59 [00:02<00:00, 16.20w/s, dev=2]model.layers.56.mlp.up_proj.weight:  80%|███████▉  | 47/59 [00:02<00:00, 15.68w/s, dev=2]  model.layers.56.post_attention_layernorm.weight:  81%|████████▏ | 48/59 [00:03<00:00, 15.22w/s, dev=2]model.layers.56.self_attn.k_proj.weight:  83%|████████▎ | 49/59 [00:03<00:00, 15.53w/s, dev=2]        model.layers.56.self_attn.k_proj.weight:  85%|████████▍ | 50/59 [00:03<00:00, 15.82w/s, dev=2]model.layers.56.self_attn.o_proj.weight:  85%|████████▍ | 50/59 [00:03<00:00, 15.82w/s, dev=2]model.layers.56.self_attn.q_proj.weight:  86%|████████▋ | 51/59 [00:03<00:00, 15.91w/s, dev=2]model.layers.56.self_attn.rotary_emb.inv_freq:  88%|████████▊ | 52/59 [00:03<00:00, 15.99w/s, dev=2]model.layers.56.self_attn.v_proj.weight:  90%|████████▉ | 53/59 [00:03<00:00, 16.29w/s, dev=2]      model.layers.57.self_attn.k_proj.weight:  92%|█████████▏| 54/59 [00:03<00:00, 16.56w/s, dev=2]model.layers.57.self_attn.o_proj.weight:  93%|█████████▎| 55/59 [00:03<00:00, 16.83w/s, dev=2]model.layers.57.self_attn.o_proj.weight:  95%|█████████▍| 56/59 [00:03<00:00, 16.89w/s, dev=2]model.layers.57.self_attn.q_proj.weight:  95%|█████████▍| 56/59 [00:03<00:00, 16.89w/s, dev=2]model.layers.57.self_attn.rotary_emb.inv_freq:  97%|█████████▋| 57/59 [00:03<00:00, 16.95w/s, dev=2]model.layers.57.self_attn.v_proj.weight:  98%|█████████▊| 58/59 [00:03<00:00, 17.25w/s, dev=2]                                                                                                      0%|          | 0/55 [00:00<?, ?w/s]model.layers.57.input_layernorm.weight:   0%|          | 0/55 [00:00<?, ?w/s, dev=2]model.layers.57.mlp.down_proj.weight:   2%|▏         | 1/55 [00:00<00:00, 1142.86w/s, dev=2]model.layers.57.mlp.down_proj.weight:   4%|▎         | 2/55 [00:00<00:04, 12.68w/s, dev=2]  model.layers.57.mlp.gate_proj.weight:   4%|▎         | 2/55 [00:00<00:04, 12.66w/s, dev=2]model.layers.57.mlp.up_proj.weight:   5%|▌         | 3/55 [00:00<00:05,  9.62w/s, dev=2]  model.layers.57.mlp.up_proj.weight:   7%|▋         | 4/55 [00:00<00:05,  8.52w/s, dev=2]model.layers.57.post_attention_layernorm.weight:   7%|▋         | 4/55 [00:00<00:05,  8.52w/s, dev=2]model.layers.58.input_layernorm.weight:   9%|▉         | 5/55 [00:00<00:04, 10.64w/s, dev=2]         model.layers.58.mlp.down_proj.weight:  11%|█         | 6/55 [00:00<00:03, 12.76w/s, dev=2]  model.layers.58.mlp.down_proj.weight:  13%|█▎        | 7/55 [00:00<00:04, 11.18w/s, dev=2]model.layers.58.mlp.gate_proj.weight:  13%|█▎        | 7/55 [00:00<00:04, 11.18w/s, dev=2]model.layers.58.mlp.up_proj.weight:  15%|█▍        | 8/55 [00:00<00:04, 10.24w/s, dev=2]  model.layers.58.post_attention_layernorm.weight:  16%|█▋        | 9/55 [00:00<00:04,  9.61w/s, dev=2]model.layers.58.post_attention_layernorm.weight:  18%|█▊        | 10/55 [00:00<00:04, 10.67w/s, dev=2]model.layers.58.self_attn.k_proj.weight:  18%|█▊        | 10/55 [00:00<00:04, 10.67w/s, dev=2]        model.layers.58.self_attn.o_proj.weight:  20%|██        | 11/55 [00:00<00:03, 11.65w/s, dev=2]model.layers.58.self_attn.q_proj.weight:  22%|██▏       | 12/55 [00:00<00:03, 12.12w/s, dev=2]model.layers.58.self_attn.rotary_emb.inv_freq:  24%|██▎       | 13/55 [00:01<00:03, 12.57w/s, dev=2]model.layers.58.self_attn.v_proj.weight:  25%|██▌       | 14/55 [00:01<00:03, 13.53w/s, dev=2]      model.layers.58.self_attn.v_proj.weight:  27%|██▋       | 15/55 [00:01<00:02, 14.41w/s, dev=2]model.layers.59.input_layernorm.weight:  27%|██▋       | 15/55 [00:01<00:02, 14.40w/s, dev=2] model.layers.59.mlp.down_proj.weight:  29%|██▉       | 16/55 [00:01<00:02, 15.36w/s, dev=2]  model.layers.59.mlp.gate_proj.weight:  31%|███       | 17/55 [00:01<00:02, 14.24w/s, dev=2]model.layers.59.mlp.up_proj.weight:  33%|███▎      | 18/55 [00:01<00:02, 13.30w/s, dev=2]  model.layers.59.post_attention_layernorm.weight:  35%|███▍      | 19/55 [00:01<00:02, 12.59w/s, dev=2]model.layers.59.post_attention_layernorm.weight:  36%|███▋      | 20/55 [00:01<00:02, 13.25w/s, dev=2]model.layers.59.self_attn.k_proj.weight:  36%|███▋      | 20/55 [00:01<00:02, 13.25w/s, dev=2]        model.layers.59.self_attn.o_proj.weight:  38%|███▊      | 21/55 [00:01<00:02, 13.85w/s, dev=2]model.layers.59.self_attn.q_proj.weight:  40%|████      | 22/55 [00:01<00:02, 14.09w/s, dev=2]model.layers.59.self_attn.rotary_emb.inv_freq:  42%|████▏     | 23/55 [00:01<00:02, 14.31w/s, dev=2]model.layers.59.self_attn.v_proj.weight:  44%|████▎     | 24/55 [00:01<00:02, 14.93w/s, dev=2]      model.layers.59.self_attn.v_proj.weight:  45%|████▌     | 25/55 [00:01<00:01, 15.48w/s, dev=2]model.layers.60.input_layernorm.weight:  45%|████▌     | 25/55 [00:01<00:01, 15.48w/s, dev=2] model.layers.60.mlp.down_proj.weight:  47%|████▋     | 26/55 [00:01<00:01, 16.09w/s, dev=2]  model.layers.60.mlp.gate_proj.weight:  49%|████▉     | 27/55 [00:01<00:01, 15.24w/s, dev=2]model.layers.60.mlp.up_proj.weight:  51%|█████     | 28/55 [00:01<00:01, 14.54w/s, dev=2]  model.layers.60.post_attention_layernorm.weight:  53%|█████▎    | 29/55 [00:02<00:01, 13.94w/s, dev=2]model.layers.60.post_attention_layernorm.weight:  55%|█████▍    | 30/55 [00:02<00:01, 14.42w/s, dev=2]model.layers.60.self_attn.k_proj.weight:  55%|█████▍    | 30/55 [00:02<00:01, 14.42w/s, dev=2]        model.layers.60.self_attn.o_proj.weight:  56%|█████▋    | 31/55 [00:02<00:01, 14.84w/s, dev=2]model.layers.60.self_attn.q_proj.weight:  58%|█████▊    | 32/55 [00:02<00:01, 14.98w/s, dev=2]model.layers.60.self_attn.rotary_emb.inv_freq:  60%|██████    | 33/55 [00:02<00:01, 15.12w/s, dev=2]model.layers.60.self_attn.v_proj.weight:  62%|██████▏   | 34/55 [00:02<00:01, 15.57w/s, dev=2]      model.layers.60.self_attn.v_proj.weight:  64%|██████▎   | 35/55 [00:02<00:01, 15.97w/s, dev=2]model.layers.61.input_layernorm.weight:  64%|██████▎   | 35/55 [00:02<00:01, 15.97w/s, dev=2] model.layers.61.mlp.down_proj.weight:  65%|██████▌   | 36/55 [00:02<00:01, 16.43w/s, dev=2]  model.layers.61.mlp.gate_proj.weight:  67%|██████▋   | 37/55 [00:02<00:01, 15.74w/s, dev=2]model.layers.61.mlp.up_proj.weight:  69%|██████▉   | 38/55 [00:02<00:01, 15.14w/s, dev=2]  model.layers.61.post_attention_layernorm.weight:  71%|███████   | 39/55 [00:02<00:01, 14.65w/s, dev=2]model.layers.61.post_attention_layernorm.weight:  73%|███████▎  | 40/55 [00:02<00:00, 15.02w/s, dev=2]model.layers.61.self_attn.k_proj.weight:  73%|███████▎  | 40/55 [00:02<00:00, 15.02w/s, dev=2]        model.layers.61.self_attn.o_proj.weight:  75%|███████▍  | 41/55 [00:02<00:00, 15.35w/s, dev=2]model.layers.61.self_attn.q_proj.weight:  76%|███████▋  | 42/55 [00:02<00:00, 15.45w/s, dev=2]model.layers.61.self_attn.rotary_emb.inv_freq:  78%|███████▊  | 43/55 [00:02<00:00, 15.56w/s, dev=2]model.layers.61.self_attn.v_proj.weight:  80%|████████  | 44/55 [00:02<00:00, 15.92w/s, dev=2]      model.layers.61.self_attn.v_proj.weight:  82%|████████▏ | 45/55 [00:02<00:00, 16.24w/s, dev=2]model.layers.62.input_layernorm.weight:  82%|████████▏ | 45/55 [00:03<00:00, 14.57w/s, dev=3] model.layers.62.mlp.down_proj.weight:  84%|████████▎ | 46/55 [00:03<00:00, 14.88w/s, dev=3]  model.layers.62.mlp.gate_proj.weight:  85%|████████▌ | 47/55 [00:03<00:00, 14.47w/s, dev=3]model.layers.62.mlp.up_proj.weight:  87%|████████▋ | 48/55 [00:03<00:00, 14.10w/s, dev=3]  model.layers.62.post_attention_layernorm.weight:  89%|████████▉ | 49/55 [00:03<00:00, 13.76w/s, dev=3]model.layers.62.post_attention_layernorm.weight:  91%|█████████ | 50/55 [00:03<00:00, 14.03w/s, dev=3]model.layers.62.self_attn.k_proj.weight:  91%|█████████ | 50/55 [00:03<00:00, 14.03w/s, dev=3]        model.layers.62.self_attn.o_proj.weight:  93%|█████████▎| 51/55 [00:03<00:00, 14.28w/s, dev=3]model.layers.62.self_attn.q_proj.weight:  95%|█████████▍| 52/55 [00:03<00:00, 14.37w/s, dev=3]model.layers.62.self_attn.rotary_emb.inv_freq:  96%|█████████▋| 53/55 [00:03<00:00, 14.45w/s, dev=3]model.layers.62.self_attn.v_proj.weight:  98%|█████████▊| 54/55 [00:03<00:00, 14.72w/s, dev=3]      model.layers.62.self_attn.v_proj.weight: 100%|██████████| 55/55 [00:03<00:00, 14.96w/s, dev=3]                                                                                                0%|          | 0/57 [00:00<?, ?w/s]model.layers.63.input_layernorm.weight:   0%|          | 0/57 [00:00<?, ?w/s, dev=3]model.layers.63.mlp.down_proj.weight:   2%|▏         | 1/57 [00:00<00:00, 968.21w/s, dev=3]model.layers.63.mlp.down_proj.weight:   4%|▎         | 2/57 [00:00<00:04, 12.44w/s, dev=3] model.layers.63.mlp.gate_proj.weight:   4%|▎         | 2/57 [00:00<00:04, 12.42w/s, dev=3]model.layers.63.mlp.up_proj.weight:   5%|▌         | 3/57 [00:00<00:05,  9.20w/s, dev=3]  model.layers.63.mlp.up_proj.weight:   7%|▋         | 4/57 [00:00<00:06,  8.13w/s, dev=3]model.layers.63.post_attention_layernorm.weight:   7%|▋         | 4/57 [00:00<00:06,  8.13w/s, dev=3]model.layers.63.self_attn.k_proj.weight:   9%|▉         | 5/57 [00:00<00:05, 10.15w/s, dev=3]        model.layers.63.self_attn.o_proj.weight:  11%|█         | 6/57 [00:00<00:04, 12.01w/s, dev=3]model.layers.63.self_attn.q_proj.weight:  12%|█▏        | 7/57 [00:00<00:03, 12.70w/s, dev=3]model.layers.63.self_attn.q_proj.weight:  14%|█▍        | 8/57 [00:00<00:03, 13.27w/s, dev=3]model.layers.63.self_attn.rotary_emb.inv_freq:  14%|█▍        | 8/57 [00:00<00:03, 13.27w/s, dev=3]model.layers.63.self_attn.v_proj.weight:  16%|█▌        | 9/57 [00:00<00:03, 14.92w/s, dev=3]      model.layers.64.input_layernorm.weight:  18%|█▊        | 10/57 [00:00<00:02, 16.38w/s, dev=3]model.layers.64.mlp.down_proj.weight:  19%|█▉        | 11/57 [00:00<00:02, 18.00w/s, dev=3]  model.layers.64.mlp.down_proj.weight:  21%|██        | 12/57 [00:00<00:02, 15.46w/s, dev=3]model.layers.64.mlp.gate_proj.weight:  21%|██        | 12/57 [00:00<00:02, 15.45w/s, dev=3]model.layers.64.mlp.up_proj.weight:  23%|██▎       | 13/57 [00:00<00:03, 13.88w/s, dev=3]  model.layers.64.post_attention_layernorm.weight:  25%|██▍       | 14/57 [00:01<00:03, 12.74w/s, dev=3]model.layers.64.self_attn.k_proj.weight:  26%|██▋       | 15/57 [00:01<00:03, 13.64w/s, dev=3]        model.layers.64.self_attn.k_proj.weight:  28%|██▊       | 16/57 [00:01<00:02, 14.45w/s, dev=3]model.layers.64.self_attn.o_proj.weight:  28%|██▊       | 16/57 [00:01<00:02, 14.45w/s, dev=3]model.layers.64.self_attn.q_proj.weight:  30%|██▉       | 17/57 [00:01<00:02, 14.70w/s, dev=3]model.layers.64.self_attn.rotary_emb.inv_freq:  32%|███▏      | 18/57 [00:01<00:02, 14.91w/s, dev=3]model.layers.64.self_attn.v_proj.weight:  33%|███▎      | 19/57 [00:01<00:02, 15.74w/s, dev=3]      model.layers.64.self_attn.v_proj.weight:  35%|███▌      | 20/57 [00:01<00:02, 16.45w/s, dev=3]model.layers.65.input_layernorm.weight:  35%|███▌      | 20/57 [00:01<00:02, 16.44w/s, dev=3] model.layers.65.mlp.down_proj.weight:  37%|███▋      | 21/57 [00:01<00:02, 17.26w/s, dev=3]  model.layers.65.mlp.gate_proj.weight:  39%|███▊      | 22/57 [00:01<00:02, 15.90w/s, dev=3]model.layers.65.mlp.up_proj.weight:  40%|████      | 23/57 [00:01<00:02, 14.87w/s, dev=3]  model.layers.65.mlp.up_proj.weight:  42%|████▏     | 24/57 [00:01<00:02, 14.04w/s, dev=3]model.layers.65.post_attention_layernorm.weight:  42%|████▏     | 24/57 [00:01<00:02, 14.04w/s, dev=3]model.layers.65.self_attn.k_proj.weight:  44%|████▍     | 25/57 [00:01<00:02, 14.62w/s, dev=3]        model.layers.65.self_attn.o_proj.weight:  46%|████▌     | 26/57 [00:01<00:02, 15.12w/s, dev=3]model.layers.65.self_attn.q_proj.weight:  47%|████▋     | 27/57 [00:01<00:01, 15.28w/s, dev=3]model.layers.65.self_attn.q_proj.weight:  49%|████▉     | 28/57 [00:01<00:01, 15.43w/s, dev=3]model.layers.65.self_attn.rotary_emb.inv_freq:  49%|████▉     | 28/57 [00:01<00:01, 15.43w/s, dev=3]model.layers.65.self_attn.v_proj.weight:  51%|█████     | 29/57 [00:01<00:01, 15.98w/s, dev=3]      model.layers.66.input_layernorm.weight:  53%|█████▎    | 30/57 [00:01<00:01, 16.45w/s, dev=3] model.layers.66.mlp.down_proj.weight:  54%|█████▍    | 31/57 [00:01<00:01, 17.00w/s, dev=3]  model.layers.66.mlp.down_proj.weight:  56%|█████▌    | 32/57 [00:01<00:01, 16.09w/s, dev=3]model.layers.66.mlp.gate_proj.weight:  56%|█████▌    | 32/57 [00:01<00:01, 16.08w/s, dev=3]model.layers.66.mlp.up_proj.weight:  58%|█████▊    | 33/57 [00:02<00:01, 15.36w/s, dev=3]  model.layers.66.post_attention_layernorm.weight:  60%|█████▉    | 34/57 [00:02<00:01, 14.68w/s, dev=3]model.layers.66.self_attn.k_proj.weight:  61%|██████▏   | 35/57 [00:02<00:01, 15.10w/s, dev=3]        model.layers.66.self_attn.k_proj.weight:  63%|██████▎   | 36/57 [00:02<00:01, 15.49w/s, dev=3]model.layers.66.self_attn.o_proj.weight:  63%|██████▎   | 36/57 [00:02<00:01, 15.49w/s, dev=3]model.layers.66.self_attn.q_proj.weight:  65%|██████▍   | 37/57 [00:02<00:01, 15.60w/s, dev=3]model.layers.66.self_attn.rotary_emb.inv_freq:  67%|██████▋   | 38/57 [00:02<00:01, 15.73w/s, dev=3]model.layers.66.self_attn.v_proj.weight:  68%|██████▊   | 39/57 [00:02<00:01, 16.14w/s, dev=3]      model.layers.67.input_layernorm.weight:  70%|███████   | 40/57 [00:02<00:01, 16.51w/s, dev=3] model.layers.67.mlp.down_proj.weight:  72%|███████▏  | 41/57 [00:02<00:00, 16.92w/s, dev=3]  model.layers.67.mlp.down_proj.weight:  74%|███████▎  | 42/57 [00:02<00:00, 16.27w/s, dev=3]model.layers.67.mlp.gate_proj.weight:  74%|███████▎  | 42/57 [00:02<00:00, 16.27w/s, dev=3]model.layers.67.mlp.up_proj.weight:  75%|███████▌  | 43/57 [00:02<00:00, 15.68w/s, dev=3]  model.layers.67.post_attention_layernorm.weight:  77%|███████▋  | 44/57 [00:02<00:00, 15.15w/s, dev=3]model.layers.67.self_attn.k_proj.weight:  79%|███████▉  | 45/57 [00:02<00:00, 15.49w/s, dev=3]        model.layers.67.self_attn.o_proj.weight:  81%|████████  | 46/57 [00:02<00:00, 15.80w/s, dev=3]model.layers.67.self_attn.q_proj.weight:  82%|████████▏ | 47/57 [00:02<00:00, 15.89w/s, dev=3]model.layers.67.self_attn.q_proj.weight:  84%|████████▍ | 48/57 [00:03<00:00, 15.98w/s, dev=3]model.layers.67.self_attn.rotary_emb.inv_freq:  84%|████████▍ | 48/57 [00:03<00:00, 15.97w/s, dev=3]model.layers.67.self_attn.v_proj.weight:  86%|████████▌ | 49/57 [00:03<00:00, 16.31w/s, dev=3]      model.layers.68.mlp.down_proj.weight:  88%|████████▊ | 50/57 [00:03<00:00, 16.60w/s, dev=3]   model.layers.68.mlp.gate_proj.weight:  89%|████████▉ | 51/57 [00:03<00:00, 16.09w/s, dev=3]model.layers.68.self_attn.k_proj.weight:  91%|█████████ | 52/57 [00:03<00:00, 15.61w/s, dev=3]model.layers.68.self_attn.o_proj.weight:  93%|█████████▎| 53/57 [00:03<00:00, 15.88w/s, dev=3]model.layers.68.self_attn.o_proj.weight:  95%|█████████▍| 54/57 [00:03<00:00, 15.96w/s, dev=3]model.layers.68.self_attn.q_proj.weight:  95%|█████████▍| 54/57 [00:03<00:00, 15.95w/s, dev=3]model.layers.68.self_attn.rotary_emb.inv_freq:  96%|█████████▋| 55/57 [00:03<00:00, 16.03w/s, dev=3]model.layers.68.self_attn.v_proj.weight:  98%|█████████▊| 56/57 [00:03<00:00, 16.32w/s, dev=3]                                                                                                      0%|          | 0/59 [00:00<?, ?w/s]model.layers.68.input_layernorm.weight:   0%|          | 0/59 [00:00<?, ?w/s, dev=3]model.layers.68.mlp.up_proj.weight:   2%|▏         | 1/59 [00:00<00:00, 905.90w/s, dev=3]model.layers.68.mlp.up_proj.weight:   3%|▎         | 2/59 [00:00<00:04, 12.72w/s, dev=3] model.layers.68.post_attention_layernorm.weight:   3%|▎         | 2/59 [00:00<00:04, 12.70w/s, dev=3]model.layers.69.input_layernorm.weight:   5%|▌         | 3/59 [00:00<00:02, 19.01w/s, dev=3]         model.layers.69.mlp.down_proj.weight:   7%|▋         | 4/59 [00:00<00:02, 25.31w/s, dev=3]  model.layers.69.mlp.down_proj.weight:   8%|▊         | 5/59 [00:00<00:03, 15.81w/s, dev=3]model.layers.69.mlp.gate_proj.weight:   8%|▊         | 5/59 [00:00<00:03, 15.79w/s, dev=3]model.layers.69.mlp.up_proj.weight:  10%|█         | 6/59 [00:00<00:04, 12.71w/s, dev=3]  model.layers.69.post_attention_layernorm.weight:  12%|█▏        | 7/59 [00:00<00:04, 11.16w/s, dev=3]model.layers.69.post_attention_layernorm.weight:  14%|█▎        | 8/59 [00:00<00:04, 12.74w/s, dev=3]model.layers.69.self_attn.k_proj.weight:  14%|█▎        | 8/59 [00:00<00:04, 12.74w/s, dev=3]        model.layers.69.self_attn.o_proj.weight:  15%|█▌        | 9/59 [00:00<00:03, 14.16w/s, dev=3]model.layers.69.self_attn.q_proj.weight:  17%|█▋        | 10/59 [00:00<00:03, 14.66w/s, dev=3]model.layers.69.self_attn.q_proj.weight:  19%|█▊        | 11/59 [00:00<00:03, 15.08w/s, dev=3]model.layers.69.self_attn.rotary_emb.inv_freq:  19%|█▊        | 11/59 [00:00<00:03, 15.08w/s, dev=3]model.layers.69.self_attn.v_proj.weight:  20%|██        | 12/59 [00:00<00:02, 16.44w/s, dev=3]      model.layers.70.input_layernorm.weight:  22%|██▏       | 13/59 [00:00<00:02, 17.66w/s, dev=3] model.layers.70.mlp.down_proj.weight:  24%|██▎       | 14/59 [00:00<00:02, 19.01w/s, dev=3]  model.layers.70.mlp.down_proj.weight:  25%|██▌       | 15/59 [00:00<00:02, 16.94w/s, dev=3]model.layers.70.mlp.gate_proj.weight:  25%|██▌       | 15/59 [00:00<00:02, 16.93w/s, dev=3]model.layers.70.mlp.up_proj.weight:  27%|██▋       | 16/59 [00:01<00:02, 15.50w/s, dev=3]  model.layers.70.post_attention_layernorm.weight:  29%|██▉       | 17/59 [00:01<00:02, 14.39w/s, dev=3]model.layers.70.self_attn.k_proj.weight:  31%|███       | 18/59 [00:01<00:02, 15.23w/s, dev=3]        model.layers.70.self_attn.k_proj.weight:  32%|███▏      | 19/59 [00:01<00:02, 15.99w/s, dev=3]model.layers.70.self_attn.o_proj.weight:  32%|███▏      | 19/59 [00:01<00:02, 15.99w/s, dev=3]model.layers.70.self_attn.q_proj.weight:  34%|███▍      | 20/59 [00:01<00:02, 16.26w/s, dev=3]model.layers.70.self_attn.rotary_emb.inv_freq:  36%|███▌      | 21/59 [00:01<00:02, 16.45w/s, dev=3]model.layers.70.self_attn.v_proj.weight:  37%|███▋      | 22/59 [00:01<00:02, 17.23w/s, dev=3]      model.layers.71.input_layernorm.weight:  39%|███▉      | 23/59 [00:01<00:02, 17.93w/s, dev=3] model.layers.71.mlp.down_proj.weight:  41%|████      | 24/59 [00:01<00:01, 18.70w/s, dev=3]  model.layers.71.mlp.down_proj.weight:  42%|████▏     | 25/59 [00:01<00:01, 17.51w/s, dev=3]model.layers.71.mlp.gate_proj.weight:  42%|████▏     | 25/59 [00:01<00:01, 17.51w/s, dev=3]model.layers.71.mlp.up_proj.weight:  44%|████▍     | 26/59 [00:01<00:02, 16.49w/s, dev=3]  model.layers.71.post_attention_layernorm.weight:  46%|████▌     | 27/59 [00:01<00:02, 15.67w/s, dev=3]model.layers.71.self_attn.k_proj.weight:  47%|████▋     | 28/59 [00:01<00:01, 16.25w/s, dev=3]        model.layers.71.self_attn.o_proj.weight:  49%|████▉     | 29/59 [00:01<00:01, 16.76w/s, dev=3]model.layers.71.self_attn.q_proj.weight:  51%|█████     | 30/59 [00:01<00:01, 16.91w/s, dev=3]model.layers.71.self_attn.q_proj.weight:  53%|█████▎    | 31/59 [00:01<00:01, 17.05w/s, dev=3]model.layers.71.self_attn.rotary_emb.inv_freq:  53%|█████▎    | 31/59 [00:01<00:01, 17.05w/s, dev=3]model.layers.71.self_attn.v_proj.weight:  54%|█████▍    | 32/59 [00:01<00:01, 17.59w/s, dev=3]      model.layers.72.input_layernorm.weight:  56%|█████▌    | 33/59 [00:01<00:01, 18.06w/s, dev=3] model.layers.72.mlp.down_proj.weight:  58%|█████▊    | 34/59 [00:01<00:01, 18.60w/s, dev=3]  model.layers.72.mlp.gate_proj.weight:  59%|█████▉    | 35/59 [00:01<00:01, 17.71w/s, dev=3]model.layers.72.mlp.up_proj.weight:  61%|██████    | 36/59 [00:02<00:01, 16.96w/s, dev=3]  model.layers.72.mlp.up_proj.weight:  63%|██████▎   | 37/59 [00:02<00:01, 16.31w/s, dev=3]model.layers.72.post_attention_layernorm.weight:  63%|██████▎   | 37/59 [00:02<00:01, 16.31w/s, dev=3]model.layers.72.self_attn.k_proj.weight:  64%|██████▍   | 38/59 [00:02<00:01, 16.75w/s, dev=3]        model.layers.72.self_attn.o_proj.weight:  66%|██████▌   | 39/59 [00:02<00:01, 17.13w/s, dev=3]model.layers.72.self_attn.q_proj.weight:  68%|██████▊   | 40/59 [00:02<00:01, 17.23w/s, dev=3]model.layers.72.self_attn.rotary_emb.inv_freq:  69%|██████▉   | 41/59 [00:02<00:01, 17.33w/s, dev=3]model.layers.72.self_attn.v_proj.weight:  71%|███████   | 42/59 [00:02<00:00, 17.75w/s, dev=3]      model.layers.72.self_attn.v_proj.weight:  73%|███████▎  | 43/59 [00:02<00:00, 18.11w/s, dev=3]model.layers.73.input_layernorm.weight:  73%|███████▎  | 43/59 [00:02<00:00, 18.11w/s, dev=3] model.layers.73.mlp.down_proj.weight:  75%|███████▍  | 44/59 [00:02<00:00, 18.53w/s, dev=3]  model.layers.73.mlp.gate_proj.weight:  76%|███████▋  | 45/59 [00:02<00:00, 17.83w/s, dev=3]model.layers.73.mlp.up_proj.weight:  78%|███████▊  | 46/59 [00:02<00:00, 17.21w/s, dev=3]  model.layers.73.post_attention_layernorm.weight:  80%|███████▉  | 47/59 [00:02<00:00, 16.67w/s, dev=3]model.layers.73.self_attn.k_proj.weight:  81%|████████▏ | 48/59 [00:02<00:00, 17.02w/s, dev=3]        model.layers.73.self_attn.k_proj.weight:  83%|████████▎ | 49/59 [00:02<00:00, 17.32w/s, dev=3]model.layers.73.self_attn.o_proj.weight:  83%|████████▎ | 49/59 [00:02<00:00, 17.32w/s, dev=3]model.layers.73.self_attn.q_proj.weight:  85%|████████▍ | 50/59 [00:02<00:00, 17.40w/s, dev=3]model.layers.73.self_attn.rotary_emb.inv_freq:  86%|████████▋ | 51/59 [00:02<00:00, 17.49w/s, dev=3]model.layers.73.self_attn.v_proj.weight:  88%|████████▊ | 52/59 [00:02<00:00, 17.83w/s, dev=3]      model.layers.74.mlp.gate_proj.weight:  90%|████████▉ | 53/59 [00:02<00:00, 18.14w/s, dev=3]   model.layers.74.self_attn.k_proj.weight:  92%|█████████▏| 54/59 [00:03<00:00, 17.61w/s, dev=3]model.layers.74.self_attn.k_proj.weight:  93%|█████████▎| 55/59 [00:03<00:00, 17.90w/s, dev=3]model.layers.74.self_attn.o_proj.weight:  93%|█████████▎| 55/59 [00:03<00:00, 17.90w/s, dev=3]model.layers.74.self_attn.q_proj.weight:  95%|█████████▍| 56/59 [00:03<00:00, 17.97w/s, dev=3]model.layers.74.self_attn.rotary_emb.inv_freq:  97%|█████████▋| 57/59 [00:03<00:00, 18.05w/s, dev=3]model.layers.74.self_attn.v_proj.weight:  98%|█████████▊| 58/59 [00:03<00:00, 18.36w/s, dev=3]                                                                                                      0%|          | 0/55 [00:00<?, ?w/s]model.layers.74.input_layernorm.weight:   0%|          | 0/55 [00:00<?, ?w/s, dev=3]model.layers.74.mlp.down_proj.weight:   2%|▏         | 1/55 [00:00<00:00, 1036.65w/s, dev=3]model.layers.74.mlp.down_proj.weight:   4%|▎         | 2/55 [00:00<00:04, 12.18w/s, dev=3]  model.layers.74.mlp.up_proj.weight:   4%|▎         | 2/55 [00:00<00:04, 12.16w/s, dev=3]  model.layers.74.post_attention_layernorm.weight:   5%|▌         | 3/55 [00:00<00:05,  9.31w/s, dev=3]model.layers.74.post_attention_layernorm.weight:   7%|▋         | 4/55 [00:00<00:04, 12.40w/s, dev=3]model.layers.75.input_layernorm.weight:   7%|▋         | 4/55 [00:00<00:04, 12.40w/s, dev=3]         model.layers.75.mlp.down_proj.weight:   9%|▉         | 5/55 [00:00<00:03, 15.48w/s, dev=3]  model.layers.75.mlp.down_proj.weight:  11%|█         | 6/55 [00:00<00:03, 12.60w/s, dev=3]model.layers.75.mlp.gate_proj.weight:  11%|█         | 6/55 [00:00<00:03, 12.59w/s, dev=3]model.layers.75.mlp.up_proj.weight:  13%|█▎        | 7/55 [00:00<00:04, 11.08w/s, dev=3]  model.layers.75.mlp.up_proj.weight:  15%|█▍        | 8/55 [00:00<00:04, 10.25w/s, dev=3]model.layers.75.post_attention_layernorm.weight:  15%|█▍        | 8/55 [00:00<00:04, 10.24w/s, dev=3]model.layers.75.self_attn.k_proj.weight:  16%|█▋        | 9/55 [00:00<00:03, 11.52w/s, dev=3]        model.layers.75.self_attn.o_proj.weight:  18%|█▊        | 10/55 [00:00<00:03, 12.70w/s, dev=3]model.layers.75.self_attn.q_proj.weight:  20%|██        | 11/55 [00:00<00:03, 13.24w/s, dev=3]model.layers.75.self_attn.rotary_emb.inv_freq:  22%|██▏       | 12/55 [00:00<00:03, 13.70w/s, dev=3]model.layers.75.self_attn.v_proj.weight:  24%|██▎       | 13/55 [00:00<00:02, 14.84w/s, dev=3]      model.layers.75.self_attn.v_proj.weight:  25%|██▌       | 14/55 [00:00<00:02, 15.86w/s, dev=3]model.layers.76.input_layernorm.weight:  25%|██▌       | 14/55 [00:00<00:02, 15.85w/s, dev=3] model.layers.76.mlp.down_proj.weight:  27%|██▋       | 15/55 [00:00<00:02, 16.98w/s, dev=3]  model.layers.76.mlp.gate_proj.weight:  29%|██▉       | 16/55 [00:01<00:02, 15.49w/s, dev=3]model.layers.76.mlp.up_proj.weight:  31%|███       | 17/55 [00:01<00:02, 14.35w/s, dev=3]  model.layers.76.post_attention_layernorm.weight:  33%|███▎      | 18/55 [00:01<00:02, 13.53w/s, dev=3]model.layers.76.self_attn.k_proj.weight:  35%|███▍      | 19/55 [00:01<00:02, 14.27w/s, dev=3]        model.layers.76.self_attn.k_proj.weight:  36%|███▋      | 20/55 [00:01<00:02, 14.96w/s, dev=3]model.layers.76.self_attn.o_proj.weight:  36%|███▋      | 20/55 [00:01<00:02, 14.95w/s, dev=3]model.layers.76.self_attn.q_proj.weight:  38%|███▊      | 21/55 [00:01<00:02, 15.22w/s, dev=3]model.layers.76.self_attn.rotary_emb.inv_freq:  40%|████      | 22/55 [00:01<00:02, 15.47w/s, dev=3]model.layers.76.self_attn.v_proj.weight:  42%|████▏     | 23/55 [00:01<00:01, 16.16w/s, dev=3]      model.layers.77.input_layernorm.weight:  44%|████▎     | 24/55 [00:01<00:01, 16.80w/s, dev=3] model.layers.77.mlp.down_proj.weight:  45%|████▌     | 25/55 [00:01<00:01, 17.49w/s, dev=3]  model.layers.77.mlp.down_proj.weight:  47%|████▋     | 26/55 [00:01<00:01, 16.50w/s, dev=3]model.layers.77.mlp.gate_proj.weight:  47%|████▋     | 26/55 [00:01<00:01, 16.49w/s, dev=3]model.layers.77.mlp.up_proj.weight:  49%|████▉     | 27/55 [00:01<00:01, 15.64w/s, dev=3]  model.layers.77.post_attention_layernorm.weight:  51%|█████     | 28/55 [00:01<00:01, 14.89w/s, dev=3]model.layers.77.self_attn.k_proj.weight:  53%|█████▎    | 29/55 [00:01<00:01, 15.42w/s, dev=3]        model.layers.77.self_attn.o_proj.weight:  55%|█████▍    | 30/55 [00:01<00:01, 15.89w/s, dev=3]model.layers.77.self_attn.q_proj.weight:  56%|█████▋    | 31/55 [00:01<00:01, 16.04w/s, dev=3]model.layers.77.self_attn.q_proj.weight:  58%|█████▊    | 32/55 [00:01<00:01, 16.18w/s, dev=3]model.layers.77.self_attn.rotary_emb.inv_freq:  58%|█████▊    | 32/55 [00:01<00:01, 16.17w/s, dev=3]model.layers.77.self_attn.v_proj.weight:  60%|██████    | 33/55 [00:01<00:01, 16.68w/s, dev=3]      model.layers.78.input_layernorm.weight:  62%|██████▏   | 34/55 [00:01<00:01, 17.08w/s, dev=3] model.layers.78.mlp.down_proj.weight:  64%|██████▎   | 35/55 [00:01<00:01, 17.58w/s, dev=3]  model.layers.78.mlp.gate_proj.weight:  65%|██████▌   | 36/55 [00:02<00:01, 16.81w/s, dev=3]model.layers.78.mlp.up_proj.weight:  67%|██████▋   | 37/55 [00:02<00:01, 16.09w/s, dev=3]  model.layers.78.mlp.up_proj.weight:  69%|██████▉   | 38/55 [00:02<00:01, 15.48w/s, dev=3]model.layers.78.post_attention_layernorm.weight:  69%|██████▉   | 38/55 [00:02<00:01, 15.47w/s, dev=3]model.layers.78.self_attn.k_proj.weight:  71%|███████   | 39/55 [00:02<00:01, 15.88w/s, dev=3]        model.layers.78.self_attn.o_proj.weight:  73%|███████▎  | 40/55 [00:02<00:00, 16.25w/s, dev=3]model.layers.78.self_attn.q_proj.weight:  75%|███████▍  | 41/55 [00:02<00:00, 16.35w/s, dev=3]model.layers.78.self_attn.rotary_emb.inv_freq:  76%|███████▋  | 42/55 [00:02<00:00, 16.45w/s, dev=3]model.layers.78.self_attn.v_proj.weight:  78%|███████▊  | 43/55 [00:02<00:00, 16.84w/s, dev=3]      model.layers.78.self_attn.v_proj.weight:  80%|████████  | 44/55 [00:02<00:00, 17.17w/s, dev=3]model.layers.79.input_layernorm.weight:  80%|████████  | 44/55 [00:02<00:00, 17.17w/s, dev=3] model.layers.79.mlp.down_proj.weight:  82%|████████▏ | 45/55 [00:02<00:00, 17.56w/s, dev=3]  model.layers.79.mlp.gate_proj.weight:  84%|████████▎ | 46/55 [00:02<00:00, 16.88w/s, dev=3]model.layers.79.mlp.up_proj.weight:  85%|████████▌ | 47/55 [00:02<00:00, 16.35w/s, dev=3]  model.layers.79.post_attention_layernorm.weight:  87%|████████▋ | 48/55 [00:03<00:00, 15.89w/s, dev=3]model.layers.79.self_attn.k_proj.weight:  89%|████████▉ | 49/55 [00:03<00:00, 16.21w/s, dev=3]        model.layers.79.self_attn.k_proj.weight:  91%|█████████ | 50/55 [00:03<00:00, 16.51w/s, dev=3]model.layers.79.self_attn.o_proj.weight:  91%|█████████ | 50/55 [00:03<00:00, 16.50w/s, dev=3]model.layers.79.self_attn.q_proj.weight:  93%|█████████▎| 51/55 [00:03<00:00, 16.60w/s, dev=3]model.layers.79.self_attn.rotary_emb.inv_freq:  95%|█████████▍| 52/55 [00:03<00:00, 16.70w/s, dev=3]model.layers.79.self_attn.v_proj.weight:  96%|█████████▋| 53/55 [00:03<00:00, 17.02w/s, dev=3]      model.norm.weight:  98%|█████████▊| 54/55 [00:03<00:00, 17.30w/s, dev=3]                                                                                                0%|          | 0/1 [00:00<?, ?w/s]lm_head.weight:   0%|          | 0/1 [00:00<?, ?w/s, dev=3]lm_head.weight: 100%|██████████| 1/1 [00:00<00:00,  6.22w/s, dev=3]                                                                   self.device: cuda:0
Loading BASE model stabilityai/stablelm-base-alpha-3b-v2...
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.15it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.02it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[2] MOVING BASE MODEL TO GPU.../home/chawins/.conda/envs/mimir/lib/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for iamgroot42/mimir contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/iamgroot42/mimir
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
Loading dataset the_pile...
Loading from HuggingFace!
Loading dataset the_pile...
Loading from HuggingFace!
Generating samples:   0%|          | 0/21 [00:00<?, ?it/s]Generating samples: 100%|██████████| 21/21 [00:00<00:00, 983.19it/s]
NEW N_SAMPLES IS  1000
Writing raw data to tmp_results/neo125_github_experiment/meta-llama_Llama-2-70b-hf/github_ngram_13_<0.8_truncated/raw_data.json
Writing raw data to tmp_results/neo125_github_experiment/meta-llama_Llama-2-70b-hf/github_ngram_13_<0.8_truncated/raw_data_lens.json
Computing criterion:   0%|          | 0/20 [00:00<?, ?it/s]Computing criterion:   5%|▌         | 1/20 [00:24<07:50, 24.77s/it]Computing criterion:  10%|█         | 2/20 [00:45<06:38, 22.14s/it]Computing criterion:  15%|█▌        | 3/20 [01:05<06:00, 21.22s/it]Computing criterion:  20%|██        | 4/20 [01:24<05:27, 20.48s/it]Computing criterion:  25%|██▌       | 5/20 [01:44<05:06, 20.45s/it]Computing criterion:  30%|███       | 6/20 [02:05<04:46, 20.49s/it]Computing criterion:  35%|███▌      | 7/20 [02:25<04:23, 20.30s/it]Computing criterion:  40%|████      | 8/20 [02:45<04:03, 20.28s/it]Computing criterion:  45%|████▌     | 9/20 [03:05<03:42, 20.27s/it]Computing criterion:  50%|█████     | 10/20 [03:26<03:24, 20.41s/it]Computing criterion:  55%|█████▌    | 11/20 [03:47<03:04, 20.50s/it]Computing criterion:  60%|██████    | 12/20 [04:07<02:42, 20.30s/it]Computing criterion:  65%|██████▌   | 13/20 [04:28<02:23, 20.46s/it]Computing criterion:  70%|███████   | 14/20 [04:48<02:02, 20.49s/it]Computing criterion:  75%|███████▌  | 15/20 [05:09<01:43, 20.68s/it]Computing criterion:  80%|████████  | 16/20 [05:30<01:22, 20.70s/it]Computing criterion:  85%|████████▌ | 17/20 [05:51<01:02, 20.82s/it]Computing criterion:  90%|█████████ | 18/20 [06:11<00:40, 20.42s/it]Computing criterion:  95%|█████████▌| 19/20 [06:31<00:20, 20.40s/it]Computing criterion: 100%|██████████| 20/20 [06:51<00:00, 20.41s/it]Computing criterion: 100%|██████████| 20/20 [06:51<00:00, 20.59s/it]
Ref scores:   0%|          | 0/1000 [00:00<?, ?it/s]Ref scores:   0%|          | 1/1000 [00:08<2:25:20,  8.73s/it]Ref scores:   0%|          | 2/1000 [00:08<1:01:35,  3.70s/it]Ref scores:   0%|          | 3/1000 [00:09<35:05,  2.11s/it]  Ref scores:   0%|          | 4/1000 [00:09<22:07,  1.33s/it]Ref scores:   0%|          | 5/1000 [00:09<15:32,  1.07it/s]Ref scores:   1%|          | 6/1000 [00:09<10:59,  1.51it/s]Ref scores:   1%|          | 7/1000 [00:09<07:57,  2.08it/s]Ref scores:   1%|          | 8/1000 [00:09<06:33,  2.52it/s]Ref scores:   1%|          | 9/1000 [00:10<05:13,  3.16it/s]Ref scores:   1%|          | 10/1000 [00:10<04:23,  3.75it/s]Ref scores:   1%|          | 11/1000 [00:10<04:00,  4.12it/s]Ref scores:   1%|          | 12/1000 [00:10<03:19,  4.96it/s]Ref scores:   1%|▏         | 13/1000 [00:10<03:16,  5.01it/s]Ref scores:   1%|▏         | 14/1000 [00:10<03:14,  5.06it/s]Ref scores:   2%|▏         | 15/1000 [00:11<03:12,  5.11it/s]Ref scores:   2%|▏         | 16/1000 [00:11<03:00,  5.45it/s]Ref scores:   2%|▏         | 17/1000 [00:11<02:46,  5.90it/s]Ref scores:   2%|▏         | 18/1000 [00:11<03:08,  5.22it/s]Ref scores:   2%|▏         | 19/1000 [00:11<02:44,  5.97it/s]Ref scores:   2%|▏         | 20/1000 [00:11<02:42,  6.04it/s]Ref scores:   2%|▏         | 21/1000 [00:12<02:50,  5.74it/s]Ref scores:   2%|▏         | 22/1000 [00:12<03:02,  5.35it/s]Ref scores:   2%|▏         | 23/1000 [00:12<02:47,  5.83it/s]Ref scores:   2%|▏         | 24/1000 [00:12<03:01,  5.39it/s]Ref scores:   2%|▎         | 25/1000 [00:12<02:46,  5.87it/s]Ref scores:   3%|▎         | 26/1000 [00:13<02:59,  5.41it/s]Ref scores:   3%|▎         | 27/1000 [00:13<02:45,  5.88it/s]Ref scores:   3%|▎         | 28/1000 [00:13<02:40,  6.06it/s]Ref scores:   3%|▎         | 29/1000 [00:13<02:55,  5.52it/s]Ref scores:   3%|▎         | 30/1000 [00:13<03:06,  5.20it/s]Ref scores:   3%|▎         | 31/1000 [00:13<02:55,  5.52it/s]Ref scores:   3%|▎         | 32/1000 [00:14<02:58,  5.42it/s]Ref scores:   3%|▎         | 33/1000 [00:14<02:52,  5.61it/s]Ref scores:   3%|▎         | 34/1000 [00:14<02:40,  6.03it/s]Ref scores:   4%|▎         | 35/1000 [00:14<02:31,  6.38it/s]Ref scores:   4%|▎         | 36/1000 [00:14<02:42,  5.93it/s]Ref scores:   4%|▎         | 37/1000 [00:14<02:57,  5.43it/s]Ref scores:   4%|▍         | 38/1000 [00:15<03:06,  5.15it/s]Ref scores:   4%|▍         | 39/1000 [00:15<02:55,  5.49it/s]Ref scores:   4%|▍         | 40/1000 [00:15<02:42,  5.92it/s]Ref scores:   4%|▍         | 41/1000 [00:15<02:48,  5.69it/s]Ref scores:   4%|▍         | 42/1000 [00:15<02:42,  5.91it/s]Ref scores:   4%|▍         | 43/1000 [00:15<02:36,  6.10it/s]Ref scores:   4%|▍         | 44/1000 [00:16<02:52,  5.55it/s]Ref scores:   4%|▍         | 45/1000 [00:16<02:39,  6.00it/s]Ref scores:   5%|▍         | 46/1000 [00:16<02:44,  5.80it/s]Ref scores:   5%|▍         | 47/1000 [00:16<02:48,  5.65it/s]Ref scores:   5%|▍         | 48/1000 [00:16<02:51,  5.55it/s]Ref scores:   5%|▍         | 49/1000 [00:17<03:01,  5.24it/s]Ref scores:   5%|▌         | 50/1000 [00:17<02:50,  5.57it/s]Ref scores:   5%|▌         | 51/1000 [00:17<03:00,  5.27it/s]Ref scores:   5%|▌         | 52/1000 [00:17<02:59,  5.29it/s]Ref scores:   5%|▌         | 53/1000 [00:17<02:50,  5.56it/s]Ref scores:   5%|▌         | 54/1000 [00:18<03:13,  4.89it/s]Ref scores:   6%|▌         | 55/1000 [00:18<02:59,  5.25it/s]Ref scores:   6%|▌         | 56/1000 [00:18<02:58,  5.28it/s]Ref scores:   6%|▌         | 57/1000 [00:18<03:06,  5.04it/s]Ref scores:   6%|▌         | 58/1000 [00:18<02:49,  5.55it/s]Ref scores:   6%|▌         | 59/1000 [00:18<02:45,  5.69it/s]Ref scores:   6%|▌         | 60/1000 [00:19<02:48,  5.58it/s]Ref scores:   6%|▌         | 61/1000 [00:19<02:35,  6.02it/s]Ref scores:   6%|▌         | 62/1000 [00:19<02:42,  5.78it/s]Ref scores:   6%|▋         | 63/1000 [00:19<02:37,  5.96it/s]Ref scores:   6%|▋         | 64/1000 [00:19<02:28,  6.32it/s]Ref scores:   6%|▋         | 65/1000 [00:19<02:21,  6.62it/s]Ref scores:   7%|▋         | 66/1000 [00:20<02:32,  6.11it/s]Ref scores:   7%|▋         | 67/1000 [00:20<02:40,  5.82it/s]Ref scores:   7%|▋         | 68/1000 [00:20<02:52,  5.41it/s]Ref scores:   7%|▋         | 69/1000 [00:20<02:54,  5.34it/s]Ref scores:   7%|▋         | 70/1000 [00:20<02:44,  5.65it/s]Ref scores:   7%|▋         | 71/1000 [00:21<02:56,  5.26it/s]Ref scores:   7%|▋         | 72/1000 [00:21<03:03,  5.06it/s]Ref scores:   7%|▋         | 73/1000 [00:21<02:53,  5.36it/s]Ref scores:   7%|▋         | 74/1000 [00:21<03:15,  4.73it/s]Ref scores:   8%|▊         | 75/1000 [00:21<02:54,  5.31it/s]Ref scores:   8%|▊         | 76/1000 [00:22<03:02,  5.06it/s]Ref scores:   8%|▊         | 77/1000 [00:22<03:16,  4.70it/s]Ref scores:   8%|▊         | 78/1000 [00:22<03:08,  4.88it/s]Ref scores:   8%|▊         | 79/1000 [00:22<02:55,  5.26it/s]Ref scores:   8%|▊         | 80/1000 [00:22<02:39,  5.75it/s]Ref scores:   8%|▊         | 81/1000 [00:22<02:29,  6.13it/s]Ref scores:   8%|▊         | 82/1000 [00:23<02:29,  6.14it/s]Ref scores:   8%|▊         | 83/1000 [00:23<02:37,  5.81it/s]Ref scores:   8%|▊         | 84/1000 [00:23<02:57,  5.15it/s]Ref scores:   8%|▊         | 85/1000 [00:23<02:48,  5.43it/s]Ref scores:   9%|▊         | 86/1000 [00:23<02:51,  5.32it/s]Ref scores:   9%|▊         | 87/1000 [00:24<02:37,  5.79it/s]Ref scores:   9%|▉         | 88/1000 [00:24<02:43,  5.57it/s]Ref scores:   9%|▉         | 89/1000 [00:24<02:30,  6.03it/s]Ref scores:   9%|▉         | 90/1000 [00:24<02:45,  5.51it/s]Ref scores:   9%|▉         | 91/1000 [00:24<02:46,  5.45it/s]Ref scores:   9%|▉         | 92/1000 [00:24<02:50,  5.33it/s]Ref scores:   9%|▉         | 93/1000 [00:25<02:43,  5.54it/s]Ref scores:   9%|▉         | 94/1000 [00:25<02:32,  5.95it/s]Ref scores:  10%|▉         | 95/1000 [00:25<02:28,  6.09it/s]Ref scores:  10%|▉         | 96/1000 [00:25<02:36,  5.76it/s]Ref scores:  10%|▉         | 97/1000 [00:25<02:41,  5.58it/s]Ref scores:  10%|▉         | 98/1000 [00:25<02:29,  6.03it/s]Ref scores:  10%|▉         | 99/1000 [00:26<02:35,  5.78it/s]Ref scores:  10%|█         | 100/1000 [00:26<02:40,  5.61it/s]Ref scores:  10%|█         | 101/1000 [00:26<02:28,  6.05it/s]Ref scores:  10%|█         | 102/1000 [00:26<02:35,  5.77it/s]Ref scores:  10%|█         | 103/1000 [00:26<02:18,  6.46it/s]Ref scores:  10%|█         | 104/1000 [00:26<02:14,  6.67it/s]Ref scores:  10%|█         | 105/1000 [00:27<02:33,  5.84it/s]Ref scores:  11%|█         | 106/1000 [00:27<02:24,  6.21it/s]Ref scores:  11%|█         | 107/1000 [00:27<02:21,  6.30it/s]Ref scores:  11%|█         | 108/1000 [00:27<02:09,  6.88it/s]Ref scores:  11%|█         | 109/1000 [00:27<02:28,  6.00it/s]Ref scores:  11%|█         | 110/1000 [00:27<02:21,  6.29it/s]Ref scores:  11%|█         | 111/1000 [00:28<02:19,  6.36it/s]Ref scores:  11%|█         | 112/1000 [00:28<02:29,  5.93it/s]Ref scores:  11%|█▏        | 113/1000 [00:28<02:27,  6.00it/s]Ref scores:  11%|█▏        | 114/1000 [00:28<02:49,  5.24it/s]Ref scores:  12%|█▏        | 115/1000 [00:28<02:40,  5.50it/s]Ref scores:  12%|█▏        | 116/1000 [00:28<02:33,  5.77it/s]Ref scores:  12%|█▏        | 117/1000 [00:29<02:29,  5.90it/s]Ref scores:  12%|█▏        | 118/1000 [00:29<02:25,  6.05it/s]Ref scores:  12%|█▏        | 119/1000 [00:29<02:32,  5.77it/s]Ref scores:  12%|█▏        | 120/1000 [00:29<02:27,  5.95it/s]Ref scores:  12%|█▏        | 121/1000 [00:29<02:34,  5.70it/s]Ref scores:  12%|█▏        | 122/1000 [00:29<02:23,  6.11it/s]Ref scores:  12%|█▏        | 123/1000 [00:30<02:09,  6.77it/s]Ref scores:  12%|█▏        | 124/1000 [00:30<02:38,  5.51it/s]Ref scores:  12%|█▎        | 125/1000 [00:30<02:42,  5.40it/s]Ref scores:  13%|█▎        | 126/1000 [00:30<02:29,  5.84it/s]Ref scores:  13%|█▎        | 127/1000 [00:30<02:20,  6.19it/s]Ref scores:  13%|█▎        | 128/1000 [00:30<02:21,  6.17it/s]Ref scores:  13%|█▎        | 129/1000 [00:31<02:14,  6.49it/s]Ref scores:  13%|█▎        | 130/1000 [00:31<02:15,  6.40it/s]Ref scores:  13%|█▎        | 131/1000 [00:31<02:39,  5.46it/s]Ref scores:  13%|█▎        | 132/1000 [00:31<02:27,  5.90it/s]Ref scores:  13%|█▎        | 133/1000 [00:31<02:45,  5.25it/s]Ref scores:  13%|█▎        | 134/1000 [00:32<02:51,  5.04it/s]Ref scores:  14%|█▎        | 135/1000 [00:32<02:29,  5.79it/s]Ref scores:  14%|█▎        | 136/1000 [00:32<02:25,  5.95it/s]Ref scores:  14%|█▎        | 137/1000 [00:32<02:15,  6.35it/s]Ref scores:  14%|█▍        | 138/1000 [00:32<02:10,  6.59it/s]Ref scores:  14%|█▍        | 139/1000 [00:32<02:11,  6.57it/s]Ref scores:  14%|█▍        | 140/1000 [00:33<02:33,  5.62it/s]Ref scores:  14%|█▍        | 141/1000 [00:33<02:36,  5.50it/s]Ref scores:  14%|█▍        | 142/1000 [00:33<02:23,  5.97it/s]Ref scores:  14%|█▍        | 143/1000 [00:33<02:20,  6.10it/s]Ref scores:  14%|█▍        | 144/1000 [00:33<02:26,  5.85it/s]Ref scores:  14%|█▍        | 145/1000 [00:33<02:22,  6.00it/s]Ref scores:  15%|█▍        | 146/1000 [00:34<02:36,  5.46it/s]Ref scores:  15%|█▍        | 147/1000 [00:34<02:38,  5.38it/s]Ref scores:  15%|█▍        | 148/1000 [00:34<02:32,  5.59it/s]Ref scores:  15%|█▍        | 149/1000 [00:34<02:28,  5.74it/s]Ref scores:  15%|█▌        | 150/1000 [00:34<02:31,  5.59it/s]Ref scores:  15%|█▌        | 151/1000 [00:34<02:12,  6.40it/s]Ref scores:  15%|█▌        | 152/1000 [00:34<02:01,  6.99it/s]Ref scores:  15%|█▌        | 153/1000 [00:35<02:13,  6.35it/s]Ref scores:  15%|█▌        | 154/1000 [00:35<02:08,  6.59it/s]Ref scores:  16%|█▌        | 155/1000 [00:35<02:25,  5.83it/s]Ref scores:  16%|█▌        | 156/1000 [00:35<02:08,  6.56it/s]Ref scores:  16%|█▌        | 157/1000 [00:35<02:26,  5.77it/s]Ref scores:  16%|█▌        | 158/1000 [00:36<02:29,  5.64it/s]Ref scores:  16%|█▌        | 159/1000 [00:36<02:33,  5.47it/s]Ref scores:  16%|█▌        | 160/1000 [00:36<02:21,  5.92it/s]Ref scores:  16%|█▌        | 161/1000 [00:36<02:34,  5.44it/s]Ref scores:  16%|█▌        | 162/1000 [00:36<02:36,  5.36it/s]Ref scores:  16%|█▋        | 163/1000 [00:37<02:51,  4.87it/s]Ref scores:  16%|█▋        | 164/1000 [00:37<02:41,  5.18it/s]Ref scores:  16%|█▋        | 165/1000 [00:37<02:31,  5.52it/s]Ref scores:  17%|█▋        | 166/1000 [00:37<02:40,  5.19it/s]Ref scores:  17%|█▋        | 167/1000 [00:37<02:18,  6.00it/s]Ref scores:  17%|█▋        | 168/1000 [00:37<02:16,  6.10it/s]Ref scores:  17%|█▋        | 169/1000 [00:38<02:14,  6.19it/s]Ref scores:  17%|█▋        | 170/1000 [00:38<02:07,  6.51it/s]Ref scores:  17%|█▋        | 171/1000 [00:38<02:02,  6.76it/s]Ref scores:  17%|█▋        | 172/1000 [00:38<02:04,  6.68it/s]Ref scores:  17%|█▋        | 173/1000 [00:38<02:00,  6.84it/s]Ref scores:  17%|█▋        | 174/1000 [00:38<02:11,  6.27it/s]Ref scores:  18%|█▊        | 175/1000 [00:38<02:10,  6.34it/s]Ref scores:  18%|█▊        | 176/1000 [00:39<02:17,  5.99it/s]Ref scores:  18%|█▊        | 177/1000 [00:39<02:22,  5.77it/s]Ref scores:  18%|█▊        | 178/1000 [00:39<02:32,  5.37it/s]Ref scores:  18%|█▊        | 179/1000 [00:39<02:41,  5.08it/s]Ref scores:  18%|█▊        | 180/1000 [00:39<02:41,  5.08it/s]Ref scores:  18%|█▊        | 181/1000 [00:40<02:32,  5.37it/s]Ref scores:  18%|█▊        | 182/1000 [00:40<02:32,  5.36it/s]Ref scores:  18%|█▊        | 183/1000 [00:40<02:40,  5.09it/s]Ref scores:  18%|█▊        | 184/1000 [00:40<02:31,  5.39it/s]Ref scores:  18%|█▊        | 185/1000 [00:40<02:46,  4.90it/s]Ref scores:  19%|█▊        | 186/1000 [00:41<02:29,  5.43it/s]Ref scores:  19%|█▊        | 187/1000 [00:41<02:18,  5.89it/s]Ref scores:  19%|█▉        | 188/1000 [00:41<02:30,  5.40it/s]Ref scores:  19%|█▉        | 189/1000 [00:41<02:38,  5.11it/s]Ref scores:  19%|█▉        | 190/1000 [00:41<02:37,  5.14it/s]Ref scores:  19%|█▉        | 191/1000 [00:41<02:27,  5.48it/s]Ref scores:  19%|█▉        | 192/1000 [00:42<02:22,  5.69it/s]Ref scores:  19%|█▉        | 193/1000 [00:42<02:13,  6.06it/s]Ref scores:  19%|█▉        | 194/1000 [00:42<02:06,  6.40it/s]Ref scores:  20%|█▉        | 195/1000 [00:42<02:13,  6.03it/s]Ref scores:  20%|█▉        | 196/1000 [00:42<02:19,  5.75it/s]Ref scores:  20%|█▉        | 197/1000 [00:42<02:22,  5.62it/s]Ref scores:  20%|█▉        | 198/1000 [00:43<02:18,  5.77it/s]Ref scores:  20%|█▉        | 199/1000 [00:43<02:14,  5.96it/s]Ref scores:  20%|██        | 200/1000 [00:43<02:12,  6.02it/s]Ref scores:  20%|██        | 201/1000 [00:43<02:32,  5.24it/s]Ref scores:  20%|██        | 202/1000 [00:43<02:23,  5.55it/s]Ref scores:  20%|██        | 203/1000 [00:44<02:33,  5.20it/s]Ref scores:  20%|██        | 204/1000 [00:44<02:13,  5.97it/s]Ref scores:  20%|██        | 205/1000 [00:44<02:18,  5.74it/s]Ref scores:  21%|██        | 206/1000 [00:44<02:28,  5.35it/s]Ref scores:  21%|██        | 207/1000 [00:44<02:22,  5.56it/s]Ref scores:  21%|██        | 208/1000 [00:44<02:06,  6.26it/s]Ref scores:  21%|██        | 209/1000 [00:45<02:13,  5.91it/s]Ref scores:  21%|██        | 210/1000 [00:45<02:05,  6.28it/s]Ref scores:  21%|██        | 211/1000 [00:45<02:13,  5.91it/s]Ref scores:  21%|██        | 212/1000 [00:45<02:25,  5.40it/s]Ref scores:  21%|██▏       | 213/1000 [00:45<02:34,  5.11it/s]Ref scores:  21%|██▏       | 214/1000 [00:46<02:39,  4.92it/s]Ref scores:  22%|██▏       | 215/1000 [00:46<02:36,  5.02it/s]Ref scores:  22%|██▏       | 216/1000 [00:46<02:34,  5.06it/s]Ref scores:  22%|██▏       | 217/1000 [00:46<02:26,  5.36it/s]Ref scores:  22%|██▏       | 218/1000 [00:46<02:26,  5.33it/s]Ref scores:  22%|██▏       | 219/1000 [00:46<02:08,  6.08it/s]Ref scores:  22%|██▏       | 220/1000 [00:47<02:15,  5.76it/s]Ref scores:  22%|██▏       | 221/1000 [00:47<02:10,  5.97it/s]Ref scores:  22%|██▏       | 222/1000 [00:47<02:02,  6.33it/s]Ref scores:  22%|██▏       | 223/1000 [00:47<02:09,  6.01it/s]Ref scores:  22%|██▏       | 224/1000 [00:47<02:01,  6.38it/s]Ref scores:  22%|██▎       | 225/1000 [00:47<01:56,  6.64it/s]Ref scores:  23%|██▎       | 226/1000 [00:48<02:05,  6.15it/s]Ref scores:  23%|██▎       | 227/1000 [00:48<02:03,  6.26it/s]Ref scores:  23%|██▎       | 228/1000 [00:48<02:11,  5.87it/s]Ref scores:  23%|██▎       | 229/1000 [00:48<02:22,  5.42it/s]Ref scores:  23%|██▎       | 230/1000 [00:48<02:15,  5.70it/s]Ref scores:  23%|██▎       | 231/1000 [00:48<02:31,  5.06it/s]Ref scores:  23%|██▎       | 232/1000 [00:49<02:30,  5.09it/s]Ref scores:  23%|██▎       | 233/1000 [00:49<02:35,  4.92it/s]Ref scores:  23%|██▎       | 234/1000 [00:49<02:39,  4.80it/s]Ref scores:  24%|██▎       | 235/1000 [00:49<02:36,  4.88it/s]Ref scores:  24%|██▎       | 236/1000 [00:49<02:25,  5.24it/s]Ref scores:  24%|██▎       | 237/1000 [00:50<02:19,  5.47it/s]Ref scores:  24%|██▍       | 238/1000 [00:50<02:27,  5.16it/s]Ref scores:  24%|██▍       | 239/1000 [00:50<02:19,  5.47it/s]Ref scores:  24%|██▍       | 240/1000 [00:50<02:27,  5.16it/s]Ref scores:  24%|██▍       | 241/1000 [00:50<02:14,  5.64it/s]Ref scores:  24%|██▍       | 242/1000 [00:51<02:09,  5.84it/s]Ref scores:  24%|██▍       | 243/1000 [00:51<02:06,  6.00it/s]Ref scores:  24%|██▍       | 244/1000 [00:51<02:02,  6.16it/s]Ref scores:  24%|██▍       | 245/1000 [00:51<01:56,  6.48it/s]Ref scores:  25%|██▍       | 246/1000 [00:51<02:04,  6.05it/s]Ref scores:  25%|██▍       | 247/1000 [00:51<02:23,  5.26it/s]Ref scores:  25%|██▍       | 248/1000 [00:52<02:22,  5.29it/s]Ref scores:  25%|██▍       | 249/1000 [00:52<02:29,  5.04it/s]Ref scores:  25%|██▌       | 250/1000 [00:52<02:20,  5.34it/s]Ref scores:  25%|██▌       | 251/1000 [00:52<02:27,  5.09it/s]Ref scores:  25%|██▌       | 252/1000 [00:52<02:17,  5.45it/s]Ref scores:  25%|██▌       | 253/1000 [00:53<02:24,  5.16it/s]Ref scores:  25%|██▌       | 254/1000 [00:53<02:25,  5.14it/s]Ref scores:  26%|██▌       | 255/1000 [00:53<02:12,  5.64it/s]Ref scores:  26%|██▌       | 256/1000 [00:53<02:15,  5.48it/s]Ref scores:  26%|██▌       | 257/1000 [00:53<02:46,  4.47it/s]Ref scores:  26%|██▌       | 258/1000 [00:54<02:30,  4.92it/s]Ref scores:  26%|██▌       | 259/1000 [00:54<02:28,  4.98it/s]Ref scores:  26%|██▌       | 260/1000 [00:54<02:26,  5.05it/s]Ref scores:  26%|██▌       | 261/1000 [00:54<02:18,  5.33it/s]Ref scores:  26%|██▌       | 262/1000 [00:54<02:25,  5.08it/s]Ref scores:  26%|██▋       | 263/1000 [00:55<02:23,  5.13it/s]Ref scores:  26%|██▋       | 264/1000 [00:55<02:10,  5.62it/s]Ref scores:  26%|██▋       | 265/1000 [00:55<02:01,  6.03it/s]Ref scores:  27%|██▋       | 266/1000 [00:55<02:06,  5.79it/s]Ref scores:  27%|██▋       | 267/1000 [00:55<02:10,  5.63it/s]Ref scores:  27%|██▋       | 268/1000 [00:55<02:19,  5.26it/s]Ref scores:  27%|██▋       | 269/1000 [00:56<02:12,  5.51it/s]Ref scores:  27%|██▋       | 270/1000 [00:56<02:26,  4.99it/s]Ref scores:  27%|██▋       | 271/1000 [00:56<02:12,  5.52it/s]Ref scores:  27%|██▋       | 273/1000 [00:56<02:00,  6.05it/s]Ref scores:  27%|██▋       | 274/1000 [00:56<02:09,  5.60it/s]Ref scores:  28%|██▊       | 275/1000 [00:57<02:05,  5.79it/s]Ref scores:  28%|██▊       | 276/1000 [00:57<02:01,  5.97it/s]Ref scores:  28%|██▊       | 277/1000 [00:57<01:54,  6.29it/s]Ref scores:  28%|██▊       | 278/1000 [00:57<02:07,  5.67it/s]Ref scores:  28%|██▊       | 279/1000 [00:57<02:22,  5.07it/s]Ref scores:  28%|██▊       | 280/1000 [00:58<02:12,  5.42it/s]Ref scores:  28%|██▊       | 281/1000 [00:58<02:08,  5.60it/s]Ref scores:  28%|██▊       | 282/1000 [00:58<01:59,  6.02it/s]Ref scores:  28%|██▊       | 283/1000 [00:58<02:10,  5.48it/s]Ref scores:  28%|██▊       | 284/1000 [00:58<02:00,  5.93it/s]Ref scores:  28%|██▊       | 285/1000 [00:58<02:06,  5.67it/s]Ref scores:  29%|██▊       | 286/1000 [00:59<01:57,  6.07it/s]Ref scores:  29%|██▊       | 287/1000 [00:59<01:44,  6.81it/s]Ref scores:  29%|██▉       | 288/1000 [00:59<02:21,  5.04it/s]Ref scores:  29%|██▉       | 289/1000 [00:59<02:11,  5.40it/s]Ref scores:  29%|██▉       | 290/1000 [00:59<02:18,  5.11it/s]Ref scores:  29%|██▉       | 291/1000 [00:59<02:06,  5.62it/s]Ref scores:  29%|██▉       | 292/1000 [01:00<01:57,  6.04it/s]Ref scores:  29%|██▉       | 293/1000 [01:00<01:51,  6.34it/s]Ref scores:  29%|██▉       | 294/1000 [01:00<01:47,  6.58it/s]Ref scores:  30%|██▉       | 295/1000 [01:00<01:43,  6.80it/s]Ref scores:  30%|██▉       | 296/1000 [01:00<01:51,  6.29it/s]Ref scores:  30%|██▉       | 297/1000 [01:00<02:08,  5.47it/s]Ref scores:  30%|██▉       | 298/1000 [01:01<02:01,  5.79it/s]Ref scores:  30%|██▉       | 299/1000 [01:01<02:10,  5.38it/s]Ref scores:  30%|███       | 300/1000 [01:01<02:05,  5.59it/s]Ref scores:  30%|███       | 301/1000 [01:01<02:01,  5.75it/s]Ref scores:  30%|███       | 302/1000 [01:01<02:06,  5.54it/s]Ref scores:  30%|███       | 303/1000 [01:01<02:00,  5.77it/s]Ref scores:  30%|███       | 304/1000 [01:02<02:10,  5.34it/s]Ref scores:  30%|███       | 305/1000 [01:02<02:03,  5.65it/s]Ref scores:  31%|███       | 306/1000 [01:02<02:05,  5.53it/s]Ref scores:  31%|███       | 307/1000 [01:02<02:13,  5.18it/s]Ref scores:  31%|███       | 308/1000 [01:02<02:05,  5.50it/s]Ref scores:  31%|███       | 309/1000 [01:03<02:13,  5.18it/s]Ref scores:  31%|███       | 310/1000 [01:03<02:03,  5.60it/s]Ref scores:  31%|███       | 311/1000 [01:03<01:54,  6.04it/s]Ref scores:  31%|███       | 312/1000 [01:03<01:58,  5.80it/s]Ref scores:  31%|███▏      | 313/1000 [01:03<02:08,  5.36it/s]Ref scores:  31%|███▏      | 314/1000 [01:04<02:14,  5.10it/s]Ref scores:  32%|███▏      | 315/1000 [01:04<02:24,  4.73it/s]Ref scores:  32%|███▏      | 316/1000 [01:04<02:12,  5.16it/s]Ref scores:  32%|███▏      | 317/1000 [01:04<02:00,  5.65it/s]Ref scores:  32%|███▏      | 318/1000 [01:04<01:56,  5.86it/s]Ref scores:  32%|███▏      | 319/1000 [01:04<02:00,  5.63it/s]Ref scores:  32%|███▏      | 320/1000 [01:05<01:52,  6.05it/s]Ref scores:  32%|███▏      | 321/1000 [01:05<01:50,  6.15it/s]Ref scores:  32%|███▏      | 322/1000 [01:05<01:50,  6.12it/s]Ref scores:  32%|███▏      | 323/1000 [01:05<01:40,  6.74it/s]Ref scores:  32%|███▏      | 324/1000 [01:05<01:41,  6.66it/s]Ref scores:  32%|███▎      | 325/1000 [01:05<01:33,  7.20it/s]Ref scores:  33%|███▎      | 327/1000 [01:06<01:32,  7.30it/s]Ref scores:  33%|███▎      | 328/1000 [01:06<01:40,  6.66it/s]Ref scores:  33%|███▎      | 329/1000 [01:06<01:42,  6.53it/s]Ref scores:  33%|███▎      | 330/1000 [01:06<01:49,  6.10it/s]Ref scores:  33%|███▎      | 331/1000 [01:06<01:44,  6.43it/s]Ref scores:  33%|███▎      | 332/1000 [01:06<01:50,  6.04it/s]Ref scores:  33%|███▎      | 333/1000 [01:07<01:49,  6.11it/s]Ref scores:  33%|███▎      | 334/1000 [01:07<01:47,  6.19it/s]Ref scores:  34%|███▎      | 335/1000 [01:07<01:45,  6.28it/s]Ref scores:  34%|███▎      | 336/1000 [01:07<01:53,  5.87it/s]Ref scores:  34%|███▎      | 337/1000 [01:07<01:46,  6.24it/s]Ref scores:  34%|███▍      | 338/1000 [01:07<01:47,  6.18it/s]Ref scores:  34%|███▍      | 339/1000 [01:08<01:53,  5.83it/s]Ref scores:  34%|███▍      | 340/1000 [01:08<01:57,  5.62it/s]Ref scores:  34%|███▍      | 341/1000 [01:08<01:44,  6.33it/s]Ref scores:  34%|███▍      | 342/1000 [01:08<01:39,  6.59it/s]Ref scores:  34%|███▍      | 343/1000 [01:08<01:48,  6.08it/s]Ref scores:  34%|███▍      | 344/1000 [01:08<01:58,  5.51it/s]Ref scores:  34%|███▍      | 345/1000 [01:09<02:16,  4.79it/s]Ref scores:  35%|███▍      | 346/1000 [01:09<02:07,  5.13it/s]Ref scores:  35%|███▍      | 347/1000 [01:09<01:55,  5.64it/s]Ref scores:  35%|███▍      | 348/1000 [01:09<01:59,  5.47it/s]Ref scores:  35%|███▍      | 349/1000 [01:09<01:45,  6.20it/s]Ref scores:  35%|███▌      | 350/1000 [01:09<01:40,  6.49it/s]Ref scores:  35%|███▌      | 351/1000 [01:10<01:36,  6.71it/s]Ref scores:  35%|███▌      | 352/1000 [01:10<01:37,  6.62it/s]Ref scores:  35%|███▌      | 353/1000 [01:10<01:51,  5.82it/s]Ref scores:  35%|███▌      | 354/1000 [01:10<01:44,  6.16it/s]Ref scores:  36%|███▌      | 355/1000 [01:10<01:55,  5.58it/s]Ref scores:  36%|███▌      | 356/1000 [01:10<01:57,  5.48it/s]Ref scores:  36%|███▌      | 357/1000 [01:11<01:58,  5.41it/s]Ref scores:  36%|███▌      | 358/1000 [01:11<01:59,  5.37it/s]Ref scores:  36%|███▌      | 359/1000 [01:11<01:53,  5.63it/s]Ref scores:  36%|███▌      | 360/1000 [01:11<01:56,  5.48it/s]Ref scores:  36%|███▌      | 361/1000 [01:11<02:02,  5.20it/s]Ref scores:  36%|███▌      | 362/1000 [01:12<02:02,  5.22it/s]Ref scores:  36%|███▋      | 363/1000 [01:12<01:47,  5.94it/s]Ref scores:  36%|███▋      | 364/1000 [01:12<01:57,  5.42it/s]Ref scores:  36%|███▋      | 365/1000 [01:12<02:04,  5.11it/s]Ref scores:  37%|███▋      | 366/1000 [01:12<02:12,  4.78it/s]Ref scores:  37%|███▋      | 367/1000 [01:13<02:03,  5.12it/s]Ref scores:  37%|███▋      | 368/1000 [01:13<01:57,  5.38it/s]Ref scores:  37%|███▋      | 369/1000 [01:13<01:49,  5.76it/s]Ref scores:  37%|███▋      | 370/1000 [01:13<01:42,  6.12it/s]Ref scores:  37%|███▋      | 371/1000 [01:13<01:33,  6.75it/s]Ref scores:  37%|███▋      | 372/1000 [01:13<01:30,  6.91it/s]Ref scores:  37%|███▋      | 373/1000 [01:13<01:40,  6.27it/s]Ref scores:  37%|███▋      | 374/1000 [01:14<01:56,  5.36it/s]Ref scores:  38%|███▊      | 375/1000 [01:14<01:47,  5.82it/s]Ref scores:  38%|███▊      | 376/1000 [01:14<01:56,  5.37it/s]Ref scores:  38%|███▊      | 377/1000 [01:14<01:51,  5.59it/s]Ref scores:  38%|███▊      | 378/1000 [01:14<01:44,  5.97it/s]Ref scores:  38%|███▊      | 379/1000 [01:15<01:49,  5.67it/s]Ref scores:  38%|███▊      | 380/1000 [01:15<02:01,  5.12it/s]Ref scores:  38%|███▊      | 381/1000 [01:15<01:59,  5.17it/s]Ref scores:  38%|███▊      | 382/1000 [01:15<01:48,  5.69it/s]Ref scores:  38%|███▊      | 383/1000 [01:15<01:41,  6.05it/s]Ref scores:  38%|███▊      | 384/1000 [01:15<01:40,  6.16it/s]Ref scores:  38%|███▊      | 385/1000 [01:16<01:39,  6.19it/s]Ref scores:  39%|███▊      | 386/1000 [01:16<01:38,  6.26it/s]Ref scores:  39%|███▊      | 387/1000 [01:16<01:29,  6.88it/s]Ref scores:  39%|███▉      | 388/1000 [01:16<01:30,  6.75it/s]Ref scores:  39%|███▉      | 389/1000 [01:16<01:27,  6.95it/s]Ref scores:  39%|███▉      | 390/1000 [01:16<01:42,  5.96it/s]Ref scores:  39%|███▉      | 391/1000 [01:17<01:37,  6.27it/s]Ref scores:  39%|███▉      | 392/1000 [01:17<01:36,  6.30it/s]Ref scores:  39%|███▉      | 393/1000 [01:17<01:47,  5.67it/s]Ref scores:  39%|███▉      | 394/1000 [01:17<01:55,  5.26it/s]Ref scores:  40%|███▉      | 395/1000 [01:17<01:48,  5.56it/s]Ref scores:  40%|███▉      | 396/1000 [01:17<01:40,  6.01it/s]Ref scores:  40%|███▉      | 397/1000 [01:18<01:38,  6.12it/s]Ref scores:  40%|███▉      | 399/1000 [01:18<01:27,  6.88it/s]Ref scores:  40%|████      | 400/1000 [01:18<01:42,  5.84it/s]Ref scores:  40%|████      | 401/1000 [01:18<01:37,  6.16it/s]Ref scores:  40%|████      | 402/1000 [01:18<01:42,  5.83it/s]Ref scores:  40%|████      | 403/1000 [01:19<01:50,  5.41it/s]Ref scores:  40%|████      | 404/1000 [01:19<01:46,  5.61it/s]Ref scores:  40%|████      | 405/1000 [01:19<01:38,  6.01it/s]Ref scores:  41%|████      | 406/1000 [01:19<01:33,  6.33it/s]Ref scores:  41%|████      | 407/1000 [01:19<01:40,  5.91it/s]Ref scores:  41%|████      | 408/1000 [01:19<01:38,  5.99it/s]Ref scores:  41%|████      | 409/1000 [01:20<01:33,  6.33it/s]Ref scores:  41%|████      | 410/1000 [01:20<01:24,  6.99it/s]Ref scores:  41%|████      | 411/1000 [01:20<01:23,  7.05it/s]Ref scores:  41%|████      | 412/1000 [01:20<01:27,  6.76it/s]Ref scores:  41%|████▏     | 413/1000 [01:20<01:27,  6.67it/s]Ref scores:  41%|████▏     | 414/1000 [01:20<01:40,  5.84it/s]Ref scores:  42%|████▏     | 415/1000 [01:21<01:39,  5.91it/s]Ref scores:  42%|████▏     | 416/1000 [01:21<01:52,  5.19it/s]Ref scores:  42%|████▏     | 417/1000 [01:21<01:51,  5.22it/s]Ref scores:  42%|████▏     | 418/1000 [01:21<01:42,  5.69it/s]Ref scores:  42%|████▏     | 419/1000 [01:21<01:39,  5.83it/s]Ref scores:  42%|████▏     | 420/1000 [01:21<01:38,  5.90it/s]Ref scores:  42%|████▏     | 421/1000 [01:22<01:36,  5.98it/s]Ref scores:  42%|████▏     | 422/1000 [01:22<01:34,  6.09it/s]Ref scores:  42%|████▏     | 423/1000 [01:22<01:44,  5.53it/s]Ref scores:  42%|████▏     | 424/1000 [01:22<01:40,  5.71it/s]Ref scores:  42%|████▎     | 425/1000 [01:22<01:48,  5.29it/s]Ref scores:  43%|████▎     | 426/1000 [01:22<01:44,  5.51it/s]Ref scores:  43%|████▎     | 427/1000 [01:23<01:50,  5.19it/s]Ref scores:  43%|████▎     | 428/1000 [01:23<01:40,  5.69it/s]Ref scores:  43%|████▎     | 429/1000 [01:23<01:47,  5.30it/s]Ref scores:  43%|████▎     | 430/1000 [01:23<01:47,  5.28it/s]Ref scores:  43%|████▎     | 431/1000 [01:23<01:53,  5.03it/s]Ref scores:  43%|████▎     | 432/1000 [01:24<01:45,  5.39it/s]Ref scores:  43%|████▎     | 433/1000 [01:24<01:40,  5.66it/s]Ref scores:  43%|████▎     | 434/1000 [01:24<01:33,  6.06it/s]Ref scores:  44%|████▎     | 435/1000 [01:24<01:37,  5.81it/s]Ref scores:  44%|████▎     | 436/1000 [01:24<01:31,  6.16it/s]Ref scores:  44%|████▎     | 437/1000 [01:24<01:41,  5.55it/s]Ref scores:  44%|████▍     | 438/1000 [01:25<01:34,  5.97it/s]Ref scores:  44%|████▍     | 439/1000 [01:25<01:42,  5.47it/s]Ref scores:  44%|████▍     | 440/1000 [01:25<01:39,  5.65it/s]Ref scores:  44%|████▍     | 441/1000 [01:25<01:42,  5.47it/s]Ref scores:  44%|████▍     | 442/1000 [01:25<01:43,  5.41it/s]Ref scores:  44%|████▍     | 443/1000 [01:26<01:35,  5.84it/s]Ref scores:  44%|████▍     | 444/1000 [01:26<01:43,  5.37it/s]Ref scores:  44%|████▍     | 445/1000 [01:26<01:44,  5.29it/s]Ref scores:  45%|████▍     | 446/1000 [01:26<01:45,  5.27it/s]Ref scores:  45%|████▍     | 447/1000 [01:26<01:35,  5.77it/s]Ref scores:  45%|████▍     | 448/1000 [01:26<01:38,  5.60it/s]Ref scores:  45%|████▍     | 449/1000 [01:27<01:40,  5.51it/s]Ref scores:  45%|████▌     | 450/1000 [01:27<01:50,  4.96it/s]Ref scores:  45%|████▌     | 451/1000 [01:27<01:53,  4.83it/s]Ref scores:  45%|████▌     | 452/1000 [01:27<01:50,  4.95it/s]Ref scores:  45%|████▌     | 453/1000 [01:28<01:49,  4.99it/s]Ref scores:  45%|████▌     | 454/1000 [01:28<01:39,  5.49it/s]Ref scores:  46%|████▌     | 455/1000 [01:28<01:34,  5.75it/s]Ref scores:  46%|████▌     | 456/1000 [01:28<01:46,  5.09it/s]Ref scores:  46%|████▌     | 457/1000 [01:28<01:40,  5.43it/s]Ref scores:  46%|████▌     | 458/1000 [01:28<01:40,  5.37it/s]Ref scores:  46%|████▌     | 459/1000 [01:29<01:45,  5.12it/s]Ref scores:  46%|████▌     | 460/1000 [01:29<01:32,  5.85it/s]Ref scores:  46%|████▌     | 461/1000 [01:29<01:35,  5.63it/s]Ref scores:  46%|████▌     | 462/1000 [01:29<01:42,  5.26it/s]Ref scores:  46%|████▋     | 463/1000 [01:29<01:46,  5.04it/s]Ref scores:  46%|████▋     | 464/1000 [01:30<01:44,  5.12it/s]Ref scores:  46%|████▋     | 465/1000 [01:30<01:43,  5.16it/s]Ref scores:  47%|████▋     | 466/1000 [01:30<01:37,  5.49it/s]Ref scores:  47%|████▋     | 467/1000 [01:30<01:32,  5.75it/s]Ref scores:  47%|████▋     | 468/1000 [01:30<01:35,  5.59it/s]Ref scores:  47%|████▋     | 469/1000 [01:30<01:37,  5.45it/s]Ref scores:  47%|████▋     | 470/1000 [01:31<01:43,  5.14it/s]Ref scores:  47%|████▋     | 471/1000 [01:31<01:42,  5.18it/s]Ref scores:  47%|████▋     | 472/1000 [01:31<01:32,  5.69it/s]Ref scores:  47%|████▋     | 473/1000 [01:31<01:34,  5.55it/s]Ref scores:  48%|████▊     | 475/1000 [01:31<01:20,  6.55it/s]Ref scores:  48%|████▊     | 476/1000 [01:32<01:20,  6.52it/s]Ref scores:  48%|████▊     | 477/1000 [01:32<01:20,  6.48it/s]Ref scores:  48%|████▊     | 478/1000 [01:32<01:25,  6.07it/s]Ref scores:  48%|████▊     | 479/1000 [01:32<01:33,  5.56it/s]Ref scores:  48%|████▊     | 480/1000 [01:32<01:39,  5.25it/s]Ref scores:  48%|████▊     | 481/1000 [01:32<01:30,  5.74it/s]Ref scores:  48%|████▊     | 482/1000 [01:33<01:45,  4.93it/s]Ref scores:  48%|████▊     | 483/1000 [01:33<01:31,  5.68it/s]Ref scores:  48%|████▊     | 484/1000 [01:33<01:27,  5.88it/s]Ref scores:  48%|████▊     | 485/1000 [01:33<01:38,  5.24it/s]Ref scores:  49%|████▊     | 486/1000 [01:33<01:38,  5.24it/s]Ref scores:  49%|████▊     | 487/1000 [01:34<01:38,  5.21it/s]Ref scores:  49%|████▉     | 488/1000 [01:34<01:48,  4.73it/s]Ref scores:  49%|████▉     | 489/1000 [01:34<01:44,  4.88it/s]Ref scores:  49%|████▉     | 490/1000 [01:34<01:47,  4.75it/s]Ref scores:  49%|████▉     | 491/1000 [01:35<01:43,  4.89it/s]Ref scores:  49%|████▉     | 492/1000 [01:35<01:37,  5.21it/s]Ref scores:  49%|████▉     | 493/1000 [01:35<01:28,  5.71it/s]Ref scores:  49%|████▉     | 494/1000 [01:35<01:25,  5.89it/s]Ref scores:  50%|████▉     | 495/1000 [01:35<01:33,  5.41it/s]Ref scores:  50%|████▉     | 496/1000 [01:35<01:34,  5.33it/s]Ref scores:  50%|████▉     | 497/1000 [01:36<01:29,  5.63it/s]Ref scores:  50%|████▉     | 498/1000 [01:36<01:39,  5.03it/s]Ref scores:  50%|████▉     | 499/1000 [01:36<01:30,  5.54it/s]Ref scores:  50%|█████     | 500/1000 [01:36<01:26,  5.80it/s]Ref scores:  50%|█████     | 501/1000 [01:36<01:33,  5.33it/s]Ref scores:  50%|█████     | 502/1000 [01:36<01:26,  5.77it/s]Ref scores:  50%|█████     | 503/1000 [01:37<01:32,  5.35it/s]Ref scores:  50%|█████     | 504/1000 [01:37<01:25,  5.81it/s]Ref scores:  50%|█████     | 505/1000 [01:37<01:28,  5.58it/s]Ref scores:  51%|█████     | 506/1000 [01:37<01:34,  5.21it/s]Ref scores:  51%|█████     | 507/1000 [01:37<01:41,  4.85it/s]Ref scores:  51%|█████     | 508/1000 [01:38<01:31,  5.40it/s]Ref scores:  51%|█████     | 509/1000 [01:38<01:26,  5.66it/s]Ref scores:  51%|█████     | 510/1000 [01:38<01:24,  5.82it/s]Ref scores:  51%|█████     | 511/1000 [01:38<01:21,  6.01it/s]Ref scores:  51%|█████     | 512/1000 [01:38<01:24,  5.79it/s]Ref scores:  51%|█████▏    | 513/1000 [01:38<01:30,  5.35it/s]Ref scores:  51%|█████▏    | 514/1000 [01:39<01:26,  5.65it/s]Ref scores:  52%|█████▏    | 515/1000 [01:39<01:23,  5.79it/s]Ref scores:  52%|█████▏    | 516/1000 [01:39<01:26,  5.62it/s]Ref scores:  52%|█████▏    | 517/1000 [01:39<01:32,  5.24it/s]Ref scores:  52%|█████▏    | 518/1000 [01:39<01:19,  6.06it/s]Ref scores:  52%|█████▏    | 519/1000 [01:39<01:17,  6.17it/s]Ref scores:  52%|█████▏    | 520/1000 [01:40<01:21,  5.87it/s]Ref scores:  52%|█████▏    | 521/1000 [01:40<01:25,  5.61it/s]Ref scores:  52%|█████▏    | 522/1000 [01:40<01:21,  5.84it/s]Ref scores:  52%|█████▏    | 523/1000 [01:40<01:20,  5.91it/s]Ref scores:  52%|█████▏    | 524/1000 [01:40<01:27,  5.43it/s]Ref scores:  52%|█████▎    | 525/1000 [01:41<01:36,  4.92it/s]Ref scores:  53%|█████▎    | 526/1000 [01:41<01:30,  5.23it/s]Ref scores:  53%|█████▎    | 527/1000 [01:41<01:34,  4.98it/s]Ref scores:  53%|█████▎    | 528/1000 [01:41<01:25,  5.52it/s]Ref scores:  53%|█████▎    | 529/1000 [01:41<01:26,  5.44it/s]Ref scores:  53%|█████▎    | 530/1000 [01:41<01:23,  5.64it/s]Ref scores:  53%|█████▎    | 531/1000 [01:42<01:17,  6.07it/s]Ref scores:  53%|█████▎    | 532/1000 [01:42<01:24,  5.52it/s]Ref scores:  53%|█████▎    | 533/1000 [01:42<01:30,  5.19it/s]Ref scores:  53%|█████▎    | 534/1000 [01:42<01:30,  5.17it/s]Ref scores:  54%|█████▎    | 535/1000 [01:42<01:29,  5.19it/s]Ref scores:  54%|█████▎    | 536/1000 [01:43<01:33,  4.97it/s]Ref scores:  54%|█████▎    | 537/1000 [01:43<01:32,  5.02it/s]Ref scores:  54%|█████▍    | 538/1000 [01:43<01:23,  5.56it/s]Ref scores:  54%|█████▍    | 539/1000 [01:43<01:24,  5.47it/s]Ref scores:  54%|█████▍    | 540/1000 [01:43<01:20,  5.70it/s]Ref scores:  54%|█████▍    | 541/1000 [01:44<01:22,  5.57it/s]Ref scores:  54%|█████▍    | 542/1000 [01:44<01:19,  5.75it/s]Ref scores:  54%|█████▍    | 543/1000 [01:44<01:14,  6.16it/s]Ref scores:  54%|█████▍    | 544/1000 [01:44<01:13,  6.17it/s]Ref scores:  55%|█████▍    | 545/1000 [01:44<01:18,  5.81it/s]Ref scores:  55%|█████▍    | 546/1000 [01:44<01:28,  5.13it/s]Ref scores:  55%|█████▍    | 547/1000 [01:45<01:28,  5.13it/s]Ref scores:  55%|█████▍    | 548/1000 [01:45<01:19,  5.66it/s]Ref scores:  55%|█████▍    | 549/1000 [01:45<01:11,  6.30it/s]Ref scores:  55%|█████▌    | 550/1000 [01:45<01:19,  5.63it/s]Ref scores:  55%|█████▌    | 551/1000 [01:45<01:17,  5.79it/s]Ref scores:  55%|█████▌    | 552/1000 [01:45<01:12,  6.15it/s]Ref scores:  55%|█████▌    | 553/1000 [01:46<01:15,  5.89it/s]Ref scores:  55%|█████▌    | 554/1000 [01:46<01:11,  6.28it/s]Ref scores:  56%|█████▌    | 555/1000 [01:46<01:10,  6.34it/s]Ref scores:  56%|█████▌    | 556/1000 [01:46<01:20,  5.48it/s]Ref scores:  56%|█████▌    | 557/1000 [01:46<01:25,  5.16it/s]Ref scores:  56%|█████▌    | 558/1000 [01:47<01:24,  5.21it/s]Ref scores:  56%|█████▌    | 559/1000 [01:47<01:17,  5.69it/s]Ref scores:  56%|█████▌    | 560/1000 [01:47<01:15,  5.80it/s]Ref scores:  56%|█████▌    | 561/1000 [01:47<01:21,  5.37it/s]Ref scores:  56%|█████▌    | 562/1000 [01:47<01:18,  5.58it/s]Ref scores:  56%|█████▋    | 563/1000 [01:47<01:13,  5.98it/s]Ref scores:  56%|█████▋    | 564/1000 [01:47<01:09,  6.31it/s]Ref scores:  56%|█████▋    | 565/1000 [01:48<01:05,  6.60it/s]Ref scores:  57%|█████▋    | 566/1000 [01:48<01:07,  6.43it/s]Ref scores:  57%|█████▋    | 567/1000 [01:48<01:15,  5.73it/s]Ref scores:  57%|█████▋    | 568/1000 [01:48<01:10,  6.12it/s]Ref scores:  57%|█████▋    | 569/1000 [01:48<01:06,  6.45it/s]Ref scores:  57%|█████▋    | 570/1000 [01:48<01:03,  6.73it/s]Ref scores:  57%|█████▋    | 571/1000 [01:49<01:05,  6.55it/s]Ref scores:  57%|█████▋    | 572/1000 [01:49<01:03,  6.77it/s]Ref scores:  57%|█████▋    | 573/1000 [01:49<01:08,  6.25it/s]Ref scores:  57%|█████▋    | 574/1000 [01:49<01:08,  6.22it/s]Ref scores:  57%|█████▊    | 575/1000 [01:49<01:08,  6.19it/s]Ref scores:  58%|█████▊    | 576/1000 [01:49<01:05,  6.49it/s]Ref scores:  58%|█████▊    | 577/1000 [01:50<01:10,  6.01it/s]Ref scores:  58%|█████▊    | 578/1000 [01:50<01:06,  6.36it/s]Ref scores:  58%|█████▊    | 579/1000 [01:50<01:07,  6.26it/s]Ref scores:  58%|█████▊    | 580/1000 [01:50<01:07,  6.22it/s]Ref scores:  58%|█████▊    | 581/1000 [01:50<01:04,  6.49it/s]Ref scores:  58%|█████▊    | 582/1000 [01:50<01:13,  5.72it/s]Ref scores:  58%|█████▊    | 583/1000 [01:51<01:05,  6.39it/s]Ref scores:  58%|█████▊    | 584/1000 [01:51<01:09,  6.01it/s]Ref scores:  58%|█████▊    | 585/1000 [01:51<01:05,  6.30it/s]Ref scores:  59%|█████▊    | 586/1000 [01:51<01:16,  5.40it/s]Ref scores:  59%|█████▊    | 587/1000 [01:51<01:12,  5.68it/s]Ref scores:  59%|█████▉    | 588/1000 [01:51<01:08,  6.05it/s]Ref scores:  59%|█████▉    | 589/1000 [01:52<01:06,  6.14it/s]Ref scores:  59%|█████▉    | 590/1000 [01:52<01:10,  5.85it/s]Ref scores:  59%|█████▉    | 591/1000 [01:52<01:08,  5.95it/s]Ref scores:  59%|█████▉    | 592/1000 [01:52<01:07,  6.01it/s]Ref scores:  59%|█████▉    | 593/1000 [01:52<01:06,  6.12it/s]Ref scores:  59%|█████▉    | 594/1000 [01:52<01:03,  6.42it/s]Ref scores:  60%|█████▉    | 595/1000 [01:53<01:04,  6.31it/s]Ref scores:  60%|█████▉    | 596/1000 [01:53<01:01,  6.58it/s]Ref scores:  60%|█████▉    | 597/1000 [01:53<01:01,  6.52it/s]Ref scores:  60%|█████▉    | 598/1000 [01:53<01:09,  5.76it/s]Ref scores:  60%|█████▉    | 599/1000 [01:53<01:11,  5.61it/s]Ref scores:  60%|██████    | 600/1000 [01:53<01:06,  6.02it/s]Ref scores:  60%|██████    | 601/1000 [01:54<01:12,  5.50it/s]Ref scores:  60%|██████    | 602/1000 [01:54<01:06,  5.94it/s]Ref scores:  60%|██████    | 603/1000 [01:54<01:12,  5.44it/s]Ref scores:  60%|██████    | 604/1000 [01:54<01:13,  5.38it/s]Ref scores:  60%|██████    | 605/1000 [01:54<01:07,  5.85it/s]Ref scores:  61%|██████    | 606/1000 [01:54<01:13,  5.39it/s]Ref scores:  61%|██████    | 607/1000 [01:55<01:09,  5.67it/s]Ref scores:  61%|██████    | 608/1000 [01:55<01:11,  5.52it/s]Ref scores:  61%|██████    | 609/1000 [01:55<01:08,  5.74it/s]Ref scores:  61%|██████    | 610/1000 [01:55<01:05,  5.94it/s]Ref scores:  61%|██████    | 611/1000 [01:55<01:11,  5.44it/s]Ref scores:  61%|██████    | 612/1000 [01:55<01:03,  6.15it/s]Ref scores:  61%|██████▏   | 613/1000 [01:56<01:09,  5.58it/s]Ref scores:  61%|██████▏   | 614/1000 [01:56<01:06,  5.81it/s]Ref scores:  62%|██████▏   | 615/1000 [01:56<01:05,  5.89it/s]Ref scores:  62%|██████▏   | 616/1000 [01:56<01:07,  5.69it/s]Ref scores:  62%|██████▏   | 617/1000 [01:56<01:08,  5.56it/s]Ref scores:  62%|██████▏   | 618/1000 [01:57<01:10,  5.41it/s]Ref scores:  62%|██████▏   | 619/1000 [01:57<01:05,  5.83it/s]Ref scores:  62%|██████▏   | 620/1000 [01:57<00:58,  6.48it/s]Ref scores:  62%|██████▏   | 621/1000 [01:57<00:58,  6.47it/s]Ref scores:  62%|██████▏   | 622/1000 [01:57<00:56,  6.66it/s]Ref scores:  62%|██████▏   | 623/1000 [01:57<00:57,  6.52it/s]Ref scores:  62%|██████▏   | 624/1000 [01:58<01:05,  5.78it/s]Ref scores:  62%|██████▎   | 625/1000 [01:58<01:06,  5.61it/s]Ref scores:  63%|██████▎   | 626/1000 [01:58<01:11,  5.23it/s]Ref scores:  63%|██████▎   | 627/1000 [01:58<01:07,  5.52it/s]Ref scores:  63%|██████▎   | 628/1000 [01:58<01:05,  5.71it/s]Ref scores:  63%|██████▎   | 629/1000 [01:58<01:00,  6.10it/s]Ref scores:  63%|██████▎   | 630/1000 [01:59<00:57,  6.41it/s]Ref scores:  63%|██████▎   | 631/1000 [01:59<00:57,  6.41it/s]Ref scores:  63%|██████▎   | 632/1000 [01:59<00:58,  6.34it/s]Ref scores:  63%|██████▎   | 633/1000 [01:59<01:01,  5.92it/s]Ref scores:  63%|██████▎   | 634/1000 [01:59<01:07,  5.43it/s]Ref scores:  64%|██████▎   | 635/1000 [01:59<01:11,  5.14it/s]Ref scores:  64%|██████▎   | 637/1000 [02:00<01:02,  5.77it/s]Ref scores:  64%|██████▍   | 638/1000 [02:00<01:04,  5.61it/s]Ref scores:  64%|██████▍   | 639/1000 [02:00<01:10,  5.12it/s]Ref scores:  64%|██████▍   | 640/1000 [02:00<01:02,  5.79it/s]Ref scores:  64%|██████▍   | 641/1000 [02:01<01:06,  5.39it/s]Ref scores:  64%|██████▍   | 642/1000 [02:01<01:07,  5.29it/s]Ref scores:  64%|██████▍   | 643/1000 [02:01<01:14,  4.81it/s]Ref scores:  64%|██████▍   | 644/1000 [02:01<01:18,  4.52it/s]Ref scores:  64%|██████▍   | 645/1000 [02:01<01:12,  4.92it/s]Ref scores:  65%|██████▍   | 646/1000 [02:02<01:11,  4.96it/s]Ref scores:  65%|██████▍   | 647/1000 [02:02<01:06,  5.32it/s]Ref scores:  65%|██████▍   | 648/1000 [02:02<01:03,  5.53it/s]Ref scores:  65%|██████▍   | 649/1000 [02:02<01:01,  5.70it/s]Ref scores:  65%|██████▌   | 650/1000 [02:02<01:06,  5.25it/s]Ref scores:  65%|██████▌   | 652/1000 [02:03<01:00,  5.75it/s]Ref scores:  65%|██████▌   | 653/1000 [02:03<01:03,  5.46it/s]Ref scores:  65%|██████▌   | 654/1000 [02:03<01:07,  5.12it/s]Ref scores:  66%|██████▌   | 655/1000 [02:03<01:02,  5.53it/s]Ref scores:  66%|██████▌   | 656/1000 [02:03<01:00,  5.70it/s]Ref scores:  66%|██████▌   | 657/1000 [02:04<00:59,  5.77it/s]Ref scores:  66%|██████▌   | 658/1000 [02:04<00:52,  6.47it/s]Ref scores:  66%|██████▌   | 659/1000 [02:04<00:51,  6.60it/s]Ref scores:  66%|██████▌   | 660/1000 [02:04<00:52,  6.48it/s]Ref scores:  66%|██████▌   | 661/1000 [02:04<00:56,  5.96it/s]Ref scores:  66%|██████▌   | 662/1000 [02:04<01:02,  5.41it/s]Ref scores:  66%|██████▋   | 663/1000 [02:05<01:06,  5.09it/s]Ref scores:  66%|██████▋   | 664/1000 [02:05<01:06,  5.07it/s]Ref scores:  66%|██████▋   | 665/1000 [02:05<01:06,  5.03it/s]Ref scores:  67%|██████▋   | 666/1000 [02:05<01:02,  5.35it/s]Ref scores:  67%|██████▋   | 667/1000 [02:05<01:03,  5.22it/s]Ref scores:  67%|██████▋   | 668/1000 [02:06<01:01,  5.43it/s]Ref scores:  67%|██████▋   | 669/1000 [02:06<01:02,  5.28it/s]Ref scores:  67%|██████▋   | 670/1000 [02:06<01:05,  5.00it/s]Ref scores:  67%|██████▋   | 671/1000 [02:06<01:06,  4.98it/s]Ref scores:  67%|██████▋   | 672/1000 [02:06<01:05,  4.97it/s]Ref scores:  67%|██████▋   | 673/1000 [02:07<01:05,  4.99it/s]Ref scores:  67%|██████▋   | 674/1000 [02:07<01:01,  5.27it/s]Ref scores:  68%|██████▊   | 675/1000 [02:07<01:02,  5.18it/s]Ref scores:  68%|██████▊   | 676/1000 [02:07<01:05,  4.91it/s]Ref scores:  68%|██████▊   | 677/1000 [02:07<00:59,  5.42it/s]Ref scores:  68%|██████▊   | 678/1000 [02:07<01:00,  5.28it/s]Ref scores:  68%|██████▊   | 679/1000 [02:08<00:57,  5.54it/s]Ref scores:  68%|██████▊   | 680/1000 [02:08<00:53,  5.94it/s]Ref scores:  68%|██████▊   | 681/1000 [02:08<00:56,  5.64it/s]Ref scores:  68%|██████▊   | 682/1000 [02:08<01:01,  5.21it/s]Ref scores:  68%|██████▊   | 683/1000 [02:08<00:57,  5.48it/s]Ref scores:  68%|██████▊   | 684/1000 [02:09<00:58,  5.37it/s]Ref scores:  68%|██████▊   | 685/1000 [02:09<01:02,  5.03it/s]Ref scores:  69%|██████▊   | 686/1000 [02:09<00:56,  5.52it/s]Ref scores:  69%|██████▊   | 687/1000 [02:09<00:58,  5.39it/s]Ref scores:  69%|██████▉   | 688/1000 [02:09<00:55,  5.59it/s]Ref scores:  69%|██████▉   | 689/1000 [02:10<01:00,  5.16it/s]Ref scores:  69%|██████▉   | 690/1000 [02:10<01:02,  4.92it/s]Ref scores:  69%|██████▉   | 691/1000 [02:10<01:02,  4.98it/s]Ref scores:  69%|██████▉   | 692/1000 [02:10<01:04,  4.79it/s]Ref scores:  69%|██████▉   | 693/1000 [02:10<01:03,  4.83it/s]Ref scores:  69%|██████▉   | 694/1000 [02:11<00:57,  5.33it/s]Ref scores:  70%|██████▉   | 695/1000 [02:11<01:03,  4.80it/s]Ref scores:  70%|██████▉   | 696/1000 [02:11<00:55,  5.52it/s]Ref scores:  70%|██████▉   | 697/1000 [02:11<00:51,  5.90it/s]Ref scores:  70%|██████▉   | 698/1000 [02:11<00:53,  5.60it/s]Ref scores:  70%|██████▉   | 699/1000 [02:11<00:52,  5.75it/s]Ref scores:  70%|███████   | 700/1000 [02:12<00:56,  5.28it/s]Ref scores:  70%|███████   | 701/1000 [02:12<00:57,  5.23it/s]Ref scores:  70%|███████   | 702/1000 [02:12<01:00,  4.97it/s]Ref scores:  70%|███████   | 703/1000 [02:12<00:59,  5.00it/s]Ref scores:  70%|███████   | 704/1000 [02:12<00:51,  5.73it/s]Ref scores:  70%|███████   | 705/1000 [02:12<00:48,  6.05it/s]Ref scores:  71%|███████   | 706/1000 [02:13<00:46,  6.35it/s]Ref scores:  71%|███████   | 707/1000 [02:13<00:49,  5.94it/s]Ref scores:  71%|███████   | 708/1000 [02:13<00:46,  6.27it/s]Ref scores:  71%|███████   | 709/1000 [02:13<00:49,  5.86it/s]Ref scores:  71%|███████   | 710/1000 [02:13<00:48,  5.99it/s]Ref scores:  71%|███████   | 711/1000 [02:14<00:53,  5.42it/s]Ref scores:  71%|███████   | 712/1000 [02:14<00:56,  5.09it/s]Ref scores:  71%|███████▏  | 713/1000 [02:14<00:59,  4.80it/s]Ref scores:  71%|███████▏  | 714/1000 [02:14<01:01,  4.67it/s]Ref scores:  72%|███████▏  | 715/1000 [02:14<00:57,  4.97it/s]Ref scores:  72%|███████▏  | 716/1000 [02:15<00:59,  4.81it/s]Ref scores:  72%|███████▏  | 717/1000 [02:15<00:58,  4.88it/s]Ref scores:  72%|███████▏  | 718/1000 [02:15<00:57,  4.92it/s]Ref scores:  72%|███████▏  | 719/1000 [02:15<00:56,  4.95it/s]Ref scores:  72%|███████▏  | 720/1000 [02:15<00:56,  4.97it/s]Ref scores:  72%|███████▏  | 721/1000 [02:16<00:55,  5.00it/s]Ref scores:  72%|███████▏  | 722/1000 [02:16<00:55,  5.03it/s]Ref scores:  72%|███████▏  | 723/1000 [02:16<00:54,  5.05it/s]Ref scores:  72%|███████▏  | 724/1000 [02:16<00:57,  4.84it/s]Ref scores:  72%|███████▎  | 725/1000 [02:16<01:00,  4.56it/s]Ref scores:  73%|███████▎  | 726/1000 [02:17<00:53,  5.09it/s]Ref scores:  73%|███████▎  | 727/1000 [02:17<00:56,  4.86it/s]Ref scores:  73%|███████▎  | 728/1000 [02:17<00:52,  5.19it/s]Ref scores:  73%|███████▎  | 729/1000 [02:17<00:52,  5.15it/s]Ref scores:  73%|███████▎  | 730/1000 [02:17<00:52,  5.13it/s]Ref scores:  73%|███████▎  | 731/1000 [02:18<00:48,  5.57it/s]Ref scores:  73%|███████▎  | 732/1000 [02:18<00:49,  5.42it/s]Ref scores:  73%|███████▎  | 733/1000 [02:18<00:52,  5.06it/s]Ref scores:  73%|███████▎  | 734/1000 [02:18<00:48,  5.52it/s]Ref scores:  74%|███████▎  | 735/1000 [02:18<00:51,  5.13it/s]Ref scores:  74%|███████▎  | 736/1000 [02:19<00:51,  5.14it/s]Ref scores:  74%|███████▎  | 737/1000 [02:19<00:51,  5.15it/s]Ref scores:  74%|███████▍  | 738/1000 [02:19<00:46,  5.60it/s]Ref scores:  74%|███████▍  | 739/1000 [02:19<00:50,  5.19it/s]Ref scores:  74%|███████▍  | 740/1000 [02:19<00:47,  5.47it/s]Ref scores:  74%|███████▍  | 741/1000 [02:19<00:45,  5.66it/s]Ref scores:  74%|███████▍  | 742/1000 [02:20<00:46,  5.51it/s]Ref scores:  74%|███████▍  | 743/1000 [02:20<00:52,  4.90it/s]Ref scores:  74%|███████▍  | 744/1000 [02:20<00:47,  5.36it/s]Ref scores:  74%|███████▍  | 745/1000 [02:20<00:44,  5.78it/s]Ref scores:  75%|███████▍  | 746/1000 [02:20<00:47,  5.31it/s]Ref scores:  75%|███████▍  | 747/1000 [02:21<00:50,  4.98it/s]Ref scores:  75%|███████▍  | 748/1000 [02:21<00:48,  5.16it/s]Ref scores:  75%|███████▍  | 749/1000 [02:21<00:49,  5.12it/s]Ref scores:  75%|███████▌  | 750/1000 [02:21<00:44,  5.59it/s]Ref scores:  75%|███████▌  | 751/1000 [02:21<00:41,  5.97it/s]Ref scores:  75%|███████▌  | 752/1000 [02:21<00:40,  6.06it/s]Ref scores:  75%|███████▌  | 753/1000 [02:22<00:39,  6.29it/s]Ref scores:  75%|███████▌  | 754/1000 [02:22<00:39,  6.18it/s]Ref scores:  76%|███████▌  | 755/1000 [02:22<00:38,  6.42it/s]Ref scores:  76%|███████▌  | 756/1000 [02:22<00:45,  5.42it/s]Ref scores:  76%|███████▌  | 757/1000 [02:22<00:45,  5.31it/s]Ref scores:  76%|███████▌  | 758/1000 [02:23<00:48,  5.01it/s]Ref scores:  76%|███████▌  | 759/1000 [02:23<00:44,  5.47it/s]Ref scores:  76%|███████▌  | 760/1000 [02:23<00:41,  5.84it/s]Ref scores:  76%|███████▌  | 761/1000 [02:23<00:38,  6.18it/s]Ref scores:  76%|███████▌  | 762/1000 [02:23<00:41,  5.80it/s]Ref scores:  76%|███████▋  | 763/1000 [02:23<00:42,  5.55it/s]Ref scores:  76%|███████▋  | 764/1000 [02:24<00:45,  5.15it/s]Ref scores:  76%|███████▋  | 765/1000 [02:24<00:43,  5.35it/s]Ref scores:  77%|███████▋  | 766/1000 [02:24<00:42,  5.51it/s]Ref scores:  77%|███████▋  | 767/1000 [02:24<00:39,  5.94it/s]Ref scores:  77%|███████▋  | 768/1000 [02:24<00:43,  5.36it/s]Ref scores:  77%|███████▋  | 769/1000 [02:25<00:45,  5.04it/s]Ref scores:  77%|███████▋  | 770/1000 [02:25<00:43,  5.29it/s]Ref scores:  77%|███████▋  | 771/1000 [02:25<00:43,  5.21it/s]Ref scores:  77%|███████▋  | 772/1000 [02:25<00:38,  5.96it/s]Ref scores:  77%|███████▋  | 773/1000 [02:25<00:36,  6.25it/s]Ref scores:  77%|███████▋  | 774/1000 [02:25<00:36,  6.16it/s]Ref scores:  78%|███████▊  | 775/1000 [02:25<00:37,  6.08it/s]Ref scores:  78%|███████▊  | 776/1000 [02:26<00:35,  6.34it/s]Ref scores:  78%|███████▊  | 777/1000 [02:26<00:39,  5.58it/s]Ref scores:  78%|███████▊  | 778/1000 [02:26<00:39,  5.69it/s]Ref scores:  78%|███████▊  | 779/1000 [02:26<00:40,  5.51it/s]Ref scores:  78%|███████▊  | 780/1000 [02:26<00:39,  5.64it/s]Ref scores:  78%|███████▊  | 781/1000 [02:27<00:42,  5.19it/s]Ref scores:  78%|███████▊  | 782/1000 [02:27<00:45,  4.74it/s]Ref scores:  78%|███████▊  | 783/1000 [02:27<00:41,  5.27it/s]Ref scores:  78%|███████▊  | 784/1000 [02:27<00:37,  5.71it/s]Ref scores:  78%|███████▊  | 785/1000 [02:27<00:38,  5.53it/s]Ref scores:  79%|███████▊  | 786/1000 [02:28<00:39,  5.41it/s]Ref scores:  79%|███████▊  | 787/1000 [02:28<00:40,  5.26it/s]Ref scores:  79%|███████▉  | 788/1000 [02:28<00:42,  5.00it/s]Ref scores:  79%|███████▉  | 789/1000 [02:28<00:40,  5.25it/s]Ref scores:  79%|███████▉  | 790/1000 [02:28<00:38,  5.52it/s]Ref scores:  79%|███████▉  | 791/1000 [02:29<00:42,  4.97it/s]Ref scores:  79%|███████▉  | 792/1000 [02:29<00:39,  5.24it/s]Ref scores:  79%|███████▉  | 793/1000 [02:29<00:34,  5.95it/s]Ref scores:  79%|███████▉  | 794/1000 [02:29<00:32,  6.29it/s]Ref scores:  80%|███████▉  | 795/1000 [02:29<00:31,  6.54it/s]Ref scores:  80%|███████▉  | 796/1000 [02:29<00:31,  6.46it/s]Ref scores:  80%|███████▉  | 797/1000 [02:29<00:31,  6.52it/s]Ref scores:  80%|███████▉  | 798/1000 [02:30<00:32,  6.31it/s]Ref scores:  80%|███████▉  | 799/1000 [02:30<00:36,  5.58it/s]Ref scores:  80%|████████  | 800/1000 [02:30<00:38,  5.17it/s]Ref scores:  80%|████████  | 801/1000 [02:30<00:40,  4.92it/s]Ref scores:  80%|████████  | 802/1000 [02:30<00:36,  5.39it/s]Ref scores:  80%|████████  | 803/1000 [02:31<00:35,  5.57it/s]Ref scores:  80%|████████  | 804/1000 [02:31<00:36,  5.40it/s]Ref scores:  80%|████████  | 805/1000 [02:31<00:34,  5.61it/s]Ref scores:  81%|████████  | 806/1000 [02:31<00:37,  5.17it/s]Ref scores:  81%|████████  | 807/1000 [02:31<00:37,  5.14it/s]Ref scores:  81%|████████  | 808/1000 [02:32<00:34,  5.61it/s]Ref scores:  81%|████████  | 809/1000 [02:32<00:36,  5.21it/s]Ref scores:  81%|████████  | 810/1000 [02:32<00:33,  5.69it/s]Ref scores:  81%|████████  | 811/1000 [02:32<00:36,  5.21it/s]Ref scores:  81%|████████  | 812/1000 [02:32<00:36,  5.17it/s]Ref scores:  81%|████████▏ | 813/1000 [02:32<00:33,  5.62it/s]Ref scores:  81%|████████▏ | 814/1000 [02:33<00:35,  5.19it/s]Ref scores:  82%|████████▏ | 815/1000 [02:33<00:36,  5.12it/s]Ref scores:  82%|████████▏ | 816/1000 [02:33<00:35,  5.11it/s]Ref scores:  82%|████████▏ | 817/1000 [02:33<00:33,  5.54it/s]Ref scores:  82%|████████▏ | 818/1000 [02:33<00:30,  5.92it/s]Ref scores:  82%|████████▏ | 819/1000 [02:33<00:27,  6.52it/s]Ref scores:  82%|████████▏ | 820/1000 [02:34<00:26,  6.69it/s]Ref scores:  82%|████████▏ | 821/1000 [02:34<00:26,  6.79it/s]Ref scores:  82%|████████▏ | 822/1000 [02:34<00:29,  6.11it/s]Ref scores:  82%|████████▏ | 823/1000 [02:34<00:30,  5.78it/s]Ref scores:  82%|████████▏ | 824/1000 [02:34<00:27,  6.40it/s]Ref scores:  82%|████████▎ | 825/1000 [02:34<00:31,  5.63it/s]Ref scores:  83%|████████▎ | 826/1000 [02:35<00:34,  5.05it/s]Ref scores:  83%|████████▎ | 827/1000 [02:35<00:31,  5.56it/s]Ref scores:  83%|████████▎ | 828/1000 [02:35<00:33,  5.16it/s]Ref scores:  83%|████████▎ | 829/1000 [02:35<00:29,  5.88it/s]Ref scores:  83%|████████▎ | 830/1000 [02:35<00:33,  5.12it/s]Ref scores:  83%|████████▎ | 831/1000 [02:36<00:34,  4.89it/s]Ref scores:  83%|████████▎ | 832/1000 [02:36<00:40,  4.13it/s]Ref scores:  83%|████████▎ | 833/1000 [02:36<00:38,  4.36it/s]Ref scores:  83%|████████▎ | 834/1000 [02:36<00:33,  4.91it/s]Ref scores:  84%|████████▎ | 835/1000 [02:37<00:31,  5.18it/s]Ref scores:  84%|████████▎ | 836/1000 [02:37<00:30,  5.45it/s]Ref scores:  84%|████████▎ | 837/1000 [02:37<00:31,  5.12it/s]Ref scores:  84%|████████▍ | 838/1000 [02:37<00:28,  5.60it/s]Ref scores:  84%|████████▍ | 839/1000 [02:37<00:29,  5.48it/s]Ref scores:  84%|████████▍ | 840/1000 [02:37<00:31,  5.14it/s]Ref scores:  84%|████████▍ | 841/1000 [02:38<00:32,  4.93it/s]Ref scores:  84%|████████▍ | 842/1000 [02:38<00:28,  5.47it/s]Ref scores:  84%|████████▍ | 843/1000 [02:38<00:30,  5.11it/s]Ref scores:  84%|████████▍ | 844/1000 [02:38<00:31,  4.88it/s]Ref scores:  84%|████████▍ | 845/1000 [02:38<00:30,  5.15it/s]Ref scores:  85%|████████▍ | 846/1000 [02:39<00:29,  5.16it/s]Ref scores:  85%|████████▍ | 847/1000 [02:39<00:30,  4.94it/s]Ref scores:  85%|████████▍ | 848/1000 [02:39<00:31,  4.77it/s]Ref scores:  85%|████████▍ | 849/1000 [02:39<00:29,  5.15it/s]Ref scores:  85%|████████▌ | 850/1000 [02:39<00:30,  4.88it/s]Ref scores:  85%|████████▌ | 851/1000 [02:40<00:27,  5.36it/s]Ref scores:  85%|████████▌ | 852/1000 [02:40<00:28,  5.28it/s]Ref scores:  85%|████████▌ | 853/1000 [02:40<00:29,  4.98it/s]Ref scores:  85%|████████▌ | 854/1000 [02:40<00:25,  5.69it/s]Ref scores:  86%|████████▌ | 855/1000 [02:40<00:24,  5.83it/s]Ref scores:  86%|████████▌ | 856/1000 [02:41<00:27,  5.32it/s]Ref scores:  86%|████████▌ | 857/1000 [02:41<00:24,  5.75it/s]Ref scores:  86%|████████▌ | 858/1000 [02:41<00:24,  5.81it/s]Ref scores:  86%|████████▌ | 859/1000 [02:41<00:27,  5.12it/s]Ref scores:  86%|████████▌ | 860/1000 [02:41<00:25,  5.57it/s]Ref scores:  86%|████████▌ | 861/1000 [02:41<00:23,  5.96it/s]Ref scores:  86%|████████▌ | 862/1000 [02:42<00:22,  6.05it/s]Ref scores:  86%|████████▋ | 863/1000 [02:42<00:22,  6.00it/s]Ref scores:  86%|████████▋ | 864/1000 [02:42<00:23,  5.67it/s]Ref scores:  86%|████████▋ | 865/1000 [02:42<00:22,  6.00it/s]Ref scores:  87%|████████▋ | 866/1000 [02:42<00:21,  6.30it/s]Ref scores:  87%|████████▋ | 867/1000 [02:42<00:20,  6.51it/s]Ref scores:  87%|████████▋ | 868/1000 [02:43<00:23,  5.72it/s]Ref scores:  87%|████████▋ | 869/1000 [02:43<00:22,  5.80it/s]Ref scores:  87%|████████▋ | 870/1000 [02:43<00:20,  6.44it/s]Ref scores:  87%|████████▋ | 871/1000 [02:43<00:20,  6.30it/s]Ref scores:  87%|████████▋ | 872/1000 [02:43<00:19,  6.53it/s]Ref scores:  87%|████████▋ | 873/1000 [02:43<00:22,  5.72it/s]Ref scores:  87%|████████▋ | 874/1000 [02:44<00:20,  6.09it/s]Ref scores:  88%|████████▊ | 875/1000 [02:44<00:19,  6.36it/s]Ref scores:  88%|████████▊ | 876/1000 [02:44<00:22,  5.63it/s]Ref scores:  88%|████████▊ | 877/1000 [02:44<00:20,  5.97it/s]Ref scores:  88%|████████▊ | 878/1000 [02:44<00:19,  6.28it/s]Ref scores:  88%|████████▊ | 879/1000 [02:44<00:20,  5.88it/s]Ref scores:  88%|████████▊ | 880/1000 [02:45<00:19,  6.17it/s]Ref scores:  88%|████████▊ | 882/1000 [02:45<00:16,  7.17it/s]Ref scores:  88%|████████▊ | 883/1000 [02:45<00:18,  6.22it/s]Ref scores:  88%|████████▊ | 885/1000 [02:45<00:18,  6.29it/s]Ref scores:  89%|████████▊ | 886/1000 [02:45<00:19,  5.98it/s]Ref scores:  89%|████████▊ | 887/1000 [02:46<00:18,  6.04it/s]Ref scores:  89%|████████▉ | 888/1000 [02:46<00:20,  5.50it/s]Ref scores:  89%|████████▉ | 889/1000 [02:46<00:20,  5.38it/s]Ref scores:  89%|████████▉ | 890/1000 [02:46<00:18,  6.03it/s]Ref scores:  89%|████████▉ | 891/1000 [02:46<00:19,  5.67it/s]Ref scores:  89%|████████▉ | 892/1000 [02:47<00:17,  6.03it/s]Ref scores:  89%|████████▉ | 893/1000 [02:47<00:19,  5.43it/s]Ref scores:  89%|████████▉ | 894/1000 [02:47<00:21,  4.89it/s]Ref scores:  90%|████████▉ | 895/1000 [02:47<00:21,  4.93it/s]Ref scores:  90%|████████▉ | 896/1000 [02:47<00:18,  5.67it/s]Ref scores:  90%|████████▉ | 897/1000 [02:47<00:17,  6.00it/s]Ref scores:  90%|████████▉ | 898/1000 [02:48<00:17,  5.98it/s]Ref scores:  90%|████████▉ | 899/1000 [02:48<00:17,  5.68it/s]Ref scores:  90%|█████████ | 900/1000 [02:48<00:16,  6.07it/s]Ref scores:  90%|█████████ | 901/1000 [02:48<00:18,  5.47it/s]Ref scores:  90%|█████████ | 902/1000 [02:48<00:17,  5.68it/s]Ref scores:  90%|█████████ | 903/1000 [02:48<00:16,  6.01it/s]Ref scores:  90%|█████████ | 904/1000 [02:49<00:17,  5.42it/s]Ref scores:  90%|█████████ | 905/1000 [02:49<00:16,  5.83it/s]Ref scores:  91%|█████████ | 906/1000 [02:49<00:15,  5.88it/s]Ref scores:  91%|█████████ | 907/1000 [02:49<00:16,  5.64it/s]Ref scores:  91%|█████████ | 908/1000 [02:49<00:16,  5.47it/s]Ref scores:  91%|█████████ | 909/1000 [02:50<00:16,  5.60it/s]Ref scores:  91%|█████████ | 910/1000 [02:50<00:15,  5.71it/s]Ref scores:  91%|█████████ | 911/1000 [02:50<00:14,  6.08it/s]Ref scores:  91%|█████████ | 912/1000 [02:50<00:13,  6.31it/s]Ref scores:  91%|█████████▏| 913/1000 [02:50<00:13,  6.47it/s]Ref scores:  91%|█████████▏| 914/1000 [02:50<00:14,  5.94it/s]Ref scores:  92%|█████████▏| 915/1000 [02:51<00:15,  5.36it/s]Ref scores:  92%|█████████▏| 916/1000 [02:51<00:16,  4.96it/s]Ref scores:  92%|█████████▏| 917/1000 [02:51<00:16,  4.97it/s]Ref scores:  92%|█████████▏| 918/1000 [02:51<00:17,  4.81it/s]Ref scores:  92%|█████████▏| 919/1000 [02:51<00:15,  5.33it/s]Ref scores:  92%|█████████▏| 920/1000 [02:52<00:14,  5.50it/s]Ref scores:  92%|█████████▏| 921/1000 [02:52<00:15,  5.05it/s]Ref scores:  92%|█████████▏| 922/1000 [02:52<00:14,  5.35it/s]Ref scores:  92%|█████████▏| 923/1000 [02:52<00:13,  5.76it/s]Ref scores:  92%|█████████▏| 924/1000 [02:52<00:14,  5.26it/s]Ref scores:  92%|█████████▎| 925/1000 [02:52<00:13,  5.68it/s]Ref scores:  93%|█████████▎| 926/1000 [02:53<00:12,  6.05it/s]Ref scores:  93%|█████████▎| 927/1000 [02:53<00:13,  5.27it/s]Ref scores:  93%|█████████▎| 928/1000 [02:53<00:13,  5.20it/s]Ref scores:  93%|█████████▎| 929/1000 [02:53<00:13,  5.13it/s]Ref scores:  93%|█████████▎| 930/1000 [02:53<00:12,  5.59it/s]Ref scores:  93%|█████████▎| 931/1000 [02:54<00:12,  5.71it/s]Ref scores:  93%|█████████▎| 932/1000 [02:54<00:11,  5.86it/s]Ref scores:  93%|█████████▎| 933/1000 [02:54<00:10,  6.19it/s]Ref scores:  93%|█████████▎| 934/1000 [02:54<00:10,  6.11it/s]Ref scores:  94%|█████████▎| 935/1000 [02:54<00:09,  6.77it/s]Ref scores:  94%|█████████▎| 936/1000 [02:54<00:10,  6.18it/s]Ref scores:  94%|█████████▎| 937/1000 [02:55<00:10,  5.84it/s]Ref scores:  94%|█████████▍| 938/1000 [02:55<00:11,  5.60it/s]Ref scores:  94%|█████████▍| 939/1000 [02:55<00:12,  4.96it/s]Ref scores:  94%|█████████▍| 940/1000 [02:55<00:11,  5.23it/s]Ref scores:  94%|█████████▍| 942/1000 [02:55<00:09,  5.92it/s]Ref scores:  94%|█████████▍| 943/1000 [02:56<00:09,  6.15it/s]Ref scores:  94%|█████████▍| 944/1000 [02:56<00:09,  6.17it/s]Ref scores:  94%|█████████▍| 945/1000 [02:56<00:08,  6.12it/s]Ref scores:  95%|█████████▍| 946/1000 [02:56<00:09,  5.76it/s]Ref scores:  95%|█████████▍| 947/1000 [02:56<00:08,  5.89it/s]Ref scores:  95%|█████████▍| 948/1000 [02:56<00:09,  5.60it/s]Ref scores:  95%|█████████▍| 949/1000 [02:57<00:08,  5.71it/s]Ref scores:  95%|█████████▌| 950/1000 [02:57<00:09,  5.26it/s]Ref scores:  95%|█████████▌| 951/1000 [02:57<00:08,  5.95it/s]Ref scores:  95%|█████████▌| 952/1000 [02:57<00:07,  6.22it/s]Ref scores:  95%|█████████▌| 953/1000 [02:57<00:08,  5.37it/s]Ref scores:  95%|█████████▌| 954/1000 [02:58<00:08,  5.29it/s]Ref scores:  96%|█████████▌| 955/1000 [02:58<00:08,  5.46it/s]Ref scores:  96%|█████████▌| 956/1000 [02:58<00:08,  5.31it/s]Ref scores:  96%|█████████▌| 957/1000 [02:58<00:07,  5.72it/s]Ref scores:  96%|█████████▌| 958/1000 [02:58<00:06,  6.10it/s]Ref scores:  96%|█████████▌| 959/1000 [02:58<00:06,  6.33it/s]Ref scores:  96%|█████████▌| 960/1000 [02:59<00:06,  6.15it/s]Ref scores:  96%|█████████▌| 961/1000 [02:59<00:06,  5.80it/s]Ref scores:  96%|█████████▌| 962/1000 [02:59<00:06,  5.86it/s]Ref scores:  96%|█████████▋| 963/1000 [02:59<00:06,  5.97it/s]Ref scores:  96%|█████████▋| 964/1000 [02:59<00:06,  5.70it/s]Ref scores:  96%|█████████▋| 965/1000 [02:59<00:06,  5.26it/s]Ref scores:  97%|█████████▋| 966/1000 [03:00<00:05,  5.96it/s]Ref scores:  97%|█████████▋| 967/1000 [03:00<00:05,  6.26it/s]Ref scores:  97%|█████████▋| 968/1000 [03:00<00:04,  6.49it/s]Ref scores:  97%|█████████▋| 969/1000 [03:00<00:05,  5.44it/s]Ref scores:  97%|█████████▋| 970/1000 [03:00<00:05,  5.33it/s]Ref scores:  97%|█████████▋| 971/1000 [03:01<00:05,  5.51it/s]Ref scores:  97%|█████████▋| 972/1000 [03:01<00:05,  4.93it/s]Ref scores:  97%|█████████▋| 973/1000 [03:01<00:05,  4.97it/s]Ref scores:  97%|█████████▋| 974/1000 [03:01<00:04,  5.70it/s]Ref scores:  98%|█████████▊| 975/1000 [03:01<00:05,  4.83it/s]Ref scores:  98%|█████████▊| 976/1000 [03:02<00:04,  4.91it/s]Ref scores:  98%|█████████▊| 977/1000 [03:02<00:04,  4.75it/s]Ref scores:  98%|█████████▊| 978/1000 [03:02<00:04,  5.48it/s]Ref scores:  98%|█████████▊| 979/1000 [03:02<00:03,  5.68it/s]Ref scores:  98%|█████████▊| 980/1000 [03:02<00:03,  5.44it/s]Ref scores:  98%|█████████▊| 981/1000 [03:02<00:03,  5.67it/s]Ref scores:  98%|█████████▊| 982/1000 [03:03<00:03,  5.21it/s]Ref scores:  98%|█████████▊| 983/1000 [03:03<00:02,  5.67it/s]Ref scores:  98%|█████████▊| 984/1000 [03:03<00:02,  5.99it/s]Ref scores:  98%|█████████▊| 985/1000 [03:03<00:02,  6.30it/s]Ref scores:  99%|█████████▊| 986/1000 [03:03<00:02,  5.88it/s]Ref scores:  99%|█████████▊| 987/1000 [03:03<00:02,  6.19it/s]Ref scores:  99%|█████████▉| 988/1000 [03:04<00:02,  5.82it/s]Ref scores:  99%|█████████▉| 989/1000 [03:04<00:01,  5.59it/s]Ref scores:  99%|█████████▉| 990/1000 [03:04<00:01,  5.45it/s]Ref scores:  99%|█████████▉| 991/1000 [03:04<00:01,  5.36it/s]Ref scores:  99%|█████████▉| 992/1000 [03:04<00:01,  6.01it/s]Ref scores:  99%|█████████▉| 993/1000 [03:04<00:01,  6.00it/s]Ref scores:  99%|█████████▉| 994/1000 [03:05<00:00,  6.07it/s]Ref scores: 100%|█████████▉| 995/1000 [03:05<00:00,  5.76it/s]Ref scores: 100%|█████████▉| 996/1000 [03:05<00:00,  5.28it/s]Ref scores: 100%|█████████▉| 997/1000 [03:05<00:00,  5.17it/s]Ref scores: 100%|█████████▉| 998/1000 [03:05<00:00,  5.63it/s]Ref scores: 100%|█████████▉| 999/1000 [03:06<00:00,  5.43it/s]Ref scores: 100%|██████████| 1000/1000 [03:06<00:00,  5.65it/s]Ref scores: 100%|██████████| 1000/1000 [03:06<00:00,  5.37it/s]
DONE (8.52s)
DONE (8.11s)
Computing criterion:   0%|          | 0/20 [00:00<?, ?it/s]Computing criterion:   5%|▌         | 1/20 [00:22<07:02, 22.26s/it]Computing criterion:  10%|█         | 2/20 [00:44<06:44, 22.48s/it]Computing criterion:  15%|█▌        | 3/20 [01:07<06:23, 22.55s/it]Computing criterion:  20%|██        | 4/20 [01:29<05:58, 22.39s/it]Computing criterion:  25%|██▌       | 5/20 [01:52<05:37, 22.53s/it]Computing criterion:  30%|███       | 6/20 [02:15<05:15, 22.55s/it]Computing criterion:  35%|███▌      | 7/20 [02:37<04:51, 22.40s/it]Computing criterion:  40%|████      | 8/20 [02:58<04:24, 22.06s/it]Computing criterion:  45%|████▌     | 9/20 [03:20<04:02, 22.01s/it]Computing criterion:  50%|█████     | 10/20 [03:41<03:38, 21.89s/it]Computing criterion:  55%|█████▌    | 11/20 [04:03<03:14, 21.65s/it]Computing criterion:  60%|██████    | 12/20 [04:25<02:54, 21.85s/it]Computing criterion:  65%|██████▌   | 13/20 [04:45<02:30, 21.46s/it]Computing criterion:  70%|███████   | 14/20 [05:07<02:08, 21.38s/it]Computing criterion:  75%|███████▌  | 15/20 [05:28<01:47, 21.47s/it]Computing criterion:  80%|████████  | 16/20 [05:50<01:26, 21.61s/it]Computing criterion:  85%|████████▌ | 17/20 [06:11<01:03, 21.31s/it]Computing criterion:  90%|█████████ | 18/20 [06:32<00:42, 21.10s/it]Computing criterion:  95%|█████████▌| 19/20 [07:01<00:23, 23.64s/it]Computing criterion: 100%|██████████| 20/20 [07:23<00:00, 23.25s/it]Computing criterion: 100%|██████████| 20/20 [07:23<00:00, 22.19s/it]
Ref scores:   0%|          | 0/1000 [00:00<?, ?it/s]Ref scores:   0%|          | 1/1000 [00:02<33:50,  2.03s/it]Ref scores:   0%|          | 2/1000 [00:02<15:51,  1.05it/s]Ref scores:   0%|          | 3/1000 [00:02<10:06,  1.64it/s]Ref scores:   0%|          | 4/1000 [00:02<07:49,  2.12it/s]Ref scores:   0%|          | 5/1000 [00:02<05:58,  2.77it/s]Ref scores:   1%|          | 6/1000 [00:03<04:48,  3.44it/s]Ref scores:   1%|          | 7/1000 [00:03<04:05,  4.05it/s]Ref scores:   1%|          | 8/1000 [00:03<03:30,  4.72it/s]Ref scores:   1%|          | 9/1000 [00:03<02:59,  5.51it/s]Ref scores:   1%|          | 10/1000 [00:03<02:51,  5.77it/s]Ref scores:   1%|          | 11/1000 [00:03<03:00,  5.48it/s]Ref scores:   1%|          | 12/1000 [00:03<02:39,  6.20it/s]Ref scores:   1%|▏         | 13/1000 [00:04<03:00,  5.47it/s]Ref scores:   1%|▏         | 14/1000 [00:04<02:54,  5.65it/s]Ref scores:   2%|▏         | 15/1000 [00:04<03:01,  5.41it/s]Ref scores:   2%|▏         | 16/1000 [00:04<02:46,  5.90it/s]Ref scores:   2%|▏         | 17/1000 [00:04<02:56,  5.58it/s]Ref scores:   2%|▏         | 18/1000 [00:04<02:49,  5.81it/s]Ref scores:   2%|▏         | 19/1000 [00:05<03:05,  5.29it/s]Ref scores:   2%|▏         | 20/1000 [00:05<02:50,  5.73it/s]Ref scores:   2%|▏         | 21/1000 [00:05<02:56,  5.54it/s]Ref scores:   2%|▏         | 22/1000 [00:05<03:02,  5.36it/s]Ref scores:   2%|▏         | 23/1000 [00:05<02:55,  5.57it/s]Ref scores:   2%|▏         | 24/1000 [00:06<02:51,  5.71it/s]Ref scores:   2%|▎         | 25/1000 [00:06<02:40,  6.07it/s]Ref scores:   3%|▎         | 26/1000 [00:06<03:00,  5.41it/s]Ref scores:   3%|▎         | 28/1000 [00:06<02:39,  6.10it/s]Ref scores:   3%|▎         | 29/1000 [00:06<02:37,  6.15it/s]Ref scores:   3%|▎         | 30/1000 [00:07<02:32,  6.38it/s]Ref scores:   3%|▎         | 31/1000 [00:07<02:52,  5.63it/s]Ref scores:   3%|▎         | 32/1000 [00:07<02:46,  5.82it/s]Ref scores:   3%|▎         | 33/1000 [00:07<02:41,  5.97it/s]Ref scores:   3%|▎         | 34/1000 [00:07<02:39,  6.06it/s]Ref scores:   4%|▎         | 35/1000 [00:07<03:05,  5.21it/s]Ref scores:   4%|▎         | 36/1000 [00:08<02:56,  5.46it/s]Ref scores:   4%|▎         | 37/1000 [00:08<03:10,  5.06it/s]Ref scores:   4%|▍         | 38/1000 [00:08<03:20,  4.79it/s]Ref scores:   4%|▍         | 39/1000 [00:08<03:07,  5.11it/s]Ref scores:   4%|▍         | 40/1000 [00:08<03:09,  5.06it/s]Ref scores:   4%|▍         | 41/1000 [00:09<03:12,  4.99it/s]Ref scores:   4%|▍         | 42/1000 [00:09<03:20,  4.77it/s]Ref scores:   4%|▍         | 43/1000 [00:09<03:07,  5.10it/s]Ref scores:   4%|▍         | 44/1000 [00:09<03:08,  5.07it/s]Ref scores:   4%|▍         | 45/1000 [00:09<02:50,  5.61it/s]Ref scores:   5%|▍         | 46/1000 [00:10<02:57,  5.38it/s]Ref scores:   5%|▍         | 47/1000 [00:10<03:10,  5.00it/s]Ref scores:   5%|▍         | 48/1000 [00:10<03:08,  5.05it/s]Ref scores:   5%|▍         | 49/1000 [00:10<03:18,  4.80it/s]Ref scores:   5%|▌         | 50/1000 [00:10<03:15,  4.86it/s]Ref scores:   5%|▌         | 51/1000 [00:11<03:15,  4.85it/s]Ref scores:   5%|▌         | 52/1000 [00:11<03:29,  4.52it/s]Ref scores:   5%|▌         | 53/1000 [00:11<03:22,  4.67it/s]Ref scores:   5%|▌         | 54/1000 [00:11<03:18,  4.78it/s]Ref scores:   6%|▌         | 55/1000 [00:11<02:58,  5.29it/s]Ref scores:   6%|▌         | 56/1000 [00:12<02:44,  5.73it/s]Ref scores:   6%|▌         | 57/1000 [00:12<02:52,  5.46it/s]Ref scores:   6%|▌         | 58/1000 [00:12<03:06,  5.04it/s]Ref scores:   6%|▌         | 59/1000 [00:12<02:49,  5.55it/s]Ref scores:   6%|▌         | 60/1000 [00:12<02:55,  5.37it/s]Ref scores:   6%|▌         | 61/1000 [00:13<03:01,  5.17it/s]Ref scores:   6%|▌         | 62/1000 [00:13<02:50,  5.49it/s]Ref scores:   6%|▋         | 63/1000 [00:13<02:43,  5.72it/s]Ref scores:   6%|▋         | 64/1000 [00:13<03:00,  5.17it/s]Ref scores:   6%|▋         | 65/1000 [00:13<03:10,  4.90it/s]Ref scores:   7%|▋         | 66/1000 [00:14<02:56,  5.28it/s]Ref scores:   7%|▋         | 67/1000 [00:14<02:42,  5.75it/s]Ref scores:   7%|▋         | 68/1000 [00:14<02:39,  5.83it/s]Ref scores:   7%|▋         | 69/1000 [00:14<02:55,  5.29it/s]Ref scores:   7%|▋         | 70/1000 [00:14<02:46,  5.59it/s]Ref scores:   7%|▋         | 71/1000 [00:14<02:34,  6.01it/s]Ref scores:   7%|▋         | 72/1000 [00:15<02:33,  6.03it/s]Ref scores:   7%|▋         | 73/1000 [00:15<02:41,  5.73it/s]Ref scores:   7%|▋         | 74/1000 [00:15<02:32,  6.09it/s]Ref scores:   8%|▊         | 75/1000 [00:15<02:24,  6.39it/s]Ref scores:   8%|▊         | 76/1000 [00:15<02:20,  6.59it/s]Ref scores:   8%|▊         | 77/1000 [00:15<02:42,  5.69it/s]Ref scores:   8%|▊         | 78/1000 [00:16<02:59,  5.15it/s]Ref scores:   8%|▊         | 79/1000 [00:16<03:01,  5.09it/s]Ref scores:   8%|▊         | 80/1000 [00:16<03:09,  4.85it/s]Ref scores:   8%|▊         | 81/1000 [00:16<03:04,  4.97it/s]Ref scores:   8%|▊         | 82/1000 [00:16<03:12,  4.76it/s]Ref scores:   8%|▊         | 83/1000 [00:17<03:18,  4.62it/s]Ref scores:   8%|▊         | 84/1000 [00:17<03:04,  4.96it/s]Ref scores:   8%|▊         | 85/1000 [00:17<03:13,  4.73it/s]Ref scores:   9%|▊         | 86/1000 [00:17<03:18,  4.59it/s]Ref scores:   9%|▊         | 87/1000 [00:18<03:15,  4.68it/s]Ref scores:   9%|▉         | 88/1000 [00:18<03:01,  5.02it/s]Ref scores:   9%|▉         | 89/1000 [00:18<03:25,  4.42it/s]Ref scores:   9%|▉         | 90/1000 [00:18<03:27,  4.38it/s]Ref scores:   9%|▉         | 91/1000 [00:18<03:09,  4.79it/s]Ref scores:   9%|▉         | 92/1000 [00:19<02:56,  5.14it/s]Ref scores:   9%|▉         | 93/1000 [00:19<02:48,  5.39it/s]Ref scores:   9%|▉         | 94/1000 [00:19<03:00,  5.01it/s]Ref scores:  10%|▉         | 95/1000 [00:19<02:49,  5.34it/s]Ref scores:  10%|▉         | 96/1000 [00:19<03:01,  4.99it/s]Ref scores:  10%|▉         | 97/1000 [00:19<02:49,  5.33it/s]Ref scores:  10%|▉         | 98/1000 [00:20<02:43,  5.52it/s]Ref scores:  10%|▉         | 99/1000 [00:20<02:56,  5.10it/s]Ref scores:  10%|█         | 100/1000 [00:20<02:58,  5.04it/s]Ref scores:  10%|█         | 101/1000 [00:20<03:00,  4.98it/s]Ref scores:  10%|█         | 102/1000 [00:21<03:01,  4.96it/s]Ref scores:  10%|█         | 103/1000 [00:21<02:51,  5.23it/s]Ref scores:  10%|█         | 104/1000 [00:21<02:54,  5.13it/s]Ref scores:  10%|█         | 105/1000 [00:21<02:44,  5.44it/s]Ref scores:  11%|█         | 106/1000 [00:21<02:57,  5.05it/s]Ref scores:  11%|█         | 107/1000 [00:22<03:20,  4.45it/s]Ref scores:  11%|█         | 108/1000 [00:22<02:57,  5.03it/s]Ref scores:  11%|█         | 109/1000 [00:22<02:40,  5.54it/s]Ref scores:  11%|█         | 110/1000 [00:22<02:34,  5.75it/s]Ref scores:  11%|█         | 111/1000 [00:22<02:18,  6.41it/s]Ref scores:  11%|█         | 112/1000 [00:22<02:45,  5.37it/s]Ref scores:  11%|█▏        | 113/1000 [00:23<02:36,  5.66it/s]Ref scores:  11%|█▏        | 114/1000 [00:23<02:52,  5.13it/s]Ref scores:  12%|█▏        | 115/1000 [00:23<02:54,  5.06it/s]Ref scores:  12%|█▏        | 116/1000 [00:23<02:39,  5.55it/s]Ref scores:  12%|█▏        | 117/1000 [00:23<02:34,  5.70it/s]Ref scores:  12%|█▏        | 118/1000 [00:23<02:43,  5.40it/s]Ref scores:  12%|█▏        | 119/1000 [00:24<02:55,  5.03it/s]Ref scores:  12%|█▏        | 120/1000 [00:24<02:46,  5.30it/s]Ref scores:  12%|█▏        | 121/1000 [00:24<02:49,  5.17it/s]Ref scores:  12%|█▏        | 122/1000 [00:24<02:51,  5.11it/s]Ref scores:  12%|█▏        | 123/1000 [00:24<02:29,  5.86it/s]Ref scores:  12%|█▏        | 124/1000 [00:25<03:08,  4.65it/s]Ref scores:  12%|█▎        | 125/1000 [00:25<03:12,  4.54it/s]Ref scores:  13%|█▎        | 126/1000 [00:25<02:44,  5.32it/s]Ref scores:  13%|█▎        | 127/1000 [00:25<03:10,  4.57it/s]Ref scores:  13%|█▎        | 128/1000 [00:26<03:14,  4.47it/s]Ref scores:  13%|█▎        | 129/1000 [00:26<03:08,  4.62it/s]Ref scores:  13%|█▎        | 130/1000 [00:26<02:54,  4.99it/s]Ref scores:  13%|█▎        | 131/1000 [00:26<02:38,  5.49it/s]Ref scores:  13%|█▎        | 132/1000 [00:26<02:51,  5.07it/s]Ref scores:  13%|█▎        | 133/1000 [00:26<02:51,  5.06it/s]Ref scores:  13%|█▎        | 134/1000 [00:27<02:36,  5.55it/s]Ref scores:  14%|█▎        | 135/1000 [00:27<02:32,  5.68it/s]Ref scores:  14%|█▎        | 136/1000 [00:27<02:22,  6.07it/s]Ref scores:  14%|█▎        | 137/1000 [00:27<02:14,  6.42it/s]Ref scores:  14%|█▍        | 138/1000 [00:27<02:14,  6.41it/s]Ref scores:  14%|█▍        | 139/1000 [00:27<02:27,  5.83it/s]Ref scores:  14%|█▍        | 140/1000 [00:28<02:12,  6.47it/s]Ref scores:  14%|█▍        | 141/1000 [00:28<02:23,  6.00it/s]Ref scores:  14%|█▍        | 142/1000 [00:28<02:40,  5.36it/s]Ref scores:  14%|█▍        | 143/1000 [00:28<02:42,  5.29it/s]Ref scores:  14%|█▍        | 144/1000 [00:28<02:35,  5.50it/s]Ref scores:  14%|█▍        | 145/1000 [00:29<02:47,  5.10it/s]Ref scores:  15%|█▍        | 146/1000 [00:29<03:03,  4.66it/s]Ref scores:  15%|█▍        | 147/1000 [00:29<03:05,  4.59it/s]Ref scores:  15%|█▍        | 148/1000 [00:29<02:45,  5.16it/s]Ref scores:  15%|█▌        | 150/1000 [00:29<02:11,  6.44it/s]Ref scores:  15%|█▌        | 151/1000 [00:30<02:08,  6.59it/s]Ref scores:  15%|█▌        | 152/1000 [00:30<02:20,  6.03it/s]Ref scores:  15%|█▌        | 153/1000 [00:30<02:28,  5.71it/s]Ref scores:  15%|█▌        | 154/1000 [00:30<02:41,  5.23it/s]Ref scores:  16%|█▌        | 155/1000 [00:30<02:33,  5.50it/s]Ref scores:  16%|█▌        | 156/1000 [00:31<02:45,  5.09it/s]Ref scores:  16%|█▌        | 157/1000 [00:31<02:31,  5.57it/s]Ref scores:  16%|█▌        | 159/1000 [00:31<01:58,  7.10it/s]Ref scores:  16%|█▌        | 160/1000 [00:31<02:11,  6.39it/s]Ref scores:  16%|█▌        | 161/1000 [00:31<02:11,  6.38it/s]Ref scores:  16%|█▌        | 162/1000 [00:31<02:13,  6.28it/s]Ref scores:  16%|█▋        | 163/1000 [00:32<02:22,  5.85it/s]Ref scores:  16%|█▋        | 164/1000 [00:32<02:36,  5.34it/s]Ref scores:  16%|█▋        | 165/1000 [00:32<02:39,  5.24it/s]Ref scores:  17%|█▋        | 166/1000 [00:32<02:49,  4.92it/s]Ref scores:  17%|█▋        | 167/1000 [00:33<02:57,  4.70it/s]Ref scores:  17%|█▋        | 168/1000 [00:33<02:37,  5.28it/s]Ref scores:  17%|█▋        | 169/1000 [00:33<02:30,  5.51it/s]Ref scores:  17%|█▋        | 170/1000 [00:33<02:36,  5.29it/s]Ref scores:  17%|█▋        | 171/1000 [00:33<02:30,  5.52it/s]Ref scores:  17%|█▋        | 172/1000 [00:33<02:41,  5.11it/s]Ref scores:  17%|█▋        | 173/1000 [00:34<02:34,  5.34it/s]Ref scores:  17%|█▋        | 174/1000 [00:34<02:38,  5.21it/s]Ref scores:  18%|█▊        | 175/1000 [00:34<02:19,  5.93it/s]Ref scores:  18%|█▊        | 176/1000 [00:34<02:34,  5.34it/s]Ref scores:  18%|█▊        | 177/1000 [00:34<02:15,  6.06it/s]Ref scores:  18%|█▊        | 178/1000 [00:34<02:32,  5.39it/s]Ref scores:  18%|█▊        | 179/1000 [00:35<02:21,  5.79it/s]Ref scores:  18%|█▊        | 180/1000 [00:35<02:36,  5.25it/s]Ref scores:  18%|█▊        | 181/1000 [00:35<02:29,  5.47it/s]Ref scores:  18%|█▊        | 182/1000 [00:35<02:24,  5.64it/s]Ref scores:  18%|█▊        | 183/1000 [00:35<02:32,  5.37it/s]Ref scores:  18%|█▊        | 184/1000 [00:36<02:35,  5.24it/s]Ref scores:  18%|█▊        | 185/1000 [00:36<02:39,  5.12it/s]Ref scores:  19%|█▊        | 186/1000 [00:36<02:55,  4.65it/s]Ref scores:  19%|█▊        | 187/1000 [00:36<02:51,  4.73it/s]Ref scores:  19%|█▉        | 188/1000 [00:36<02:49,  4.80it/s]Ref scores:  19%|█▉        | 189/1000 [00:37<02:54,  4.65it/s]Ref scores:  19%|█▉        | 190/1000 [00:37<02:35,  5.20it/s]Ref scores:  19%|█▉        | 191/1000 [00:37<02:39,  5.08it/s]Ref scores:  19%|█▉        | 192/1000 [00:37<02:39,  5.06it/s]Ref scores:  19%|█▉        | 193/1000 [00:37<02:25,  5.56it/s]Ref scores:  19%|█▉        | 194/1000 [00:38<02:15,  5.94it/s]Ref scores:  20%|█▉        | 195/1000 [00:38<02:08,  6.28it/s]Ref scores:  20%|█▉        | 196/1000 [00:38<02:16,  5.89it/s]Ref scores:  20%|█▉        | 197/1000 [00:38<02:30,  5.32it/s]Ref scores:  20%|█▉        | 198/1000 [00:38<02:35,  5.17it/s]Ref scores:  20%|█▉        | 199/1000 [00:39<02:44,  4.86it/s]Ref scores:  20%|██        | 200/1000 [00:39<03:10,  4.19it/s]Ref scores:  20%|██        | 201/1000 [00:39<02:40,  4.99it/s]Ref scores:  20%|██        | 202/1000 [00:39<02:46,  4.79it/s]Ref scores:  20%|██        | 203/1000 [00:39<03:04,  4.31it/s]Ref scores:  20%|██        | 204/1000 [00:40<02:42,  4.91it/s]Ref scores:  20%|██        | 205/1000 [00:40<02:47,  4.76it/s]Ref scores:  21%|██        | 206/1000 [00:40<02:27,  5.38it/s]Ref scores:  21%|██        | 207/1000 [00:40<02:20,  5.63it/s]Ref scores:  21%|██        | 208/1000 [00:40<02:14,  5.90it/s]Ref scores:  21%|██        | 209/1000 [00:40<02:22,  5.56it/s]Ref scores:  21%|██        | 210/1000 [00:41<02:13,  5.93it/s]Ref scores:  21%|██        | 211/1000 [00:41<02:26,  5.37it/s]Ref scores:  21%|██        | 212/1000 [00:41<02:36,  5.03it/s]Ref scores:  21%|██▏       | 213/1000 [00:41<02:20,  5.61it/s]Ref scores:  21%|██▏       | 214/1000 [00:41<02:38,  4.95it/s]Ref scores:  22%|██▏       | 215/1000 [00:42<02:45,  4.74it/s]Ref scores:  22%|██▏       | 216/1000 [00:42<02:27,  5.30it/s]Ref scores:  22%|██▏       | 217/1000 [00:42<02:32,  5.15it/s]Ref scores:  22%|██▏       | 218/1000 [00:42<02:33,  5.09it/s]Ref scores:  22%|██▏       | 219/1000 [00:42<02:42,  4.81it/s]Ref scores:  22%|██▏       | 220/1000 [00:43<02:53,  4.50it/s]Ref scores:  22%|██▏       | 221/1000 [00:43<03:03,  4.26it/s]Ref scores:  22%|██▏       | 222/1000 [00:43<02:40,  4.85it/s]Ref scores:  22%|██▏       | 223/1000 [00:43<02:16,  5.69it/s]Ref scores:  22%|██▏       | 224/1000 [00:43<02:31,  5.12it/s]Ref scores:  22%|██▎       | 225/1000 [00:44<02:34,  5.02it/s]Ref scores:  23%|██▎       | 226/1000 [00:44<02:43,  4.75it/s]Ref scores:  23%|██▎       | 227/1000 [00:44<02:30,  5.13it/s]Ref scores:  23%|██▎       | 228/1000 [00:44<02:34,  5.00it/s]Ref scores:  23%|██▎       | 229/1000 [00:44<02:24,  5.34it/s]Ref scores:  23%|██▎       | 230/1000 [00:45<02:34,  4.97it/s]Ref scores:  23%|██▎       | 231/1000 [00:45<02:36,  4.90it/s]Ref scores:  23%|██▎       | 232/1000 [00:45<02:50,  4.49it/s]Ref scores:  23%|██▎       | 233/1000 [00:45<02:37,  4.88it/s]Ref scores:  23%|██▎       | 234/1000 [00:46<02:37,  4.86it/s]Ref scores:  24%|██▎       | 235/1000 [00:46<02:21,  5.39it/s]Ref scores:  24%|██▎       | 237/1000 [00:46<02:12,  5.75it/s]Ref scores:  24%|██▍       | 238/1000 [00:46<02:18,  5.50it/s]Ref scores:  24%|██▍       | 239/1000 [00:46<02:22,  5.33it/s]Ref scores:  24%|██▍       | 240/1000 [00:47<02:26,  5.20it/s]Ref scores:  24%|██▍       | 241/1000 [00:47<02:40,  4.72it/s]Ref scores:  24%|██▍       | 242/1000 [00:47<02:45,  4.59it/s]Ref scores:  24%|██▍       | 243/1000 [00:47<02:30,  5.03it/s]Ref scores:  24%|██▍       | 244/1000 [00:48<03:35,  3.51it/s]Ref scores:  24%|██▍       | 245/1000 [00:48<03:17,  3.83it/s]Ref scores:  25%|██▍       | 246/1000 [00:48<02:49,  4.45it/s]Ref scores:  25%|██▍       | 247/1000 [00:48<03:02,  4.12it/s]Ref scores:  25%|██▍       | 248/1000 [00:49<02:39,  4.72it/s]Ref scores:  25%|██▍       | 249/1000 [00:49<02:50,  4.40it/s]Ref scores:  25%|██▌       | 250/1000 [00:49<02:33,  4.87it/s]Ref scores:  25%|██▌       | 251/1000 [00:49<02:32,  4.91it/s]Ref scores:  25%|██▌       | 252/1000 [00:49<02:45,  4.53it/s]Ref scores:  25%|██▌       | 253/1000 [00:50<02:30,  4.95it/s]Ref scores:  25%|██▌       | 254/1000 [00:50<02:30,  4.95it/s]Ref scores:  26%|██▌       | 255/1000 [00:50<02:18,  5.36it/s]Ref scores:  26%|██▌       | 256/1000 [00:50<02:01,  6.12it/s]Ref scores:  26%|██▌       | 257/1000 [00:50<02:00,  6.14it/s]Ref scores:  26%|██▌       | 258/1000 [00:50<01:59,  6.20it/s]Ref scores:  26%|██▌       | 259/1000 [00:50<01:47,  6.87it/s]Ref scores:  26%|██▌       | 260/1000 [00:51<02:10,  5.66it/s]Ref scores:  26%|██▌       | 261/1000 [00:51<02:05,  5.87it/s]Ref scores:  26%|██▌       | 262/1000 [00:51<02:18,  5.32it/s]Ref scores:  26%|██▋       | 263/1000 [00:51<02:11,  5.60it/s]Ref scores:  26%|██▋       | 264/1000 [00:51<02:22,  5.16it/s]Ref scores:  26%|██▋       | 265/1000 [00:52<02:21,  5.20it/s]Ref scores:  27%|██▋       | 266/1000 [00:52<02:22,  5.14it/s]Ref scores:  27%|██▋       | 267/1000 [00:52<02:23,  5.10it/s]Ref scores:  27%|██▋       | 268/1000 [00:52<02:29,  4.88it/s]Ref scores:  27%|██▋       | 269/1000 [00:52<02:17,  5.30it/s]Ref scores:  27%|██▋       | 270/1000 [00:53<02:28,  4.93it/s]Ref scores:  27%|██▋       | 271/1000 [00:53<02:18,  5.27it/s]Ref scores:  27%|██▋       | 272/1000 [00:53<02:20,  5.16it/s]Ref scores:  27%|██▋       | 273/1000 [00:53<02:29,  4.87it/s]Ref scores:  27%|██▋       | 274/1000 [00:53<02:28,  4.88it/s]Ref scores:  28%|██▊       | 275/1000 [00:54<02:19,  5.21it/s]Ref scores:  28%|██▊       | 276/1000 [00:54<02:20,  5.15it/s]Ref scores:  28%|██▊       | 277/1000 [00:54<02:28,  4.87it/s]Ref scores:  28%|██▊       | 278/1000 [00:54<02:16,  5.27it/s]Ref scores:  28%|██▊       | 279/1000 [00:54<02:08,  5.59it/s]Ref scores:  28%|██▊       | 280/1000 [00:54<01:52,  6.38it/s]Ref scores:  28%|██▊       | 281/1000 [00:55<01:47,  6.67it/s]Ref scores:  28%|██▊       | 282/1000 [00:55<02:06,  5.69it/s]Ref scores:  28%|██▊       | 283/1000 [00:55<02:12,  5.42it/s]Ref scores:  28%|██▊       | 284/1000 [00:55<02:01,  5.89it/s]Ref scores:  28%|██▊       | 285/1000 [00:55<02:08,  5.57it/s]Ref scores:  29%|██▊       | 286/1000 [00:56<02:20,  5.09it/s]Ref scores:  29%|██▊       | 287/1000 [00:56<02:05,  5.66it/s]Ref scores:  29%|██▉       | 288/1000 [00:56<02:02,  5.82it/s]Ref scores:  29%|██▉       | 289/1000 [00:56<02:15,  5.26it/s]Ref scores:  29%|██▉       | 290/1000 [00:56<02:16,  5.19it/s]Ref scores:  29%|██▉       | 291/1000 [00:57<02:25,  4.88it/s]Ref scores:  29%|██▉       | 292/1000 [00:57<02:31,  4.69it/s]Ref scores:  29%|██▉       | 293/1000 [00:57<02:19,  5.06it/s]Ref scores:  29%|██▉       | 294/1000 [00:57<02:20,  5.01it/s]Ref scores:  30%|██▉       | 295/1000 [00:57<02:12,  5.32it/s]Ref scores:  30%|██▉       | 296/1000 [00:57<02:04,  5.64it/s]Ref scores:  30%|██▉       | 297/1000 [00:58<02:15,  5.18it/s]Ref scores:  30%|██▉       | 298/1000 [00:58<02:24,  4.86it/s]Ref scores:  30%|██▉       | 299/1000 [00:58<02:09,  5.41it/s]Ref scores:  30%|███       | 300/1000 [00:58<02:19,  5.01it/s]Ref scores:  30%|███       | 301/1000 [00:58<02:05,  5.58it/s]Ref scores:  30%|███       | 302/1000 [00:59<02:16,  5.11it/s]Ref scores:  30%|███       | 303/1000 [00:59<02:23,  4.85it/s]Ref scores:  30%|███       | 304/1000 [00:59<02:40,  4.34it/s]Ref scores:  30%|███       | 305/1000 [00:59<02:51,  4.04it/s]Ref scores:  31%|███       | 306/1000 [01:00<02:54,  3.97it/s]Ref scores:  31%|███       | 307/1000 [01:00<02:29,  4.62it/s]Ref scores:  31%|███       | 308/1000 [01:00<02:17,  5.02it/s]Ref scores:  31%|███       | 309/1000 [01:00<02:04,  5.55it/s]Ref scores:  31%|███       | 310/1000 [01:00<02:00,  5.73it/s]Ref scores:  31%|███       | 311/1000 [01:01<02:05,  5.49it/s]Ref scores:  31%|███       | 312/1000 [01:01<02:20,  4.89it/s]Ref scores:  31%|███▏      | 313/1000 [01:01<02:20,  4.88it/s]Ref scores:  31%|███▏      | 314/1000 [01:01<02:25,  4.70it/s]Ref scores:  32%|███▏      | 315/1000 [01:01<02:14,  5.09it/s]Ref scores:  32%|███▏      | 316/1000 [01:02<02:05,  5.46it/s]Ref scores:  32%|███▏      | 317/1000 [01:02<02:10,  5.25it/s]Ref scores:  32%|███▏      | 319/1000 [01:02<01:53,  6.00it/s]Ref scores:  32%|███▏      | 320/1000 [01:02<01:51,  6.08it/s]Ref scores:  32%|███▏      | 321/1000 [01:02<02:03,  5.50it/s]Ref scores:  32%|███▏      | 322/1000 [01:03<02:07,  5.33it/s]Ref scores:  32%|███▏      | 323/1000 [01:03<02:14,  5.02it/s]Ref scores:  32%|███▏      | 324/1000 [01:03<02:15,  4.97it/s]Ref scores:  32%|███▎      | 325/1000 [01:03<02:16,  4.93it/s]Ref scores:  33%|███▎      | 326/1000 [01:03<02:16,  4.93it/s]Ref scores:  33%|███▎      | 327/1000 [01:04<02:02,  5.49it/s]Ref scores:  33%|███▎      | 328/1000 [01:04<02:12,  5.08it/s]Ref scores:  33%|███▎      | 329/1000 [01:04<02:24,  4.65it/s]Ref scores:  33%|███▎      | 330/1000 [01:04<02:12,  5.04it/s]Ref scores:  33%|███▎      | 331/1000 [01:04<02:18,  4.82it/s]Ref scores:  33%|███▎      | 332/1000 [01:05<02:23,  4.66it/s]Ref scores:  33%|███▎      | 333/1000 [01:05<02:17,  4.84it/s]Ref scores:  33%|███▎      | 334/1000 [01:05<02:07,  5.21it/s]Ref scores:  34%|███▎      | 335/1000 [01:05<02:01,  5.49it/s]Ref scores:  34%|███▎      | 336/1000 [01:05<02:10,  5.10it/s]Ref scores:  34%|███▎      | 337/1000 [01:06<02:02,  5.40it/s]Ref scores:  34%|███▍      | 338/1000 [01:06<02:12,  5.00it/s]Ref scores:  34%|███▍      | 339/1000 [01:06<02:02,  5.40it/s]Ref scores:  34%|███▍      | 340/1000 [01:06<01:52,  5.87it/s]Ref scores:  34%|███▍      | 341/1000 [01:06<01:40,  6.56it/s]Ref scores:  34%|███▍      | 342/1000 [01:06<01:40,  6.55it/s]Ref scores:  34%|███▍      | 343/1000 [01:07<01:51,  5.90it/s]Ref scores:  34%|███▍      | 345/1000 [01:07<01:43,  6.32it/s]Ref scores:  35%|███▍      | 346/1000 [01:07<01:55,  5.68it/s]Ref scores:  35%|███▍      | 347/1000 [01:07<02:04,  5.23it/s]Ref scores:  35%|███▍      | 348/1000 [01:08<02:21,  4.62it/s]Ref scores:  35%|███▍      | 349/1000 [01:08<02:17,  4.74it/s]Ref scores:  35%|███▌      | 350/1000 [01:08<02:16,  4.78it/s]Ref scores:  35%|███▌      | 351/1000 [01:08<02:35,  4.18it/s]Ref scores:  35%|███▌      | 352/1000 [01:09<02:20,  4.62it/s]Ref scores:  35%|███▌      | 353/1000 [01:09<02:28,  4.34it/s]Ref scores:  35%|███▌      | 354/1000 [01:09<02:23,  4.51it/s]Ref scores:  36%|███▌      | 355/1000 [01:09<02:10,  4.96it/s]Ref scores:  36%|███▌      | 356/1000 [01:09<02:01,  5.29it/s]Ref scores:  36%|███▌      | 357/1000 [01:09<01:50,  5.81it/s]Ref scores:  36%|███▌      | 358/1000 [01:10<01:48,  5.93it/s]Ref scores:  36%|███▌      | 359/1000 [01:10<02:00,  5.31it/s]Ref scores:  36%|███▌      | 360/1000 [01:10<02:00,  5.30it/s]Ref scores:  36%|███▌      | 361/1000 [01:10<02:09,  4.94it/s]Ref scores:  36%|███▌      | 362/1000 [01:10<02:09,  4.91it/s]Ref scores:  36%|███▋      | 363/1000 [01:11<02:09,  4.92it/s]Ref scores:  36%|███▋      | 364/1000 [01:11<02:08,  4.95it/s]Ref scores:  36%|███▋      | 365/1000 [01:11<01:50,  5.75it/s]Ref scores:  37%|███▋      | 366/1000 [01:11<02:00,  5.24it/s]Ref scores:  37%|███▋      | 367/1000 [01:11<01:44,  6.03it/s]Ref scores:  37%|███▋      | 368/1000 [01:12<01:57,  5.36it/s]Ref scores:  37%|███▋      | 370/1000 [01:12<01:44,  6.03it/s]Ref scores:  37%|███▋      | 371/1000 [01:12<01:43,  6.10it/s]Ref scores:  37%|███▋      | 372/1000 [01:12<01:41,  6.16it/s]Ref scores:  37%|███▋      | 373/1000 [01:12<01:41,  6.18it/s]Ref scores:  37%|███▋      | 374/1000 [01:12<01:47,  5.80it/s]Ref scores:  38%|███▊      | 375/1000 [01:13<01:58,  5.28it/s]Ref scores:  38%|███▊      | 376/1000 [01:13<02:05,  4.98it/s]Ref scores:  38%|███▊      | 377/1000 [01:13<02:20,  4.43it/s]Ref scores:  38%|███▊      | 378/1000 [01:13<02:21,  4.40it/s]Ref scores:  38%|███▊      | 379/1000 [01:14<02:16,  4.55it/s]Ref scores:  38%|███▊      | 380/1000 [01:14<02:11,  4.70it/s]Ref scores:  38%|███▊      | 381/1000 [01:14<02:14,  4.60it/s]Ref scores:  38%|███▊      | 382/1000 [01:14<02:16,  4.52it/s]Ref scores:  38%|███▊      | 383/1000 [01:14<02:03,  4.99it/s]Ref scores:  38%|███▊      | 384/1000 [01:15<01:51,  5.52it/s]Ref scores:  38%|███▊      | 385/1000 [01:15<01:47,  5.74it/s]Ref scores:  39%|███▊      | 386/1000 [01:15<01:52,  5.46it/s]Ref scores:  39%|███▊      | 387/1000 [01:15<01:46,  5.76it/s]Ref scores:  39%|███▉      | 388/1000 [01:15<01:42,  6.00it/s]Ref scores:  39%|███▉      | 389/1000 [01:16<01:53,  5.37it/s]Ref scores:  39%|███▉      | 390/1000 [01:16<02:01,  5.01it/s]Ref scores:  39%|███▉      | 391/1000 [01:16<01:49,  5.58it/s]Ref scores:  39%|███▉      | 392/1000 [01:16<01:54,  5.33it/s]Ref scores:  39%|███▉      | 393/1000 [01:16<01:47,  5.66it/s]Ref scores:  39%|███▉      | 394/1000 [01:16<01:56,  5.20it/s]Ref scores:  40%|███▉      | 395/1000 [01:17<01:49,  5.54it/s]Ref scores:  40%|███▉      | 396/1000 [01:17<01:44,  5.77it/s]Ref scores:  40%|███▉      | 397/1000 [01:17<01:50,  5.47it/s]Ref scores:  40%|███▉      | 398/1000 [01:17<01:54,  5.26it/s]Ref scores:  40%|███▉      | 399/1000 [01:17<01:47,  5.59it/s]Ref scores:  40%|████      | 400/1000 [01:18<01:52,  5.35it/s]Ref scores:  40%|████      | 401/1000 [01:18<01:46,  5.60it/s]Ref scores:  40%|████      | 402/1000 [01:18<01:42,  5.85it/s]Ref scores:  40%|████      | 403/1000 [01:18<01:52,  5.31it/s]Ref scores:  40%|████      | 404/1000 [01:18<02:05,  4.73it/s]Ref scores:  40%|████      | 405/1000 [01:18<01:47,  5.54it/s]Ref scores:  41%|████      | 406/1000 [01:19<01:51,  5.33it/s]Ref scores:  41%|████      | 407/1000 [01:19<01:44,  5.65it/s]Ref scores:  41%|████      | 408/1000 [01:19<01:41,  5.82it/s]Ref scores:  41%|████      | 409/1000 [01:19<01:39,  5.93it/s]Ref scores:  41%|████      | 410/1000 [01:19<01:46,  5.54it/s]Ref scores:  41%|████      | 411/1000 [01:20<01:50,  5.33it/s]Ref scores:  41%|████      | 412/1000 [01:20<01:50,  5.32it/s]Ref scores:  41%|████▏     | 413/1000 [01:20<01:53,  5.17it/s]Ref scores:  41%|████▏     | 414/1000 [01:20<01:59,  4.90it/s]Ref scores:  42%|████▏     | 415/1000 [01:20<02:04,  4.72it/s]Ref scores:  42%|████▏     | 416/1000 [01:21<02:12,  4.42it/s]Ref scores:  42%|████▏     | 417/1000 [01:21<02:07,  4.56it/s]Ref scores:  42%|████▏     | 418/1000 [01:21<01:52,  5.18it/s]Ref scores:  42%|████▏     | 419/1000 [01:21<01:59,  4.87it/s]Ref scores:  42%|████▏     | 420/1000 [01:21<01:57,  4.92it/s]Ref scores:  42%|████▏     | 421/1000 [01:22<01:57,  4.93it/s]Ref scores:  42%|████▏     | 422/1000 [01:22<01:45,  5.47it/s]Ref scores:  42%|████▏     | 423/1000 [01:22<01:37,  5.93it/s]Ref scores:  42%|████▏     | 424/1000 [01:22<01:42,  5.60it/s]Ref scores:  42%|████▎     | 425/1000 [01:22<01:35,  6.04it/s]Ref scores:  43%|████▎     | 426/1000 [01:22<01:33,  6.11it/s]Ref scores:  43%|████▎     | 427/1000 [01:23<01:28,  6.51it/s]Ref scores:  43%|████▎     | 428/1000 [01:23<01:20,  7.10it/s]Ref scores:  43%|████▎     | 429/1000 [01:23<01:19,  7.17it/s]Ref scores:  43%|████▎     | 430/1000 [01:23<01:14,  7.64it/s]Ref scores:  43%|████▎     | 431/1000 [01:23<01:14,  7.59it/s]Ref scores:  43%|████▎     | 432/1000 [01:23<01:18,  7.24it/s]Ref scores:  43%|████▎     | 433/1000 [01:23<01:17,  7.31it/s]Ref scores:  43%|████▎     | 434/1000 [01:24<01:29,  6.36it/s]Ref scores:  44%|████▎     | 435/1000 [01:24<01:36,  5.87it/s]Ref scores:  44%|████▎     | 436/1000 [01:24<01:39,  5.69it/s]Ref scores:  44%|████▎     | 437/1000 [01:24<01:43,  5.45it/s]Ref scores:  44%|████▍     | 438/1000 [01:24<01:51,  5.04it/s]Ref scores:  44%|████▍     | 439/1000 [01:24<01:43,  5.43it/s]Ref scores:  44%|████▍     | 440/1000 [01:25<01:44,  5.38it/s]Ref scores:  44%|████▍     | 441/1000 [01:25<01:51,  5.03it/s]Ref scores:  44%|████▍     | 442/1000 [01:25<01:44,  5.33it/s]Ref scores:  44%|████▍     | 443/1000 [01:25<01:47,  5.19it/s]Ref scores:  44%|████▍     | 444/1000 [01:25<01:41,  5.49it/s]Ref scores:  44%|████▍     | 445/1000 [01:26<01:44,  5.33it/s]Ref scores:  45%|████▍     | 446/1000 [01:26<01:45,  5.23it/s]Ref scores:  45%|████▍     | 447/1000 [01:26<01:52,  4.90it/s]Ref scores:  45%|████▍     | 448/1000 [01:26<02:02,  4.52it/s]Ref scores:  45%|████▍     | 449/1000 [01:27<02:03,  4.45it/s]Ref scores:  45%|████▌     | 450/1000 [01:27<01:59,  4.59it/s]Ref scores:  45%|████▌     | 451/1000 [01:27<01:55,  4.77it/s]Ref scores:  45%|████▌     | 452/1000 [01:27<01:42,  5.34it/s]Ref scores:  45%|████▌     | 453/1000 [01:27<01:54,  4.78it/s]Ref scores:  45%|████▌     | 454/1000 [01:28<01:52,  4.83it/s]Ref scores:  46%|████▌     | 455/1000 [01:28<01:51,  4.87it/s]Ref scores:  46%|████▌     | 456/1000 [01:28<01:40,  5.43it/s]Ref scores:  46%|████▌     | 457/1000 [01:28<01:36,  5.64it/s]Ref scores:  46%|████▌     | 458/1000 [01:28<01:37,  5.53it/s]Ref scores:  46%|████▌     | 459/1000 [01:28<01:46,  5.08it/s]Ref scores:  46%|████▌     | 460/1000 [01:29<01:51,  4.83it/s]Ref scores:  46%|████▌     | 461/1000 [01:29<01:44,  5.18it/s]Ref scores:  46%|████▌     | 462/1000 [01:29<01:34,  5.68it/s]Ref scores:  46%|████▋     | 463/1000 [01:29<01:24,  6.39it/s]Ref scores:  46%|████▋     | 464/1000 [01:29<01:36,  5.58it/s]Ref scores:  46%|████▋     | 465/1000 [01:30<01:44,  5.14it/s]Ref scores:  47%|████▋     | 466/1000 [01:30<01:29,  5.99it/s]Ref scores:  47%|████▋     | 467/1000 [01:30<01:39,  5.37it/s]Ref scores:  47%|████▋     | 468/1000 [01:30<01:34,  5.62it/s]Ref scores:  47%|████▋     | 469/1000 [01:30<01:31,  5.82it/s]Ref scores:  47%|████▋     | 470/1000 [01:30<01:45,  5.02it/s]Ref scores:  47%|████▋     | 471/1000 [01:31<01:50,  4.77it/s]Ref scores:  47%|████▋     | 472/1000 [01:31<01:38,  5.36it/s]Ref scores:  47%|████▋     | 473/1000 [01:31<01:41,  5.19it/s]Ref scores:  47%|████▋     | 474/1000 [01:31<01:48,  4.85it/s]Ref scores:  48%|████▊     | 475/1000 [01:31<01:39,  5.26it/s]Ref scores:  48%|████▊     | 476/1000 [01:32<01:45,  4.95it/s]Ref scores:  48%|████▊     | 477/1000 [01:32<01:38,  5.33it/s]Ref scores:  48%|████▊     | 478/1000 [01:32<01:40,  5.22it/s]Ref scores:  48%|████▊     | 479/1000 [01:32<01:39,  5.23it/s]Ref scores:  48%|████▊     | 480/1000 [01:32<01:33,  5.56it/s]Ref scores:  48%|████▊     | 481/1000 [01:33<01:41,  5.13it/s]Ref scores:  48%|████▊     | 482/1000 [01:33<01:42,  5.03it/s]Ref scores:  48%|████▊     | 483/1000 [01:33<01:32,  5.56it/s]Ref scores:  48%|████▊     | 484/1000 [01:33<01:28,  5.84it/s]Ref scores:  48%|████▊     | 485/1000 [01:33<01:26,  5.96it/s]Ref scores:  49%|████▊     | 486/1000 [01:34<01:40,  5.09it/s]Ref scores:  49%|████▊     | 487/1000 [01:34<01:33,  5.46it/s]Ref scores:  49%|████▉     | 488/1000 [01:34<01:29,  5.75it/s]Ref scores:  49%|████▉     | 489/1000 [01:34<01:42,  4.98it/s]Ref scores:  49%|████▉     | 490/1000 [01:34<01:36,  5.30it/s]Ref scores:  49%|████▉     | 491/1000 [01:34<01:38,  5.16it/s]Ref scores:  49%|████▉     | 492/1000 [01:35<01:44,  4.88it/s]Ref scores:  49%|████▉     | 493/1000 [01:35<01:35,  5.30it/s]Ref scores:  49%|████▉     | 494/1000 [01:35<01:23,  6.06it/s]Ref scores:  50%|████▉     | 495/1000 [01:35<01:29,  5.65it/s]Ref scores:  50%|████▉     | 496/1000 [01:35<01:32,  5.43it/s]Ref scores:  50%|████▉     | 497/1000 [01:36<01:36,  5.23it/s]Ref scores:  50%|████▉     | 498/1000 [01:36<01:42,  4.90it/s]Ref scores:  50%|████▉     | 499/1000 [01:36<01:27,  5.70it/s]Ref scores:  50%|█████     | 500/1000 [01:36<01:16,  6.50it/s]Ref scores:  50%|█████     | 501/1000 [01:36<01:24,  5.93it/s]Ref scores:  50%|█████     | 502/1000 [01:36<01:21,  6.12it/s]Ref scores:  50%|█████     | 503/1000 [01:37<01:26,  5.73it/s]Ref scores:  50%|█████     | 504/1000 [01:37<01:30,  5.47it/s]Ref scores:  50%|█████     | 505/1000 [01:37<01:33,  5.27it/s]Ref scores:  51%|█████     | 506/1000 [01:37<01:28,  5.61it/s]Ref scores:  51%|█████     | 507/1000 [01:37<01:35,  5.14it/s]Ref scores:  51%|█████     | 508/1000 [01:37<01:26,  5.67it/s]Ref scores:  51%|█████     | 509/1000 [01:38<01:30,  5.44it/s]Ref scores:  51%|█████     | 510/1000 [01:38<01:23,  5.90it/s]Ref scores:  51%|█████     | 511/1000 [01:38<01:14,  6.59it/s]Ref scores:  51%|█████     | 512/1000 [01:38<01:07,  7.18it/s]Ref scores:  51%|█████▏    | 513/1000 [01:38<01:16,  6.35it/s]Ref scores:  51%|█████▏    | 514/1000 [01:38<01:22,  5.88it/s]Ref scores:  52%|█████▏    | 515/1000 [01:39<01:16,  6.32it/s]Ref scores:  52%|█████▏    | 516/1000 [01:39<01:22,  5.85it/s]Ref scores:  52%|█████▏    | 517/1000 [01:39<01:35,  5.03it/s]Ref scores:  52%|█████▏    | 518/1000 [01:39<01:40,  4.80it/s]Ref scores:  52%|█████▏    | 519/1000 [01:39<01:38,  4.87it/s]Ref scores:  52%|█████▏    | 520/1000 [01:40<01:28,  5.44it/s]Ref scores:  52%|█████▏    | 521/1000 [01:40<01:23,  5.75it/s]Ref scores:  52%|█████▏    | 522/1000 [01:40<01:27,  5.44it/s]Ref scores:  52%|█████▏    | 523/1000 [01:40<01:22,  5.76it/s]Ref scores:  52%|█████▏    | 524/1000 [01:40<01:26,  5.52it/s]Ref scores:  52%|█████▎    | 525/1000 [01:41<01:37,  4.88it/s]Ref scores:  53%|█████▎    | 526/1000 [01:41<01:40,  4.69it/s]Ref scores:  53%|█████▎    | 527/1000 [01:41<01:43,  4.57it/s]Ref scores:  53%|█████▎    | 528/1000 [01:41<01:31,  5.16it/s]Ref scores:  53%|█████▎    | 529/1000 [01:41<01:30,  5.20it/s]Ref scores:  53%|█████▎    | 530/1000 [01:42<01:36,  4.89it/s]Ref scores:  53%|█████▎    | 531/1000 [01:42<01:39,  4.70it/s]Ref scores:  53%|█████▎    | 532/1000 [01:42<01:24,  5.56it/s]Ref scores:  53%|█████▎    | 533/1000 [01:42<01:17,  5.99it/s]Ref scores:  53%|█████▎    | 534/1000 [01:42<01:26,  5.38it/s]Ref scores:  54%|█████▎    | 535/1000 [01:43<01:32,  5.01it/s]Ref scores:  54%|█████▎    | 536/1000 [01:43<02:01,  3.81it/s]Ref scores:  54%|█████▎    | 537/1000 [01:43<01:43,  4.48it/s]Ref scores:  54%|█████▍    | 538/1000 [01:43<01:40,  4.58it/s]Ref scores:  54%|█████▍    | 539/1000 [01:44<01:46,  4.33it/s]Ref scores:  54%|█████▍    | 540/1000 [01:44<01:36,  4.78it/s]Ref scores:  54%|█████▍    | 541/1000 [01:44<01:28,  5.20it/s]Ref scores:  54%|█████▍    | 542/1000 [01:44<01:23,  5.49it/s]Ref scores:  54%|█████▍    | 543/1000 [01:44<01:17,  5.93it/s]Ref scores:  54%|█████▍    | 544/1000 [01:44<01:14,  6.12it/s]Ref scores:  55%|█████▍    | 545/1000 [01:44<01:12,  6.24it/s]Ref scores:  55%|█████▍    | 546/1000 [01:45<01:22,  5.52it/s]Ref scores:  55%|█████▍    | 547/1000 [01:45<01:24,  5.35it/s]Ref scores:  55%|█████▍    | 548/1000 [01:45<01:27,  5.19it/s]Ref scores:  55%|█████▍    | 549/1000 [01:45<01:18,  5.74it/s]Ref scores:  55%|█████▌    | 550/1000 [01:45<01:16,  5.90it/s]Ref scores:  55%|█████▌    | 551/1000 [01:46<01:20,  5.58it/s]Ref scores:  55%|█████▌    | 552/1000 [01:46<01:23,  5.36it/s]Ref scores:  55%|█████▌    | 553/1000 [01:46<01:29,  4.99it/s]Ref scores:  55%|█████▌    | 554/1000 [01:46<01:20,  5.57it/s]Ref scores:  56%|█████▌    | 555/1000 [01:46<01:17,  5.76it/s]Ref scores:  56%|█████▌    | 556/1000 [01:46<01:15,  5.91it/s]Ref scores:  56%|█████▌    | 557/1000 [01:47<01:10,  6.28it/s]Ref scores:  56%|█████▌    | 558/1000 [01:47<01:19,  5.53it/s]Ref scores:  56%|█████▌    | 559/1000 [01:47<01:26,  5.09it/s]Ref scores:  56%|█████▌    | 560/1000 [01:47<01:21,  5.38it/s]Ref scores:  56%|█████▌    | 561/1000 [01:47<01:23,  5.26it/s]Ref scores:  56%|█████▌    | 562/1000 [01:48<01:18,  5.60it/s]Ref scores:  56%|█████▋    | 563/1000 [01:48<01:29,  4.90it/s]Ref scores:  56%|█████▋    | 564/1000 [01:48<01:32,  4.71it/s]Ref scores:  56%|█████▋    | 565/1000 [01:48<01:25,  5.10it/s]Ref scores:  57%|█████▋    | 566/1000 [01:48<01:17,  5.63it/s]Ref scores:  57%|█████▋    | 567/1000 [01:48<01:11,  6.09it/s]Ref scores:  57%|█████▋    | 568/1000 [01:49<01:19,  5.41it/s]Ref scores:  57%|█████▋    | 570/1000 [01:49<01:04,  6.68it/s]Ref scores:  57%|█████▋    | 571/1000 [01:49<01:04,  6.68it/s]Ref scores:  57%|█████▋    | 572/1000 [01:49<01:09,  6.14it/s]Ref scores:  57%|█████▋    | 573/1000 [01:49<01:14,  5.73it/s]Ref scores:  57%|█████▋    | 574/1000 [01:50<01:12,  5.87it/s]Ref scores:  57%|█████▊    | 575/1000 [01:50<01:19,  5.38it/s]Ref scores:  58%|█████▊    | 576/1000 [01:50<01:12,  5.86it/s]Ref scores:  58%|█████▊    | 577/1000 [01:50<01:19,  5.32it/s]Ref scores:  58%|█████▊    | 578/1000 [01:51<01:59,  3.52it/s]Ref scores:  58%|█████▊    | 579/1000 [01:51<01:52,  3.73it/s]Ref scores:  58%|█████▊    | 580/1000 [01:51<01:50,  3.80it/s]Ref scores:  58%|█████▊    | 581/1000 [01:51<01:36,  4.35it/s]Ref scores:  58%|█████▊    | 582/1000 [01:52<01:36,  4.34it/s]Ref scores:  58%|█████▊    | 583/1000 [01:52<01:26,  4.84it/s]Ref scores:  58%|█████▊    | 584/1000 [01:52<01:26,  4.83it/s]Ref scores:  58%|█████▊    | 585/1000 [01:52<01:16,  5.42it/s]Ref scores:  59%|█████▊    | 586/1000 [01:52<01:22,  5.02it/s]Ref scores:  59%|█████▊    | 587/1000 [01:53<01:22,  5.02it/s]Ref scores:  59%|█████▉    | 588/1000 [01:53<01:25,  4.81it/s]Ref scores:  59%|█████▉    | 589/1000 [01:53<01:16,  5.38it/s]Ref scores:  59%|█████▉    | 590/1000 [01:53<01:18,  5.22it/s]Ref scores:  59%|█████▉    | 591/1000 [01:53<01:23,  4.91it/s]Ref scores:  59%|█████▉    | 592/1000 [01:54<01:23,  4.90it/s]Ref scores:  59%|█████▉    | 593/1000 [01:54<01:23,  4.89it/s]Ref scores:  59%|█████▉    | 594/1000 [01:54<01:14,  5.48it/s]Ref scores:  60%|█████▉    | 595/1000 [01:54<01:23,  4.86it/s]Ref scores:  60%|█████▉    | 596/1000 [01:54<01:22,  4.91it/s]Ref scores:  60%|█████▉    | 597/1000 [01:55<01:16,  5.26it/s]Ref scores:  60%|█████▉    | 598/1000 [01:55<01:16,  5.27it/s]Ref scores:  60%|█████▉    | 599/1000 [01:55<01:17,  5.16it/s]Ref scores:  60%|██████    | 600/1000 [01:55<01:17,  5.19it/s]Ref scores:  60%|██████    | 601/1000 [01:55<01:10,  5.69it/s]Ref scores:  60%|██████    | 602/1000 [01:55<01:07,  5.93it/s]Ref scores:  60%|██████    | 603/1000 [01:56<01:05,  6.08it/s]Ref scores:  60%|██████    | 604/1000 [01:56<01:03,  6.21it/s]Ref scores:  60%|██████    | 605/1000 [01:56<01:00,  6.56it/s]Ref scores:  61%|██████    | 606/1000 [01:56<01:05,  5.98it/s]Ref scores:  61%|██████    | 607/1000 [01:56<01:04,  6.05it/s]Ref scores:  61%|██████    | 608/1000 [01:56<01:08,  5.69it/s]Ref scores:  61%|██████    | 609/1000 [01:57<01:07,  5.83it/s]Ref scores:  61%|██████    | 610/1000 [01:57<01:05,  5.95it/s]Ref scores:  61%|██████    | 611/1000 [01:57<01:16,  5.09it/s]Ref scores:  61%|██████    | 612/1000 [01:57<01:20,  4.81it/s]Ref scores:  61%|██████▏   | 613/1000 [01:57<01:26,  4.48it/s]Ref scores:  61%|██████▏   | 614/1000 [01:58<01:23,  4.61it/s]Ref scores:  62%|██████▏   | 615/1000 [01:58<01:25,  4.51it/s]Ref scores:  62%|██████▏   | 616/1000 [01:58<01:29,  4.27it/s]Ref scores:  62%|██████▏   | 617/1000 [01:58<01:20,  4.77it/s]Ref scores:  62%|██████▏   | 618/1000 [01:58<01:11,  5.37it/s]Ref scores:  62%|██████▏   | 619/1000 [01:59<01:05,  5.84it/s]Ref scores:  62%|██████▏   | 620/1000 [01:59<01:12,  5.26it/s]Ref scores:  62%|██████▏   | 621/1000 [01:59<01:08,  5.53it/s]Ref scores:  62%|██████▏   | 622/1000 [01:59<01:11,  5.30it/s]Ref scores:  62%|██████▏   | 623/1000 [01:59<01:02,  6.07it/s]Ref scores:  62%|██████▏   | 624/1000 [01:59<00:58,  6.41it/s]Ref scores:  62%|██████▎   | 625/1000 [02:00<00:58,  6.39it/s]Ref scores:  63%|██████▎   | 626/1000 [02:00<00:58,  6.35it/s]Ref scores:  63%|██████▎   | 627/1000 [02:00<01:03,  5.88it/s]Ref scores:  63%|██████▎   | 628/1000 [02:00<01:09,  5.36it/s]Ref scores:  63%|██████▎   | 629/1000 [02:00<01:03,  5.87it/s]Ref scores:  63%|██████▎   | 630/1000 [02:00<01:00,  6.10it/s]Ref scores:  63%|██████▎   | 631/1000 [02:01<00:59,  6.18it/s]Ref scores:  63%|██████▎   | 632/1000 [02:01<01:03,  5.83it/s]Ref scores:  63%|██████▎   | 633/1000 [02:01<00:56,  6.54it/s]Ref scores:  63%|██████▎   | 634/1000 [02:01<01:01,  5.99it/s]Ref scores:  64%|██████▎   | 635/1000 [02:01<00:57,  6.36it/s]Ref scores:  64%|██████▎   | 636/1000 [02:01<01:01,  5.87it/s]Ref scores:  64%|██████▎   | 637/1000 [02:02<01:00,  6.01it/s]Ref scores:  64%|██████▍   | 638/1000 [02:02<01:06,  5.41it/s]Ref scores:  64%|██████▍   | 639/1000 [02:02<01:11,  5.05it/s]Ref scores:  64%|██████▍   | 640/1000 [02:02<01:17,  4.65it/s]Ref scores:  64%|██████▍   | 641/1000 [02:02<01:04,  5.53it/s]Ref scores:  64%|██████▍   | 642/1000 [02:03<01:01,  5.82it/s]Ref scores:  64%|██████▍   | 643/1000 [02:03<00:59,  5.96it/s]Ref scores:  64%|██████▍   | 644/1000 [02:03<01:03,  5.60it/s]Ref scores:  64%|██████▍   | 645/1000 [02:03<01:01,  5.79it/s]Ref scores:  65%|██████▍   | 646/1000 [02:03<00:56,  6.21it/s]Ref scores:  65%|██████▍   | 647/1000 [02:03<00:54,  6.53it/s]Ref scores:  65%|██████▍   | 648/1000 [02:04<00:54,  6.43it/s]Ref scores:  65%|██████▍   | 649/1000 [02:04<01:02,  5.60it/s]Ref scores:  65%|██████▌   | 650/1000 [02:04<00:59,  5.85it/s]Ref scores:  65%|██████▌   | 651/1000 [02:04<00:57,  6.02it/s]Ref scores:  65%|██████▌   | 652/1000 [02:04<00:56,  6.12it/s]Ref scores:  65%|██████▌   | 653/1000 [02:04<00:59,  5.84it/s]Ref scores:  65%|██████▌   | 654/1000 [02:05<00:55,  6.24it/s]Ref scores:  66%|██████▌   | 655/1000 [02:05<00:55,  6.24it/s]Ref scores:  66%|██████▌   | 656/1000 [02:05<00:54,  6.26it/s]Ref scores:  66%|██████▌   | 657/1000 [02:05<00:59,  5.80it/s]Ref scores:  66%|██████▌   | 658/1000 [02:05<01:01,  5.54it/s]Ref scores:  66%|██████▌   | 659/1000 [02:05<01:06,  5.10it/s]Ref scores:  66%|██████▌   | 661/1000 [02:06<00:57,  5.88it/s]Ref scores:  66%|██████▌   | 662/1000 [02:06<00:55,  6.04it/s]Ref scores:  66%|██████▋   | 663/1000 [02:06<01:01,  5.47it/s]Ref scores:  66%|██████▋   | 664/1000 [02:06<01:07,  4.97it/s]Ref scores:  66%|██████▋   | 665/1000 [02:07<01:03,  5.25it/s]Ref scores:  67%|██████▋   | 666/1000 [02:07<01:03,  5.26it/s]Ref scores:  67%|██████▋   | 667/1000 [02:07<00:59,  5.59it/s]Ref scores:  67%|██████▋   | 668/1000 [02:07<01:09,  4.76it/s]Ref scores:  67%|██████▋   | 669/1000 [02:07<01:04,  5.12it/s]Ref scores:  67%|██████▋   | 670/1000 [02:07<01:00,  5.49it/s]Ref scores:  67%|██████▋   | 671/1000 [02:08<01:01,  5.31it/s]Ref scores:  67%|██████▋   | 672/1000 [02:08<01:06,  4.96it/s]Ref scores:  67%|██████▋   | 673/1000 [02:08<01:06,  4.95it/s]Ref scores:  67%|██████▋   | 674/1000 [02:08<01:05,  4.94it/s]Ref scores:  68%|██████▊   | 675/1000 [02:08<00:59,  5.48it/s]Ref scores:  68%|██████▊   | 676/1000 [02:09<01:04,  5.06it/s]Ref scores:  68%|██████▊   | 677/1000 [02:09<00:57,  5.58it/s]Ref scores:  68%|██████▊   | 678/1000 [02:09<00:53,  6.04it/s]Ref scores:  68%|██████▊   | 679/1000 [02:09<00:51,  6.20it/s]Ref scores:  68%|██████▊   | 680/1000 [02:09<01:01,  5.22it/s]Ref scores:  68%|██████▊   | 681/1000 [02:10<00:55,  5.74it/s]Ref scores:  68%|██████▊   | 682/1000 [02:10<00:58,  5.45it/s]Ref scores:  68%|██████▊   | 683/1000 [02:10<01:00,  5.27it/s]Ref scores:  68%|██████▊   | 684/1000 [02:10<00:57,  5.52it/s]Ref scores:  68%|██████▊   | 685/1000 [02:10<00:59,  5.29it/s]Ref scores:  69%|██████▊   | 686/1000 [02:10<00:54,  5.79it/s]Ref scores:  69%|██████▊   | 687/1000 [02:11<00:59,  5.26it/s]Ref scores:  69%|██████▉   | 688/1000 [02:11<00:50,  6.12it/s]Ref scores:  69%|██████▉   | 689/1000 [02:11<00:57,  5.41it/s]Ref scores:  69%|██████▉   | 690/1000 [02:11<01:04,  4.81it/s]Ref scores:  69%|██████▉   | 691/1000 [02:11<01:03,  4.86it/s]Ref scores:  69%|██████▉   | 692/1000 [02:12<01:05,  4.68it/s]Ref scores:  69%|██████▉   | 693/1000 [02:12<01:04,  4.77it/s]Ref scores:  69%|██████▉   | 694/1000 [02:12<00:58,  5.19it/s]Ref scores:  70%|██████▉   | 695/1000 [02:12<01:02,  4.91it/s]Ref scores:  70%|██████▉   | 696/1000 [02:12<01:01,  4.91it/s]Ref scores:  70%|██████▉   | 697/1000 [02:13<01:04,  4.72it/s]Ref scores:  70%|██████▉   | 698/1000 [02:13<01:02,  4.87it/s]Ref scores:  70%|██████▉   | 699/1000 [02:13<00:57,  5.20it/s]Ref scores:  70%|███████   | 700/1000 [02:13<00:54,  5.55it/s]Ref scores:  70%|███████   | 701/1000 [02:13<00:56,  5.31it/s]Ref scores:  70%|███████   | 702/1000 [02:14<00:56,  5.30it/s]Ref scores:  70%|███████   | 703/1000 [02:14<00:57,  5.21it/s]Ref scores:  70%|███████   | 704/1000 [02:14<00:51,  5.72it/s]Ref scores:  70%|███████   | 705/1000 [02:14<00:50,  5.85it/s]Ref scores:  71%|███████   | 706/1000 [02:14<00:48,  6.05it/s]Ref scores:  71%|███████   | 707/1000 [02:14<00:47,  6.20it/s]Ref scores:  71%|███████   | 708/1000 [02:15<00:47,  6.20it/s]Ref scores:  71%|███████   | 709/1000 [02:15<00:50,  5.72it/s]Ref scores:  71%|███████   | 710/1000 [02:15<00:56,  5.17it/s]Ref scores:  71%|███████   | 711/1000 [02:15<00:56,  5.08it/s]Ref scores:  71%|███████   | 712/1000 [02:15<00:49,  5.85it/s]Ref scores:  71%|███████▏  | 713/1000 [02:15<00:48,  5.96it/s]Ref scores:  71%|███████▏  | 714/1000 [02:16<00:47,  6.06it/s]Ref scores:  72%|███████▏  | 715/1000 [02:16<00:50,  5.68it/s]Ref scores:  72%|███████▏  | 716/1000 [02:16<00:52,  5.43it/s]Ref scores:  72%|███████▏  | 717/1000 [02:16<00:50,  5.65it/s]Ref scores:  72%|███████▏  | 718/1000 [02:16<00:54,  5.17it/s]Ref scores:  72%|███████▏  | 719/1000 [02:17<00:57,  4.88it/s]Ref scores:  72%|███████▏  | 720/1000 [02:17<00:49,  5.70it/s]Ref scores:  72%|███████▏  | 721/1000 [02:17<00:47,  5.85it/s]Ref scores:  72%|███████▏  | 722/1000 [02:17<00:46,  5.97it/s]Ref scores:  72%|███████▏  | 723/1000 [02:17<00:45,  6.04it/s]Ref scores:  72%|███████▏  | 724/1000 [02:17<00:42,  6.42it/s]Ref scores:  72%|███████▎  | 725/1000 [02:18<00:48,  5.68it/s]Ref scores:  73%|███████▎  | 726/1000 [02:18<00:46,  5.83it/s]Ref scores:  73%|███████▎  | 727/1000 [02:18<00:51,  5.32it/s]Ref scores:  73%|███████▎  | 728/1000 [02:18<00:56,  4.84it/s]Ref scores:  73%|███████▎  | 729/1000 [02:18<00:55,  4.89it/s]Ref scores:  73%|███████▎  | 730/1000 [02:19<00:57,  4.71it/s]Ref scores:  73%|███████▎  | 731/1000 [02:19<00:55,  4.87it/s]Ref scores:  73%|███████▎  | 732/1000 [02:19<00:46,  5.71it/s]Ref scores:  73%|███████▎  | 733/1000 [02:19<00:53,  4.97it/s]Ref scores:  73%|███████▎  | 734/1000 [02:20<01:04,  4.15it/s]Ref scores:  74%|███████▎  | 735/1000 [02:20<00:55,  4.77it/s]Ref scores:  74%|███████▎  | 736/1000 [02:20<00:47,  5.56it/s]Ref scores:  74%|███████▎  | 737/1000 [02:20<00:48,  5.39it/s]Ref scores:  74%|███████▍  | 738/1000 [02:20<00:50,  5.21it/s]Ref scores:  74%|███████▍  | 739/1000 [02:20<00:55,  4.70it/s]Ref scores:  74%|███████▍  | 740/1000 [02:21<00:51,  5.07it/s]Ref scores:  74%|███████▍  | 741/1000 [02:21<00:53,  4.82it/s]Ref scores:  74%|███████▍  | 742/1000 [02:21<00:55,  4.67it/s]Ref scores:  74%|███████▍  | 743/1000 [02:21<00:50,  5.10it/s]Ref scores:  74%|███████▍  | 744/1000 [02:21<00:45,  5.64it/s]Ref scores:  74%|███████▍  | 745/1000 [02:22<00:46,  5.43it/s]Ref scores:  75%|███████▍  | 746/1000 [02:22<00:48,  5.22it/s]Ref scores:  75%|███████▍  | 747/1000 [02:22<00:51,  4.92it/s]Ref scores:  75%|███████▍  | 748/1000 [02:22<00:43,  5.80it/s]Ref scores:  75%|███████▍  | 749/1000 [02:22<00:42,  5.92it/s]Ref scores:  75%|███████▌  | 750/1000 [02:23<00:44,  5.57it/s]Ref scores:  75%|███████▌  | 751/1000 [02:23<00:46,  5.32it/s]Ref scores:  75%|███████▌  | 752/1000 [02:23<00:42,  5.82it/s]Ref scores:  75%|███████▌  | 753/1000 [02:23<00:41,  5.93it/s]Ref scores:  75%|███████▌  | 754/1000 [02:23<00:40,  6.12it/s]Ref scores:  76%|███████▌  | 755/1000 [02:23<00:45,  5.44it/s]Ref scores:  76%|███████▌  | 756/1000 [02:24<00:46,  5.28it/s]Ref scores:  76%|███████▌  | 757/1000 [02:24<00:46,  5.27it/s]Ref scores:  76%|███████▌  | 758/1000 [02:24<00:41,  5.78it/s]Ref scores:  76%|███████▌  | 759/1000 [02:24<00:45,  5.25it/s]Ref scores:  76%|███████▌  | 760/1000 [02:24<00:42,  5.59it/s]Ref scores:  76%|███████▌  | 761/1000 [02:24<00:40,  5.84it/s]Ref scores:  76%|███████▌  | 762/1000 [02:25<00:39,  6.04it/s]Ref scores:  76%|███████▋  | 763/1000 [02:25<00:38,  6.20it/s]Ref scores:  76%|███████▋  | 764/1000 [02:25<00:37,  6.21it/s]Ref scores:  76%|███████▋  | 765/1000 [02:25<00:42,  5.49it/s]Ref scores:  77%|███████▋  | 766/1000 [02:25<00:41,  5.71it/s]Ref scores:  77%|███████▋  | 767/1000 [02:26<00:45,  5.17it/s]Ref scores:  77%|███████▋  | 768/1000 [02:26<00:47,  4.88it/s]Ref scores:  77%|███████▋  | 769/1000 [02:26<00:44,  5.22it/s]Ref scores:  77%|███████▋  | 770/1000 [02:26<00:39,  5.76it/s]Ref scores:  77%|███████▋  | 771/1000 [02:26<00:40,  5.61it/s]Ref scores:  77%|███████▋  | 772/1000 [02:26<00:44,  5.15it/s]Ref scores:  77%|███████▋  | 773/1000 [02:27<00:41,  5.51it/s]Ref scores:  77%|███████▋  | 774/1000 [02:27<00:44,  5.09it/s]Ref scores:  78%|███████▊  | 775/1000 [02:27<00:44,  5.00it/s]Ref scores:  78%|███████▊  | 776/1000 [02:27<00:46,  4.77it/s]Ref scores:  78%|███████▊  | 777/1000 [02:27<00:40,  5.56it/s]Ref scores:  78%|███████▊  | 778/1000 [02:28<00:43,  5.11it/s]Ref scores:  78%|███████▊  | 779/1000 [02:28<00:40,  5.49it/s]Ref scores:  78%|███████▊  | 780/1000 [02:28<00:41,  5.27it/s]Ref scores:  78%|███████▊  | 781/1000 [02:28<00:46,  4.74it/s]Ref scores:  78%|███████▊  | 782/1000 [02:29<00:49,  4.41it/s]Ref scores:  78%|███████▊  | 783/1000 [02:29<00:44,  4.86it/s]Ref scores:  78%|███████▊  | 784/1000 [02:29<00:40,  5.28it/s]Ref scores:  78%|███████▊  | 785/1000 [02:29<00:43,  4.96it/s]Ref scores:  79%|███████▊  | 786/1000 [02:29<00:38,  5.51it/s]Ref scores:  79%|███████▊  | 787/1000 [02:29<00:39,  5.44it/s]Ref scores:  79%|███████▉  | 788/1000 [02:30<00:37,  5.71it/s]Ref scores:  79%|███████▉  | 789/1000 [02:30<00:41,  5.02it/s]Ref scores:  79%|███████▉  | 790/1000 [02:30<00:37,  5.59it/s]Ref scores:  79%|███████▉  | 791/1000 [02:30<00:42,  4.96it/s]Ref scores:  79%|███████▉  | 792/1000 [02:30<00:41,  4.96it/s]Ref scores:  79%|███████▉  | 793/1000 [02:31<00:43,  4.76it/s]Ref scores:  79%|███████▉  | 794/1000 [02:31<00:45,  4.49it/s]Ref scores:  80%|███████▉  | 795/1000 [02:31<00:41,  4.91it/s]Ref scores:  80%|███████▉  | 796/1000 [02:31<00:43,  4.72it/s]Ref scores:  80%|███████▉  | 797/1000 [02:32<00:44,  4.60it/s]Ref scores:  80%|███████▉  | 798/1000 [02:32<00:44,  4.53it/s]Ref scores:  80%|███████▉  | 799/1000 [02:32<01:00,  3.35it/s]Ref scores:  80%|████████  | 800/1000 [02:32<00:53,  3.71it/s]Ref scores:  80%|████████  | 801/1000 [02:33<00:51,  3.86it/s]Ref scores:  80%|████████  | 802/1000 [02:33<00:43,  4.52it/s]Ref scores:  80%|████████  | 803/1000 [02:33<00:44,  4.48it/s]Ref scores:  80%|████████  | 804/1000 [02:33<00:36,  5.33it/s]Ref scores:  80%|████████  | 805/1000 [02:33<00:33,  5.83it/s]Ref scores:  81%|████████  | 806/1000 [02:33<00:35,  5.50it/s]Ref scores:  81%|████████  | 807/1000 [02:34<00:36,  5.32it/s]Ref scores:  81%|████████  | 809/1000 [02:34<00:31,  6.02it/s]Ref scores:  81%|████████  | 810/1000 [02:34<00:34,  5.48it/s]Ref scores:  81%|████████  | 811/1000 [02:34<00:32,  5.75it/s]Ref scores:  81%|████████  | 812/1000 [02:35<00:34,  5.50it/s]Ref scores:  81%|████████▏ | 813/1000 [02:35<00:32,  5.76it/s]Ref scores:  81%|████████▏ | 814/1000 [02:35<00:31,  5.91it/s]Ref scores:  82%|████████▏ | 815/1000 [02:35<00:34,  5.33it/s]Ref scores:  82%|████████▏ | 817/1000 [02:35<00:28,  6.36it/s]Ref scores:  82%|████████▏ | 818/1000 [02:35<00:30,  6.06it/s]Ref scores:  82%|████████▏ | 819/1000 [02:36<00:28,  6.37it/s]Ref scores:  82%|████████▏ | 820/1000 [02:36<00:28,  6.33it/s]Ref scores:  82%|████████▏ | 821/1000 [02:36<00:30,  5.89it/s]Ref scores:  82%|████████▏ | 822/1000 [02:36<00:29,  6.05it/s]Ref scores:  82%|████████▏ | 823/1000 [02:36<00:32,  5.38it/s]Ref scores:  82%|████████▎ | 825/1000 [02:37<00:29,  6.01it/s]Ref scores:  83%|████████▎ | 826/1000 [02:37<00:30,  5.70it/s]Ref scores:  83%|████████▎ | 827/1000 [02:37<00:28,  6.04it/s]Ref scores:  83%|████████▎ | 828/1000 [02:37<00:30,  5.65it/s]Ref scores:  83%|████████▎ | 829/1000 [02:37<00:28,  6.04it/s]Ref scores:  83%|████████▎ | 830/1000 [02:38<00:30,  5.65it/s]Ref scores:  83%|████████▎ | 831/1000 [02:38<00:32,  5.19it/s]Ref scores:  83%|████████▎ | 832/1000 [02:38<00:35,  4.70it/s]Ref scores:  83%|████████▎ | 833/1000 [02:38<00:35,  4.75it/s]Ref scores:  83%|████████▎ | 834/1000 [02:38<00:33,  4.89it/s]Ref scores:  84%|████████▎ | 835/1000 [02:39<00:35,  4.70it/s]Ref scores:  84%|████████▎ | 836/1000 [02:39<00:31,  5.29it/s]Ref scores:  84%|████████▎ | 837/1000 [02:39<00:31,  5.17it/s]Ref scores:  84%|████████▍ | 838/1000 [02:39<00:37,  4.34it/s]Ref scores:  84%|████████▍ | 839/1000 [02:39<00:33,  4.84it/s]Ref scores:  84%|████████▍ | 840/1000 [02:40<00:30,  5.22it/s]Ref scores:  84%|████████▍ | 841/1000 [02:40<00:27,  5.75it/s]Ref scores:  84%|████████▍ | 842/1000 [02:40<00:26,  5.97it/s]Ref scores:  84%|████████▍ | 843/1000 [02:40<00:29,  5.37it/s]Ref scores:  84%|████████▍ | 844/1000 [02:40<00:32,  4.79it/s]Ref scores:  84%|████████▍ | 845/1000 [02:41<00:28,  5.38it/s]Ref scores:  85%|████████▍ | 846/1000 [02:41<00:30,  5.05it/s]Ref scores:  85%|████████▍ | 847/1000 [02:41<00:32,  4.64it/s]Ref scores:  85%|████████▍ | 848/1000 [02:41<00:33,  4.59it/s]Ref scores:  85%|████████▍ | 849/1000 [02:41<00:29,  5.06it/s]Ref scores:  85%|████████▌ | 850/1000 [02:42<00:29,  5.01it/s]Ref scores:  85%|████████▌ | 851/1000 [02:42<00:32,  4.60it/s]Ref scores:  85%|████████▌ | 852/1000 [02:42<00:29,  4.98it/s]Ref scores:  85%|████████▌ | 853/1000 [02:42<00:29,  4.96it/s]Ref scores:  85%|████████▌ | 854/1000 [02:42<00:26,  5.52it/s]Ref scores:  86%|████████▌ | 856/1000 [02:43<00:21,  6.81it/s]Ref scores:  86%|████████▌ | 857/1000 [02:43<00:22,  6.23it/s]Ref scores:  86%|████████▌ | 858/1000 [02:43<00:22,  6.25it/s]Ref scores:  86%|████████▌ | 859/1000 [02:43<00:21,  6.55it/s]Ref scores:  86%|████████▌ | 860/1000 [02:43<00:20,  6.77it/s]Ref scores:  86%|████████▌ | 861/1000 [02:43<00:23,  5.81it/s]Ref scores:  86%|████████▌ | 862/1000 [02:44<00:26,  5.29it/s]Ref scores:  86%|████████▋ | 863/1000 [02:44<00:24,  5.54it/s]Ref scores:  86%|████████▋ | 864/1000 [02:44<00:23,  5.73it/s]Ref scores:  86%|████████▋ | 865/1000 [02:44<00:24,  5.44it/s]Ref scores:  87%|████████▋ | 866/1000 [02:44<00:23,  5.72it/s]Ref scores:  87%|████████▋ | 867/1000 [02:45<00:24,  5.46it/s]Ref scores:  87%|████████▋ | 868/1000 [02:45<00:22,  5.75it/s]Ref scores:  87%|████████▋ | 869/1000 [02:45<00:20,  6.45it/s]Ref scores:  87%|████████▋ | 870/1000 [02:45<00:19,  6.69it/s]Ref scores:  87%|████████▋ | 871/1000 [02:45<00:20,  6.19it/s]Ref scores:  87%|████████▋ | 872/1000 [02:45<00:18,  6.91it/s]Ref scores:  87%|████████▋ | 873/1000 [02:45<00:20,  6.18it/s]Ref scores:  87%|████████▋ | 874/1000 [02:46<00:22,  5.72it/s]Ref scores:  88%|████████▊ | 875/1000 [02:46<00:19,  6.43it/s]Ref scores:  88%|████████▊ | 876/1000 [02:46<00:18,  6.74it/s]Ref scores:  88%|████████▊ | 877/1000 [02:46<00:19,  6.22it/s]Ref scores:  88%|████████▊ | 878/1000 [02:46<00:22,  5.50it/s]Ref scores:  88%|████████▊ | 879/1000 [02:46<00:20,  5.79it/s]Ref scores:  88%|████████▊ | 880/1000 [02:47<00:21,  5.52it/s]Ref scores:  88%|████████▊ | 881/1000 [02:47<00:23,  5.08it/s]Ref scores:  88%|████████▊ | 882/1000 [02:47<00:24,  4.83it/s]Ref scores:  88%|████████▊ | 883/1000 [02:47<00:25,  4.67it/s]Ref scores:  88%|████████▊ | 884/1000 [02:48<00:22,  5.08it/s]Ref scores:  88%|████████▊ | 885/1000 [02:48<00:24,  4.63it/s]Ref scores:  89%|████████▊ | 886/1000 [02:48<00:24,  4.72it/s]Ref scores:  89%|████████▊ | 887/1000 [02:48<00:24,  4.58it/s]Ref scores:  89%|████████▉ | 888/1000 [02:48<00:21,  5.16it/s]Ref scores:  89%|████████▉ | 889/1000 [02:49<00:22,  4.87it/s]Ref scores:  89%|████████▉ | 890/1000 [02:49<00:21,  5.22it/s]Ref scores:  89%|████████▉ | 891/1000 [02:49<00:22,  4.91it/s]Ref scores:  89%|████████▉ | 892/1000 [02:49<00:19,  5.48it/s]Ref scores:  89%|████████▉ | 893/1000 [02:49<00:18,  5.71it/s]Ref scores:  89%|████████▉ | 894/1000 [02:50<00:20,  5.22it/s]Ref scores:  90%|████████▉ | 895/1000 [02:50<00:21,  4.92it/s]Ref scores:  90%|████████▉ | 896/1000 [02:50<00:21,  4.90it/s]Ref scores:  90%|████████▉ | 897/1000 [02:50<00:18,  5.49it/s]Ref scores:  90%|████████▉ | 898/1000 [02:50<00:20,  5.07it/s]Ref scores:  90%|████████▉ | 899/1000 [02:50<00:19,  5.06it/s]Ref scores:  90%|█████████ | 900/1000 [02:51<00:20,  5.00it/s]Ref scores:  90%|█████████ | 901/1000 [02:51<00:17,  5.54it/s]Ref scores:  90%|█████████ | 902/1000 [02:51<00:19,  4.94it/s]Ref scores:  90%|█████████ | 903/1000 [02:51<00:20,  4.72it/s]Ref scores:  90%|█████████ | 904/1000 [02:51<00:18,  5.16it/s]Ref scores:  90%|█████████ | 905/1000 [02:52<00:19,  4.87it/s]Ref scores:  91%|█████████ | 906/1000 [02:52<00:18,  5.22it/s]Ref scores:  91%|█████████ | 907/1000 [02:52<00:18,  5.10it/s]Ref scores:  91%|█████████ | 908/1000 [02:52<00:19,  4.83it/s]Ref scores:  91%|█████████ | 909/1000 [02:53<00:18,  4.88it/s]Ref scores:  91%|█████████ | 910/1000 [02:53<00:17,  5.21it/s]Ref scores:  91%|█████████ | 911/1000 [02:53<00:19,  4.55it/s]Ref scores:  91%|█████████ | 912/1000 [02:53<00:17,  4.96it/s]Ref scores:  91%|█████████▏| 913/1000 [02:53<00:16,  5.28it/s]Ref scores:  91%|█████████▏| 914/1000 [02:54<00:17,  4.92it/s]Ref scores:  92%|█████████▏| 915/1000 [02:54<00:15,  5.33it/s]Ref scores:  92%|█████████▏| 916/1000 [02:54<00:16,  5.22it/s]Ref scores:  92%|█████████▏| 917/1000 [02:54<00:16,  4.90it/s]Ref scores:  92%|█████████▏| 918/1000 [02:54<00:15,  5.23it/s]Ref scores:  92%|█████████▏| 919/1000 [02:54<00:14,  5.57it/s]Ref scores:  92%|█████████▏| 920/1000 [02:55<00:13,  5.75it/s]Ref scores:  92%|█████████▏| 921/1000 [02:55<00:14,  5.60it/s]Ref scores:  92%|█████████▏| 922/1000 [02:55<00:15,  5.15it/s]Ref scores:  92%|█████████▏| 923/1000 [02:55<00:15,  4.85it/s]Ref scores:  92%|█████████▏| 924/1000 [02:55<00:15,  4.84it/s]Ref scores:  92%|█████████▎| 925/1000 [02:56<00:14,  5.19it/s]Ref scores:  93%|█████████▎| 926/1000 [02:56<00:14,  5.10it/s]Ref scores:  93%|█████████▎| 927/1000 [02:56<00:13,  5.47it/s]Ref scores:  93%|█████████▎| 928/1000 [02:56<00:11,  6.27it/s]Ref scores:  93%|█████████▎| 929/1000 [02:56<00:12,  5.82it/s]Ref scores:  93%|█████████▎| 930/1000 [02:56<00:12,  5.53it/s]Ref scores:  93%|█████████▎| 931/1000 [02:57<00:13,  5.30it/s]Ref scores:  93%|█████████▎| 932/1000 [02:57<00:12,  5.62it/s]Ref scores:  93%|█████████▎| 933/1000 [02:57<00:12,  5.40it/s]Ref scores:  93%|█████████▎| 934/1000 [02:57<00:12,  5.22it/s]Ref scores:  94%|█████████▎| 935/1000 [02:57<00:12,  5.14it/s]Ref scores:  94%|█████████▎| 936/1000 [02:58<00:11,  5.68it/s]Ref scores:  94%|█████████▎| 937/1000 [02:58<00:12,  5.16it/s]Ref scores:  94%|█████████▍| 938/1000 [03:04<01:59,  1.93s/it]Ref scores:  94%|█████████▍| 939/1000 [03:04<01:26,  1.41s/it]Ref scores:  94%|█████████▍| 940/1000 [03:04<01:02,  1.05s/it]Ref scores:  94%|█████████▍| 941/1000 [03:04<00:45,  1.29it/s]Ref scores:  94%|█████████▍| 942/1000 [03:05<00:35,  1.64it/s]Ref scores:  94%|█████████▍| 943/1000 [03:05<00:27,  2.04it/s]Ref scores:  94%|█████████▍| 944/1000 [03:05<00:22,  2.47it/s]Ref scores:  94%|█████████▍| 945/1000 [03:05<00:18,  2.91it/s]Ref scores:  95%|█████████▍| 946/1000 [03:05<00:16,  3.32it/s]Ref scores:  95%|█████████▍| 947/1000 [03:05<00:13,  3.98it/s]Ref scores:  95%|█████████▍| 948/1000 [03:06<00:12,  4.21it/s]Ref scores:  95%|█████████▍| 949/1000 [03:06<00:11,  4.41it/s]Ref scores:  95%|█████████▌| 950/1000 [03:06<00:09,  5.02it/s]Ref scores:  95%|█████████▌| 951/1000 [03:06<00:11,  4.44it/s]Ref scores:  95%|█████████▌| 952/1000 [03:07<00:10,  4.67it/s]Ref scores:  95%|█████████▌| 953/1000 [03:07<00:08,  5.24it/s]Ref scores:  95%|█████████▌| 954/1000 [03:07<00:08,  5.57it/s]Ref scores:  96%|█████████▌| 955/1000 [03:07<00:09,  4.94it/s]Ref scores:  96%|█████████▌| 956/1000 [03:07<00:08,  4.91it/s]Ref scores:  96%|█████████▌| 957/1000 [03:07<00:09,  4.70it/s]Ref scores:  96%|█████████▌| 958/1000 [03:08<00:08,  4.87it/s]Ref scores:  96%|█████████▌| 959/1000 [03:08<00:08,  4.90it/s]Ref scores:  96%|█████████▌| 960/1000 [03:08<00:07,  5.44it/s]Ref scores:  96%|█████████▌| 961/1000 [03:08<00:07,  5.30it/s]Ref scores:  96%|█████████▌| 962/1000 [03:08<00:06,  5.63it/s]Ref scores:  96%|█████████▋| 963/1000 [03:08<00:05,  6.39it/s]Ref scores:  96%|█████████▋| 964/1000 [03:09<00:06,  5.89it/s]Ref scores:  96%|█████████▋| 965/1000 [03:09<00:06,  5.07it/s]Ref scores:  97%|█████████▋| 966/1000 [03:09<00:07,  4.68it/s]Ref scores:  97%|█████████▋| 967/1000 [03:09<00:07,  4.57it/s]Ref scores:  97%|█████████▋| 968/1000 [03:10<00:07,  4.48it/s]Ref scores:  97%|█████████▋| 969/1000 [03:10<00:06,  4.62it/s]Ref scores:  97%|█████████▋| 970/1000 [03:10<00:05,  5.06it/s]Ref scores:  97%|█████████▋| 971/1000 [03:10<00:06,  4.81it/s]Ref scores:  97%|█████████▋| 972/1000 [03:10<00:05,  4.85it/s]Ref scores:  97%|█████████▋| 973/1000 [03:11<00:06,  4.49it/s]Ref scores:  97%|█████████▋| 974/1000 [03:11<00:05,  4.92it/s]Ref scores:  98%|█████████▊| 975/1000 [03:11<00:04,  5.78it/s]Ref scores:  98%|█████████▊| 976/1000 [03:11<00:04,  5.99it/s]Ref scores:  98%|█████████▊| 977/1000 [03:11<00:04,  5.35it/s]Ref scores:  98%|█████████▊| 978/1000 [03:12<00:03,  5.66it/s]Ref scores:  98%|█████████▊| 979/1000 [03:12<00:05,  3.90it/s]Ref scores:  98%|█████████▊| 980/1000 [03:12<00:04,  4.18it/s]Ref scores:  98%|█████████▊| 981/1000 [03:12<00:04,  4.64it/s]Ref scores:  98%|█████████▊| 982/1000 [03:13<00:04,  4.39it/s]Ref scores:  98%|█████████▊| 983/1000 [03:13<00:03,  4.53it/s]Ref scores:  98%|█████████▊| 984/1000 [03:13<00:03,  4.67it/s]Ref scores:  98%|█████████▊| 985/1000 [03:13<00:02,  5.05it/s]Ref scores:  99%|█████████▊| 986/1000 [03:13<00:02,  5.58it/s]Ref scores:  99%|█████████▊| 987/1000 [03:13<00:02,  5.35it/s]Ref scores:  99%|█████████▉| 988/1000 [03:14<00:02,  5.84it/s]Ref scores:  99%|█████████▉| 989/1000 [03:14<00:02,  5.21it/s]Ref scores:  99%|█████████▉| 990/1000 [03:14<00:01,  5.14it/s]Ref scores:  99%|█████████▉| 991/1000 [03:14<00:01,  5.09it/s]Ref scores:  99%|█████████▉| 992/1000 [03:14<00:01,  5.06it/s]Ref scores:  99%|█████████▉| 993/1000 [03:15<00:01,  5.42it/s]Ref scores:  99%|█████████▉| 994/1000 [03:15<00:01,  5.04it/s]Ref scores: 100%|█████████▉| 995/1000 [03:15<00:00,  5.83it/s]Ref scores: 100%|█████████▉| 996/1000 [03:15<00:00,  5.51it/s]Ref scores: 100%|█████████▉| 997/1000 [03:15<00:00,  5.31it/s]Ref scores: 100%|█████████▉| 998/1000 [03:16<00:00,  4.59it/s]Ref scores: 100%|█████████▉| 999/1000 [03:16<00:00,  4.99it/s]Ref scores: 100%|██████████| 1000/1000 [03:16<00:00,  5.32it/s]Ref scores: 100%|██████████| 1000/1000 [03:16<00:00,  5.09it/s]
DONE (1.92s)
DONE (7.52s)
loss_threshold ROC AUC: 0.655065, PR AUC: 0.6138570602931931, tpr_at_low_fpr: {0.001: 0.028, 0.01: 0.075}
min_k_threshold ROC AUC: 0.6532229999999999, PR AUC: 0.6128560864243784, tpr_at_low_fpr: {0.001: 0.026, 0.01: 0.076}
zlib_threshold ROC AUC: 0.671046, PR AUC: 0.6310844318504416, tpr_at_low_fpr: {0.001: 0.044, 0.01: 0.129}
ref-stablelm-base-alpha-3b-v2_threshold ROC AUC: 0.402482, PR AUC: 0.42008576532742825, tpr_at_low_fpr: {0.001: 0.0, 0.01: 0.009}
loss_threshold roc_auc: 0.655
min_k_threshold roc_auc: 0.653
zlib_threshold roc_auc: 0.671
ref-stablelm-base-alpha-3b-v2_threshold roc_auc: 0.402
Finished.
